[{"categories":["网络协议"],"content":"在移动应用安全领域，逆向工程师常面临一个核心挑战：如何快速理解私有通信协议的逻辑，尤其是那些试图模仿或改造TLS的自定义加密协议。这类协议往往通过混淆、非标字段或魔改算法来规避检测，但其底层设计仍可能暴露出与TLS相似的模式与漏洞。 分析TLS协议的价值远不止于理解HTTPS流量： 协议设计范本：TLS是经过严格验证的工业级协议，其握手流程、密钥交换机制和错误处理逻辑为自定义协议提供了“最佳实践”参考。逆向工程师可通过对比TLS标准，快速定位私有协议中的异常点（如缺失身份验证、弱随机数生成）。 ​流量特征提取：TLS握手阶段的明文特征（如ClientHello扩展类型、证书链顺序）可作为指纹，帮助识别私有协议中类似的握手阶段。 ​密钥计算逆向：TLS 1.3的精简设计（如密钥派生函数HKDF）展示了如何从少量参数生成密钥，此类模式常被自定义协议借鉴，分析其数学逻辑有助于破解私有协议的密钥生成过程。 本文将以TLS 1.2与TLS 1.3的握手流程为核心，解析其协议组合的底层逻辑，并提炼出一套逆向分析自定义协议的方法论，最终实现以下目标： 通过TLS协议逆向，构建通用协议分析框架； 识别私有协议中的典型设计缺陷（如降级攻击面、密钥复用）； 提供工具链与实战案例，加速私有协议的解密。 ","date":"2025-03-16","objectID":"/posts/e319adc/:0:0","tags":["TLS协议"],"title":"TLS协议握手与协议组合的深度解构：从TLS 1.2到TLS 1.3的移动安全视角","uri":"/posts/e319adc/"},{"categories":["网络协议"],"content":"一、TLS协议的核心目标与组件概述 ","date":"2025-03-16","objectID":"/posts/e319adc/:1:0","tags":["TLS协议"],"title":"TLS协议握手与协议组合的深度解构：从TLS 1.2到TLS 1.3的移动安全视角","uri":"/posts/e319adc/"},{"categories":["网络协议"],"content":"1.1 SSL/TLS的演进历史 其实早期的互联网协议基本都是不加密进行传输的，如HTTP、FTP等协议 传输层安全性协议（英语：Transport Layer Security，缩写：TLS）及其前身安全套接层（英语：Secure Sockets Layer，缩写：SSL）的历史进程如下表所示： 协议 发布时间 状态 SSL 1.0 未公布 未公布 SSL 2.0 1995年 已于2011年弃用 SSL 3.0 1996年 已于2015年弃用 TLS 1.0 1999年 已于2020年弃用 TLS 1.1 2006年 已于2020年弃用 TLS 1.2 2008年 TLS 1.3 2018年 TLS 1.0 于1999年发布为RFC 2246 TLS 1.1 于2006年作为RFC 4346发布 TLS 1.2 于2008年发布为RFC 5246 TLS 1.3 于2018年8月作为建议标准在RFC 8446发布 SSL（Secure Sockets Layer）是网景公司（Netscape）设计的主要用于Web的安全传输协议，这种协议在Web上获得了广泛的应用。SSL1.0没有被公开发布过，1995 网景公司发布SSL2.0，但是由于SSL2.0有严重的安全漏洞，因此1996年又发布了SSL3.0。 但是在2014年10月，Google发布在SSL 3.0中发现设计缺陷，建议禁用此一协议。攻击者可以向TLS发送虚假错误提示，然后将安全连接强行降级到过时且不安全的SSL 3.0，然后就可以利用其中的设计漏洞窃取敏感信息。Google在自己公司相关产品中陆续禁止回溯兼容，强制使用TLS协议。Mozilla也在11月25日发布的Firefox 34中彻底禁用了SSL 3.0。微软同样发出了安全通告。这就是SSL3.0在2015年被弃用的原因。但是由于SSL存在的时间太长了，人们以及习惯用SSL这个名词来指代加密的安全传输协议，因此我们要知道现在说的SSL绝大多数都是说的TLS加密。 众所周知当年的浏览器大战微软战胜了网景，而后网景将SSL协议的管理权交给了标准化组织IETF（Internet Engineering Task Force）。1999年，IETF在SSL3.0的基础上进行发布了TLS协议的1.0版本，需要注意的是TLS1.0版本和SSL3.0版本的区别很小，并且TLS1.0是可以降级到SSL3.0来使用的，之所以换名字主要是为了避免一些版权和法律的问题。这也就导致了后来谷歌禁止TLS回溯兼容SSL协议从而避免安全事故的发送。注意其实所有TLS版本在2011年3月发布的RFC 6176中删除了对SSL2.0的兼容，这样TLS会话将永远无法协商使用的SSL 2.0以避免安全问题。但是还是可以降级协商到SSL3.0的。 TLS 1.1在 RFC 4346 中定义，于2006年4月发表。TLS 1.2在 RFC 5246 中定义，于2008年8月发表。TLS 1.3在 RFC 8446 中定义，于2018年8月发表。实际上现代的浏览器已经基本不使用 SSL，使用的都是 TLS，而目前主流使用的加密协议版本是TLS1.2和TLS1.3。 ","date":"2025-03-16","objectID":"/posts/e319adc/:1:1","tags":["TLS协议"],"title":"TLS协议握手与协议组合的深度解构：从TLS 1.2到TLS 1.3的移动安全视角","uri":"/posts/e319adc/"},{"categories":["网络协议"],"content":"1.2 TLS的“分层”结构 SSL/TLS最初是为了给HTTP协议加密使用，也就是HTTPS协议，通常来说我们可以认为HTTP+SSL/TLS=HTTPS，而实际上现在我们的很多其他应用层协议都可以使用SSL/TLS，比如SSH、FTPS、POP3S、IMAPS等等。从五层网络模型上看，其工作的空间如下： TLS协议是一个分层协议，其中握手协议（Handshake Protocol）和记录协议（Record Protocol）在安全通信中扮演不同但互补的角色 1.2.1 ​握手协议（Handshake Protocol）​ 核心功能：负责建立安全会话所需的参数，验证身份，并生成加密密钥。 主要任务： ​协商参数：客户端和服务器交换支持的TLS版本、加密套件（如AES-GCM、RSA等）和压缩方法（现代TLS通常禁用）。 ​身份验证：服务器通过数字证书验证身份（客户端验证可选）。 ​密钥交换：通过Diffie-Hellman等算法生成共享密钥材料，避免明文传输密钥。 ​生成会话密钥：基于预主密钥和随机数，派发生成对称加密密钥（如会话密钥）和初始化向量（IV）。 ​完成握手：双方确认协商参数一致，准备切换至加密通信。 适用场景 仅在连接初始化或会话恢复时运行（如TLS 1.3的0-RTT或1-RTT握手）。 在TLS 1.3中，部分握手消息可能被记录协议加密传输。 1.2.2 记录协议（Record Protocol）​ 功能核心：负责所有数据的加密、完整性保护和传输，无论数据来源是握手消息还是应用层。 主要任务 ​分块处理：将上层数据（如HTTP请求）分割为不超过16KB的块。 ​加密与完整性保护：使用握手协议生成的密钥，对数据应用对称加密（如AES）和MAC（如HMAC，TLS 1.3使用AEAD）。 ​封装传输：添加记录头（类型、版本、长度），形成TLS记录传输。 ​处理多种数据类型：包括握手协议、警报协议、应用数据等。 ​适用场景 在握手阶段：可能加密部分握手消息（如TLS 1.3的加密扩展）。 在应用阶段：加密传输HTTP等应用数据。 通过对两层协议的大致了解，可以看出 握手协议是“谈判专家”，确保双方安全参数一致并生成密钥。 ​记录协议是“执行者”，确保所有传输数据的安全性和完整性。 ​协同工作：握手协议建立安全基础，记录协议基于此基础保护实际通信，两者共同构建端到端的安全通道。 ","date":"2025-03-16","objectID":"/posts/e319adc/:1:2","tags":["TLS协议"],"title":"TLS协议握手与协议组合的深度解构：从TLS 1.2到TLS 1.3的移动安全视角","uri":"/posts/e319adc/"},{"categories":["网络协议"],"content":"二、TLS 1.2握手流程的逐层拆解 下面将结合RFC文档、CS源码、Wireshark抓包这三个角度来讲解，资源来自于 The Illustrated TLS 1.2 Connection: Every byte explained The Illustrated TLS 1.2 Connection - Github ","date":"2025-03-16","objectID":"/posts/e319adc/:2:0","tags":["TLS协议"],"title":"TLS协议握手与协议组合的深度解构：从TLS 1.2到TLS 1.3的移动安全视角","uri":"/posts/e319adc/"},{"categories":["网络协议"],"content":"2.1 完整握手流程 首先通过官方RFC文档初步认识下一个完整的握手流程 Client Server ClientHello --------\u003e ServerHello Certificate* ServerKeyExchange* CertificateRequest* \u003c-------- ServerHelloDone Certificate* ClientKeyExchange CertificateVerify* [ChangeCipherSpec] Finished --------\u003e [ChangeCipherSpec] \u003c-------- Finished Application Data \u003c-------\u003e Application Data Figure 1. Message flow for a full handshake *号表示可选步骤或与实际握手情况相关。比如重建已有连接，服务端无需执行Certificate，再比如使用RSA公钥加密时，无需ServerKeyExchange。 搭配Wireshark看看实际抓包中握手的流程 从上图中可以得到一些初步理解： 整个握手过程经历了四次数据传输 每次传输中都带有至少一个数据包 完整的握手流程有时候也被称为2-RTT流程，即完整的握手流程需要客户端和服务端交互2次才能完成握手。 仔细看抓包中红框数据包的地方可以发现，每个数据所在的层级都是Record Layer，每个数据包细分又可以得到Handshake Protocol，这也印证了上文提到的TLS“分层”架构，底层Record Layer负责装载上层传来的数据包 Record层有其对应的结构，在接收到上层传来的数据包时完成封装 struct { uint8 major; uint8 minor; } ProtocolVersion; enum { change_cipher_spec(20), alert(21), handshake(22), application_data(23), (255) } ContentType; struct { ContentType type; ProtocolVersion version; uint16 length; opaque fragment[TLSPlaintext.length]; } TLSPlaintext; 从上述定义可以看到Record的前两字节是用于定义协议版本，但是从上图我们发现TLS 1.2对应的版本为0303，这乍看起来有点别扭，但其实是历史发展的结果。历史上TLS由SSL进化而来，通常也统称为SSL/TLS，因此版本对应关系分别是: SSL 3.0 -\u003e 0300 TLS 1.0 -\u003e 0301 TLS 1.1 -\u003e 0302 TLS 1.2 -\u003e 0303 TLS 1.3 -\u003e 0304 … 这个版本号字段虽然不是很重要，但是却可以作为TLS协议的特征记录下来 2.1.1 STEP 1 2.1.1.1 Client Hello 当客户端首次与服务端建立连接或需要重新协商加密握手会话时，需要将Client Hello作为第一条消息发送给服务端，就像TCP连接需要发送SYN 一样，告诉服务端你要建立一个TLS连接，关于ClientHello的结构如下 struct { ProtocolVersion client_version; Random random; SessionID session_id; CipherSuite cipher_suites\u003c2..2^16-2\u003e; CompressionMethod compression_methods\u003c1..2^8-1\u003e; select (extensions_present) { case false: struct {}; case true: Extension extensions\u003c0..2^16-1\u003e; }; } ClientHello; client_version：指客户端版本，值为 0x0303，表示TLS 1.2。值得一提的是该值与Record中的版本不一定一致，后者由于兼容性的原因通常会设置为一个较旧的版本(比如 TLS 1.0)，服务端应当以 ClientHello中指定的版本为准，作用是告诉服务端当前客户端所支持的最新版本，以便后续服务端根据对应版本进行后续协商流程。 random：是客户端本地生成的32 字节随机数，在RFC5246中提到随机数的前四字节应该是客户端的本地时间戳，但后来发现这样会存在针对客户端或者服务端的设备指纹标记，因此已经不建议使用时间戳了。random的作用是为了增强加密密钥的安全性，作为随机因子，通过该随机数使用基于HMAC的PRF算法生成客户端和服务端的密钥。 session_id：主要用于恢复加密链接，需要客户端和服务端同时支持。由于秘钥协商的过程中涉及到很多费时的操作，对于短链接而言将之前协商好的加密通道恢复可以大大减少运算资源。如果服务器支持恢复会话，那么后续可以直接进入加密通信，否则还是需要进行完整的握手协商。该字段的长度是可变的，占1字节，也就是说数据部分最多可以长达255字节。 cipher_suites：表示客户端所支持的加密套件，带有2字节长度字段，每个加密套件用2字节表示，且优先级高的排在前面。作用是和服务端协商加密算法，服务端根据支持算法在ServerHello返回一个最合适的算法组合。算法套件的格式为TLS_密钥交换算法_身份认证算法_WITH_对称加密算法_消息摘要算法，比如TLS_DHE_RSA_WITH_AES_256_CBC_SHA256，密钥交换算法是DHE，身份认证算法是RSA，对称加密算法是AES_256_CBC，消息摘要算法是SHA256，由于RSA又可以用于加密也可以用于身份认证，因此密钥交换算法使用RSA时，只写一个RSA，比如TLS_RSA_WITH_AES_256_CBC_SHA256。 compression_methods：表示客户端所支持的一系列压缩算法。数据需要先压缩后加密，因为加密后的数据通常很难压缩。但是压缩的数据在加密中会受到类似CRIME攻击的影响，因此在TLS1.3中已经将TLS压缩功能去除，TLS1.2算法也建议不启用压缩功能。 extensions：可以在不改变底层协议的情况下，添加附加功能。客户端使用扩展请求其他功能，服务端若不提供这些功能，客户端可能会中止握手。对于扩展字段的详细定义可以看Transport Layer Security (TLS) Extensions 客户端发送完 ClientHello 消息后，将等待 ServerHello 消息。 服务端返回的任何握手消息（HelloRequest 除外）都将被视为异常 2.1.2 STEP 2 2.1.2.1 Server Hello 当服务端接收到ClientHello，则开始TLS握手流程， 服务端需要根据客户端提供的加密套件，协商一个合适的算法簇，其中包括对称加密算法、身份验证算法、非对称加密算法以及消息摘要算法。若服务端不能找到一个合适的算法簇匹配项，则会响应握手失败的预警消息。关于ServerHello的结构如下 struct { ProtocolVersion server_version; Random random; SessionID session_id; CipherSuite cipher_suite; CompressionMethod compression_method; select (extensions_present) { case false: struct {}; case true: Extension extensions\u003c0..2^16-1\u003e; }; } ServerHello; client_version：服务端根据客户端发送的版本号返回一个服务端支持的最高版本号。若客户端不支持服务端选择的版本号，则客户端必须发送protocol_version的alert消息并关闭连接。 random：逻辑和客户端相同 session_id：若客户端提供了会话ID，则可以校验是否与历史会话匹配 若不匹配，则服务端可以选择直接使用客户端的会话ID或根据自定义规则生成一个新的会话ID，客户端需要保存服务端返回的会话ID当作本次会话的ID 若匹配，则可以直接执行1-RTT握手流程，返回ServerHello后直接返回ChangeCipherSpec和Finished消息。 Client Server ClientHello --------\u003e ServerHello [ChangeCipherSpec] \u003c-------- Finished [ChangeCipherSpec] Finished --------\u003e Application Data \u003c-------\u003e Application Data Figure 2. Message flow for an abbreviated handshake cipher_suites：服务端根据客户端提供的算法套件列表和自己当前支持算法进行匹配，选择一个最合适的算法组合，若没有匹配项，则使用默认的TLS_RSA_WITH_AES_128_CBC_SHA。 TLS1.2协议要求客户端和服务端都必须实现密码套件TLS_RSA_WITH_AES_128_CBC_SHA compression_methods：逻辑和客户端相同 extensions：服务端需","date":"2025-03-16","objectID":"/posts/e319adc/:2:1","tags":["TLS协议"],"title":"TLS协议握手与协议组合的深度解构：从TLS 1.2到TLS 1.3的移动安全视角","uri":"/posts/e319adc/"},{"categories":["网络协议"],"content":"2.2 会话恢复机制 TODO： Session ID与Session Ticket的区别与风险 ","date":"2025-03-16","objectID":"/posts/e319adc/:2:2","tags":["TLS协议"],"title":"TLS协议握手与协议组合的深度解构：从TLS 1.2到TLS 1.3的移动安全视角","uri":"/posts/e319adc/"},{"categories":["网络协议"],"content":"三、TLS 1.3的协议重组与握手简化 ","date":"2025-03-16","objectID":"/posts/e319adc/:3:0","tags":["TLS协议"],"title":"TLS协议握手与协议组合的深度解构：从TLS 1.2到TLS 1.3的移动安全视角","uri":"/posts/e319adc/"},{"categories":["网络协议"],"content":"3.1 协议消息的“合并”与“弃用”​ 由于TLS 1.3是在TLS 1.2的基础上优化而来的，因此对于与上节实现相同的部分就不再详细介绍了，而只关注其中不同的部分。 总体来看，TLS 1.3与TLS 1.2相比，较大的差异有下面这些: 去除了一大堆过时的对称加密算法，只留下较为安全的AEAD(Authenticated Encryption with Associated Data)算法；加密套件(cipher suite)的概念被修改为单独的认证、秘钥交换算法以及秘钥拓展和MAC用到的哈希算法； 去除了静态RSA和秘钥交换算法套件，使目前所有基于公钥的交换算法都能保证前向安全； 引入了0-RTT(round-trip time) 的模式，减少握手的消息往返次数； ServerHello之后所有的握手消息都进行了加密； 修改了秘钥拓展算法，称为HKDF(HMAC-based Extract-and-Expand Key Derivation Function)； 废弃了TLS 1.2中的协议版本协商方法，改为使用Extension实现； TLS 1.2中的会话恢复功能现在采用了新的 PSK 交换实现； …… 下面将结合RFC文档、CS源码、Wireshark抓包这三个角度来讲解，资源来自于 The Illustrated TLS 1.3 Connection: Every byte explained The Illustrated TLS 1.3 Connection - Github 照惯例通过官方RFC文档初步认识下一个完整的握手流程 Client Server Key ^ ClientHello Exch | + key_share* | + signature_algorithms* | + psk_key_exchange_modes* v + pre_shared_key* --------\u003e ServerHello ^ Key + key_share* | Exch + pre_shared_key* v {EncryptedExtensions} ^ Server {CertificateRequest*} v Params {Certificate*} ^ {CertificateVerify*} | Auth {Finished} v \u003c-------- [Application Data*] ^ {Certificate*} Auth | {CertificateVerify*} v {Finished} --------\u003e [Application Data] \u003c-------\u003e [Application Data] + Indicates noteworthy extensions sent in the previously noted message. * Indicates optional or situation-dependent messages/extensions that are not always sent. {} Indicates messages protected using keys derived from a [sender]_handshake_traffic_secret. [] Indicates messages protected using keys derived from [sender]_application_traffic_secret_N. Figure 1: Message Flow for Full TLS Handshake 如果大家对于TLS1.2还有印象的话就会发现有几个变化 整个握手流程减少了一次服务端的回调 新增了key_share、pre_shared_key等等新的结构 整个流程目前只有1RTT，相比较之前的减少了一倍，在通信效率方面的提升巨大，而且还存在0RTT的模式，下面就通过具体的握手流程来分析下TLS1.3带来的变化 3.1.1 STEP 1 3.1.1.1 Client Hello 与TLS1.2一样，握手总是以Client发送Hello请求开始。但正如本节开头所说，TLS握手时的协议协商不再使用Handshake/Hello中的version字段，虽然是1.3版本，但请求中version还是指定1.2版本，这是因为有许多web中间件在设计时候会忽略不认识的TLS版本号，因此为了兼容性，版本号依旧保持不变。实际协商TLS版本是使用的是SupportedVersions拓展实现的。ClientHello的结构如下 struct { ProtocolVersion legacy_version = 0x0303; /* TLS v1.2 */ Random random; opaque legacy_session_id\u003c0..32\u003e; CipherSuite cipher_suites\u003c2..2^16-2\u003e; opaque legacy_compression_methods\u003c1..2^8-1\u003e; Extension extensions\u003c8..2^16-1\u003e; } ClientHello; session_id字段在此前的版本中该字段被用于恢复TLS会话，不过在TLS1.3中会话恢复使用了一种更为灵活的PSK秘钥交换方式，因此这个字段在TLS1.3中是没有实际作用的。 在ClientHello消息中，有一个重要的拓展，即KeyShare，用于与服务器交换秘钥。前文说到在TLS1.3中，ServerHello之后的所有消息都是加密的，那么为了双方能够正确加解密数据，因此在ClientHello中，客户端就已经通过该拓展告诉服务端自己的公钥以及秘钥交换算法，如图所示 客户端指定了x25519椭圆曲线加密，生成一对公私钥，该公钥就随着Client Hello发送给了服务端。 3.1.2 STEP 2 3.1.2.1 Server Hello 服务端根据客户端提供的选项，选择一个好自己支持的TLS版本以及加密套件，这里选的是TLS_AES_256_GCM_SHA384 由于涉及到了秘钥交换，服务端在收到请求后也需要先生成一对临时公私钥，Key Share Extension 中返回的即为上述公钥。 如果还记得上文的ECDH秘钥交换方法，就明白到这里服务端就可以很容易计算出两端的共享秘钥。该秘钥用于生成后续握手包所需的秘钥，使用HKDF函数进行生成，如下所示 early_secret = HKDF-Extract(salt: 00, key: 00...) empty_hash = SHA384(\"\") derived_secret = HKDF-Expand-Label(key: early_secret, label: \"derived\", ctx: empty_hash, len: 48) handshake_secret = HKDF-Extract(salt: derived_secret, key: shared_secret) client_secret = HKDF-Expand-Label(key: handshake_secret, label: \"c hs traffic\", ctx: hello_hash, len: 48) server_secret = HKDF-Expand-Label(key: handshake_secret, label: \"s hs traffic\", ctx: hello_hash, len: 48) client_handshake_key = HKDF-Expand-Label(key: client_secret, label: \"key\", ctx: \"\", len: 32) server_handshake_key = HKDF-Expand-Label(key: server_secret, label: \"key\", ctx: \"\", len: 32) client_handshake_iv = HKDF-Expand-Label(key: client_secret, label: \"iv\", ctx: \"\", len: 12) server_handshake_iv = HKDF-Expand-Label(key: server_secret, label: \"iv\", ctx: \"\", len: 12) 3.1.2.2 Server Encrypted Extensions 在计算完共享秘钥后，后续的流量将使用上述秘钥进行加密，因此对于TLS 1.2的情况服务端会先返回一个 ChangeCipherSpec，在TLS 1.3中可不必多此一举，不过在兼容模式下为了防止某些中间件抽风还是会多这么一步。 我们这里直接看加密的数据，服务端一般会先返回一个Encrypted Extensions类型的Record消息，该消息加密后存放在Record(type=0x17)，即Application Data的Body部分，同时(加密后数据的)末尾还添加了16字节的 Auth Tag，这是AEAD算法用来校验加密消息完整性的数据。 根据之前服务端所选择的套件，这里数据使用 AES-256-GCM 进行加密和校验，这里解密后的拓展长度为空。一般与握手无关的额外拓展都会放在这里返回，这是为了能够尽可能地减少握手阶段的明文传输。 3.1.2.3 Server Certificate 使","date":"2025-03-16","objectID":"/posts/e319adc/:3:1","tags":["TLS协议"],"title":"TLS协议握手与协议组合的深度解构：从TLS 1.2到TLS 1.3的移动安全视角","uri":"/posts/e319adc/"},{"categories":["网络协议"],"content":"3.2 1-RTT与0-RTT握手流程 密钥计算的提前化（Early Data与PSK机制）。 0-RTT的安全争议与移动端应用限制（重放攻击风险）。 ","date":"2025-03-16","objectID":"/posts/e319adc/:3:2","tags":["TLS协议"],"title":"TLS协议握手与协议组合的深度解构：从TLS 1.2到TLS 1.3的移动安全视角","uri":"/posts/e319adc/"},{"categories":["网络协议"],"content":"四、协议组合变化的安全意义 ","date":"2025-03-16","objectID":"/posts/e319adc/:4:0","tags":["TLS协议"],"title":"TLS协议握手与协议组合的深度解构：从TLS 1.2到TLS 1.3的移动安全视角","uri":"/posts/e319adc/"},{"categories":["网络协议"],"content":"4.1 密钥交换机制的演进 从静态RSA到临时ECDHE（前向保密的强制化）。 加密与密钥交换的耦合关系（加密套件的AEAD化）。 ","date":"2025-03-16","objectID":"/posts/e319adc/:4:1","tags":["TLS协议"],"title":"TLS协议握手与协议组合的深度解构：从TLS 1.2到TLS 1.3的移动安全视角","uri":"/posts/e319adc/"},{"categories":["网络协议"],"content":"4.2 握手消息的加密范围 TLS 1.2的明文部分（Server Certificate） vs TLS 1.3的加密扩展（Encrypted Extensions）。 ","date":"2025-03-16","objectID":"/posts/e319adc/:4:2","tags":["TLS协议"],"title":"TLS协议握手与协议组合的深度解构：从TLS 1.2到TLS 1.3的移动安全视角","uri":"/posts/e319adc/"},{"categories":["网络协议"],"content":"五、逆向分析自定义协议的方法论提炼 从TLS设计中学习的通用模式： ​握手阶段的标志性消息​（如随机数交换、密钥参数传递）。 ​密钥计算的时序依赖（何时生成加密密钥、如何验证完整性）。 ​自定义协议的常见漏洞点： 未加密的元数据暴露（如协议版本、支持的算法）。 弱密钥交换逻辑（静态密钥复用、缺乏前向保密）。 ","date":"2025-03-16","objectID":"/posts/e319adc/:5:0","tags":["TLS协议"],"title":"TLS协议握手与协议组合的深度解构：从TLS 1.2到TLS 1.3的移动安全视角","uri":"/posts/e319adc/"},{"categories":["网络协议"],"content":"六、移动端TLS协议分析的实践挑战 中间件干扰问题：移动网络中的代理与TLS拦截（证书锁定绕过）。 ​协议混淆技术的干扰：如何区分TLS握手与私有协议（流量特征分析）。 ","date":"2025-03-16","objectID":"/posts/e319adc/:6:0","tags":["TLS协议"],"title":"TLS协议握手与协议组合的深度解构：从TLS 1.2到TLS 1.3的移动安全视角","uri":"/posts/e319adc/"},{"categories":["网络协议"],"content":"七、结语 ","date":"2025-03-16","objectID":"/posts/e319adc/:7:0","tags":["TLS协议"],"title":"TLS协议握手与协议组合的深度解构：从TLS 1.2到TLS 1.3的移动安全视角","uri":"/posts/e319adc/"},{"categories":["网络协议"],"content":"7.1 TLS协议分析的普适性价值 逆向范式的标准化 TLS的分层设计（握手协议与记录协议解耦）和密钥派生流程（从随机数到会话密钥的确定性推导）为私有协议提供了标准范本。逆向分析人员可通过对比TLS的标准流程，快速定位私有协议中的“非常规”操作，例如： 握手阶段未交换随机数（易遭受重放攻击）； 密钥派生依赖静态参数（缺乏前向保密）； 未加密的元数据暴露（如协议版本、设备指纹）。 攻击面的映射 TLS的历史漏洞（如FREAK、Logjam）本质上源于协议组合的缺陷（允许降级到弱算法）。类似地，私有协议若未强制加密算法或允许版本回滚，其攻击面可被快速锁定。 ","date":"2025-03-16","objectID":"/posts/e319adc/:7:1","tags":["TLS协议"],"title":"TLS协议握手与协议组合的深度解构：从TLS 1.2到TLS 1.3的移动安全视角","uri":"/posts/e319adc/"},{"categories":["网络协议"],"content":"7.2 从协议逆向到漏洞挖掘的方法论 通过解构TLS，我们可提炼出逆向分析私有协议的关键路径： 流程拆解： 识别握手阶段（类比TLS的ClientHello/ServerHello）与应用数据传输阶段（类比TLS记录协议）； 标记明文与密文分界点（如TLS 1.3的EncryptedExtensions）。 ​密钥追踪： 定位随机数生成点（如Hook SecureRandom类方法）； 捕获密钥派生函数的输入输出（如拦截OpenSSL的EVP_DigestSign函数）。 ​风险建模： 若协议未加密算法协商过程，可伪造降级请求（模拟TLS的Downgrade Dance攻击）； 若协议复用会话密钥，可重放历史流量解密数据（类比TLS 1.2的Session Resumption漏洞）。 ","date":"2025-03-16","objectID":"/posts/e319adc/:7:2","tags":["TLS协议"],"title":"TLS协议握手与协议组合的深度解构：从TLS 1.2到TLS 1.3的移动安全视角","uri":"/posts/e319adc/"},{"categories":["网络协议"],"content":"7.3 后续思考 工具化思维： 将TLS逆向方法论转化为自动化工具，例如： 基于机器学习的协议指纹识别（从流量中分类TLS-like协议）； 动态插桩框架（如Frida脚本库）快速提取密钥参数。 ​协作与知识沉淀： 建立私有协议的特征库（如常见随机数位置、密钥派生函数哈希类型），推动社区共享攻击面模型。 TLS协议是一面“镜子”，既映照出工业级协议应有的严谨性，也暴露出自定义协议在安全性上的妥协。作为移动安全工程师，我们应深入理解TLS的设计哲学，将其转化为逆向工程的“探针”——从随机数的生成到加密层的切换，每一步都可能成为击穿私有协议的突破口。唯有将协议逆向与安全设计原则深度融合，才能在隐私与安全的博弈中找到无往不胜的突破口。 ","date":"2025-03-16","objectID":"/posts/e319adc/:7:3","tags":["TLS协议"],"title":"TLS协议握手与协议组合的深度解构：从TLS 1.2到TLS 1.3的移动安全视角","uri":"/posts/e319adc/"},{"categories":["设备异常性检测"],"content":"思路 怎么可以利用Android提供的KeyAttestation认证方式来做设备异常性的检测呢？首先想想KeyAttestation是什么？能够提供什么？ 提供可信环境可以支持存储密钥 设备端可以将密钥保存在KeyStore当中并认为该密钥具有绝对安全性 设备身份和完整性校验 验证密钥可信度的方式就是对整条证书链做校验并最终提取根证书进行校验 因此可以看出，核心是对证书链的校验及对根证书的数据进行校验，证书的内容可以从官方文档中了解 证书可分为证书本身及证书扩展，其中证书本身的序列包括 signatureAlgorithm: 用于签署密钥的算法的 AlgorithmIdentifier：ECDSA 用于 EC 密钥，RSA 用于 RSA 密钥。 signatureValue: BIT STRING，在 ASN.1 DER 编码的 tbsCertificate 上计算的签名。 tbsCertificate: TBSCertificate 序列 从文档中包括源码实现中可以了解到，这些证书本身的信息是为了做证书链校验的，除此之外，更核心的是根证书扩展字段的校验 KeyDescription ::= SEQUENCE { attestationVersion INTEGER, # KM2 value is 1. KM3 value is 2. KM4 value is 3. attestationSecurityLevel SecurityLevel, keymasterVersion INTEGER, keymasterSecurityLevel SecurityLevel, attestationChallenge OCTET_STRING, uniqueId OCTET_STRING, softwareEnforced AuthorizationList, teeEnforced AuthorizationList, } SecurityLevel ::= ENUMERATED { Software (0), TrustedEnvironment (1), StrongBox (2), } AuthorizationList ::= SEQUENCE { purpose [1] EXPLICIT SET OF INTEGER OPTIONAL, algorithm [2] EXPLICIT INTEGER OPTIONAL, keySize [3] EXPLICIT INTEGER OPTIONAL. digest [5] EXPLICIT SET OF INTEGER OPTIONAL, padding [6] EXPLICIT SET OF INTEGER OPTIONAL, ecCurve [10] EXPLICIT INTEGER OPTIONAL, rsaPublicExponent [200] EXPLICIT INTEGER OPTIONAL, rollbackResistance [303] EXPLICIT NULL OPTIONAL, # KM4 activeDateTime [400] EXPLICIT INTEGER OPTIONAL originationExpireDateTime [401] EXPLICIT INTEGER OPTIONAL usageExpireDateTime [402] EXPLICIT INTEGER OPTIONAL noAuthRequired [503] EXPLICIT NULL OPTIONAL, userAuthType [504] EXPLICIT INTEGER OPTIONAL, authTimeout [505] EXPLICIT INTEGER OPTIONAL, allowWhileOnBody [506] EXPLICIT NULL OPTIONAL, trustedUserPresenceRequired [507] EXPLICIT NULL OPTIONAL, # KM4 trustedConfirmationRequired [508] EXPLICIT NULL OPTIONAL, # KM4 unlockedDeviceRequired [509] EXPLICIT NULL OPTIONAL, # KM4 allApplications [600] EXPLICIT NULL OPTIONAL, applicationId [601] EXPLICIT OCTET_STRING OPTIONAL, creationDateTime [701] EXPLICIT INTEGER OPTIONAL, origin [702] EXPLICIT INTEGER OPTIONAL, rollbackResistant [703] EXPLICIT NULL OPTIONAL, # KM2 and KM3 only. rootOfTrust [704] EXPLICIT RootOfTrust OPTIONAL, osVersion [705] EXPLICIT INTEGER OPTIONAL, osPatchLevel [706] EXPLICIT INTEGER OPTIONAL, attestationApplicationId [709] EXPLICIT OCTET_STRING OPTIONAL, # KM3 attestationIdBrand [710] EXPLICIT OCTET_STRING OPTIONAL, # KM3 attestationIdDevice [711] EXPLICIT OCTET_STRING OPTIONAL, # KM3 attestationIdProduct [712] EXPLICIT OCTET_STRING OPTIONAL, # KM3 attestationIdSerial [713] EXPLICIT OCTET_STRING OPTIONAL, # KM3 attestationIdImei [714] EXPLICIT OCTET_STRING OPTIONAL, # KM3 attestationIdMeid [715] EXPLICIT OCTET_STRING OPTIONAL, # KM3 attestationIdManufacturer [716] EXPLICIT OCTET_STRING OPTIONAL, # KM3 attestationIdModel [717] EXPLICIT OCTET_STRING OPTIONAL, # KM3 vendorPatchLevel [718] EXPLICIT INTEGER OPTIONAL, # KM4 bootPatchLevel [719] EXPLICIT INTEGER OPTIONAL, # KM4 } RootOfTrust ::= SEQUENCE { verifiedBootKey OCTET_STRING, deviceLocked BOOLEAN, verifiedBootState VerifiedBootState, verifiedBootHash OCTET_STRING, # KM4 } VerifiedBootState ::= ENUMERATED { Verified (0), SelfSigned (1), Unverified (2), Failed (3), } 其中可以利用来做异常性检测的是 attestationVersion：attestation版本，采集该字段可以做机型的离群检测 attestationSecurityLevel：该字段包括设备所支持的可信环境版本，同理可以做离群检测 keymasterVersion：同上 keymasterSecurityLevel：同上 teeEnforced-rootOfTrust（通常是在设备制造商在出厂时写入设备） verifiedBootKey：验证设备Bootloader的公钥，可以在后台做机型版本检测 deviceLocked：设备解锁状态，可以直接检测 verifiedBootState：同上，可以直接检测 verifiedBootHash：当前启动链完整性的哈希值，包括Bootloader和所有加载和验证的启动相关分区，可以在后台做机型版本检测 ","date":"2024-08-31","objectID":"/posts/keyattestation%E6%A3%80%E6%B5%8B%E6%80%9D%E8%B7%AF/:0:1","tags":["KeyAttestation"],"title":"KeyAttestation检测思路","uri":"/posts/keyattestation%E6%A3%80%E6%B5%8B%E6%80%9D%E8%B7%AF/"},{"categories":["设备异常性检测"],"content":"结合github项目KeyAttestation来学习KeyAttestation原理 ","date":"2024-08-30","objectID":"/posts/keyattestation%E5%8E%9F%E7%90%86%E7%90%86%E8%A7%A3/:0:0","tags":["KeyAttestation"],"title":"KeyAttestation原理理解","uri":"/posts/keyattestation%E5%8E%9F%E7%90%86%E7%90%86%E8%A7%A3/"},{"categories":["设备异常性检测"],"content":"一、项目结构 1.1 App展示 页面展示来自于attestationResult这个回调结果 // app/src/main/java/io/github/vvb2060/keyattestation/home/HomeViewModel.kt val useStrongBox = hasStrongBox \u0026\u0026 preferStrongBox val includeProps = hasDeviceIds \u0026\u0026 preferIncludeProps val useAttestKey = hasAttestKey \u0026\u0026 preferAttestKey val result = try { val attestationResult = doAttestation(useStrongBox, includeProps, useAttestKey) Resource.success(attestationResult) } catch (e: Throwable) { val cause = if (e is AttestationException) e.cause else e Log.w(AppApplication.TAG, \"Do attestation error.\", cause) when (e) { is AttestationException -\u003e Resource.error(e, null) else -\u003e Resource.error(AttestationException(CODE_UNKNOWN, e), null) } } 1.2 初步梳理流程 // app/src/main/java/io/github/vvb2060/keyattestation/home/HomeViewModel.kt @Throws(AttestationException::class) private fun doAttestation(useStrongBox: Boolean, includeProps: Boolean, useAttestKey: Boolean): AttestationResult { val certs = ArrayList\u003cCertificate\u003e() val alias = if (useStrongBox) \"${AppApplication.TAG}_strongbox\" else AppApplication.TAG val attestKeyAlias = if (useAttestKey) \"${alias}_persistent\" else null try { // 1. generateKey if (useAttestKey \u0026\u0026 !keyStore.containsAlias(attestKeyAlias)) { generateKey(attestKeyAlias!!, useStrongBox, includeProps, attestKeyAlias) } generateKey(alias, useStrongBox, includeProps, attestKeyAlias) // 2. certs collect val certChain = keyStore.getCertificateChain(alias) ?: throw CertificateException(\"Unable to get certificate chain\") for (cert in certChain) { val buf = ByteArrayInputStream(cert.encoded) certs.add(certificateFactory.generateCertificate(buf)) } if (useAttestKey) { val persistChain = keyStore.getCertificateChain(attestKeyAlias) ?: throw CertificateException(\"Unable to get certificate chain\") for (cert in persistChain) { val buf = ByteArrayInputStream(cert.encoded) certs.add(certificateFactory.generateCertificate(buf)) } } } catch (e: ProviderException) { // 异常流程，可忽略 ...... } catch (e: Exception) { throw AttestationException(CODE_UNKNOWN, e) } @Suppress(\"UNCHECKED_CAST\") // 3. parseCertificateChain currentCerts = certs as List\u003cX509Certificate\u003e return parseCertificateChain(certs) } 从代码流程中可以分为三步 generateKey certs collect parseCertificateChain ","date":"2024-08-30","objectID":"/posts/keyattestation%E5%8E%9F%E7%90%86%E7%90%86%E8%A7%A3/:0:1","tags":["KeyAttestation"],"title":"KeyAttestation原理理解","uri":"/posts/keyattestation%E5%8E%9F%E7%90%86%E7%90%86%E8%A7%A3/"},{"categories":["设备异常性检测"],"content":"二、源码分析 2.1 入参 doAttestation的入参有三个 useStrongBox includeProps useAttestKey 获取方式是 // android.hardware.strongbox_keystore useStrongBox = pm.hasSystemFeature(PackageManager.FEATURE_STRONGBOX_KEYSTORE) // android.hardware.keystore.app_attest_key hasAttestKey = pm.hasSystemFeature(PackageManager.FEATURE_KEYSTORE_APP_ATTEST_KEY) hasDeviceIds = pm.hasSystemFeature(\"android.software.device_id_attestation\") 是从PackageManager中获取系统属性，这三个属性指的是什么意思呢？这里需要引入Android KeyStore的演变历史 KeyStore是借助系统芯片 (SoC) 中提供的可信执行环境，由硬件支持的密钥库 KeyMaster 0.2 0.3 在 Android 6.0 之前的版本中，Android 已有一个非常简单的由硬件支持的加密服务 API（由 0.2 和 0.3 版的 Keymaster 硬件抽象层 (HAL) 提供）。该密钥库能够提供数字签名和验证操作，以及不对称签名密钥对的生成和导入操作。该 API 在许多设备上都已实现，但有许多安全目标无法只通过一个签名 API 来轻松达成。Android 6.0 中的密钥库在该密钥库 API 的基础上进行了扩展，能够提供更广泛的功能 KeyMaster 1 在 Android 6.0 中，密钥库不仅增加了对称加密基元（AES 和 HMAC），还增加了针对由硬件支持的密钥的访问权限控制系统。访问权限控制在密钥生成期间指定，并会在密钥的整个生命周期内被强制执行。可以将密钥限定为仅在用户通过身份验证后才可使用，并且只能用于指定的目的或只有在具有指定的加密参数时才可使用。如需了解详情，请参阅授权标记和函数页面。 KeyMaster 2 在 Android 7.0 中，Keymaster 2 增加了对密钥认证和版本绑定的支持。密钥认证提供公钥证书，这些证书中包含密钥及其访问权限控制的详细描述，以使密钥存在于安全硬件中并使其配置可以远程验证。 KeyMaster 3 在 Android 8.0 中，Keymaster 3 从旧式 C 结构硬件抽象层 (HAL) 转换到根据新硬件接口定义语言 (HIDL) 中的定义生成的 C++ HAL 接口。在此变更过程中，很多参数类型发生了变化，但这些类型和方法与旧的类型和 HAL 结构体方法一一对应。如需了解详情，请参阅函数页面 除了此接口修订之外，Android 8.0 还扩展了 Keymaster 2 的认证功能，以支持 ID 认证。 ID 认证提供了一种受限且可选的机制来严格认证硬件标识符，例如设备序列号、产品名称和手机 ID (IMEI/MEID)。为了实现此新增功能，Android 8.0 更改了 ASN.1 认证架构，添加了 ID 认证。Keymaster 实现需要通过某种安全方式来检索相关的数据项，还需要定义一种安全永久地停用该功能的机制。 KeyMaster 4 Android 9 纳入了以下更新： 更新到 Keymaster 4 对嵌入式安全元件的支持 对安全密钥导入的支持 对 3DES 加密的支持 更改了版本绑定，以便 boot.img 和 system.img 分别设置版本以允许独立更新 从KeyStore的版本演变上看，在迭代过程中逐步加入了新的认证方式，而FEATURE_STRONGBOX_KEYSTORE、FEATURE_KEYSTORE_APP_ATTEST_KEY就是判断设备是否支持某种认证方式（原因是因为OEM厂商不一定会紧跟着Google的架构演变方案） 2.2 generateKey if (useAttestKey \u0026\u0026 !keyStore.containsAlias(attestKeyAlias)) { generateKey(attestKeyAlias!!, useStrongBox, includeProps, attestKeyAlias) } generateKey(alias, useStrongBox, includeProps, attestKeyAlias) 这里区分了生成key的类型，如果设备开启了App Attest Key特性的话生成的密钥可以用来做密钥认证（Key Attestation），否则就是正常的数字签名密钥 这里优先根据是否开启了App Attest Key特性及KeyStore中是否包含attestKeyAlias的密钥来进行密钥生成 private fun generateKey(alias: String, useStrongBox: Boolean, includeProps: Boolean, attestKeyAlias: String?) { val now = Date() val attestKey = alias == attestKeyAlias // 密钥用途判定 val purposes = if (Build.VERSION.SDK_INT \u003e= Build.VERSION_CODES.S \u0026\u0026 attestKey) { KeyProperties.PURPOSE_ATTEST_KEY } else { KeyProperties.PURPOSE_SIGN } // 设置 KeyGenParameterSpec val builder = KeyGenParameterSpec.Builder(alias, purposes) .setAlgorithmParameterSpec(ECGenParameterSpec(\"secp256r1\")) .setDigests(KeyProperties.DIGEST_SHA256) .setCertificateNotBefore(now) .setAttestationChallenge(now.toString().toByteArray()) if (Build.VERSION.SDK_INT \u003e= Build.VERSION_CODES.P \u0026\u0026 useStrongBox) { builder.setIsStrongBoxBacked(true) } if (Build.VERSION.SDK_INT \u003e= Build.VERSION_CODES.S) { if (includeProps) { builder.setDevicePropertiesAttestationIncluded(true) } if (attestKey) { builder.setCertificateSubject(X500Principal(\"CN=App Attest Key\")) } else { builder.setAttestKeyAlias(attestKeyAlias) } } // 获取 KeyPairGenerator 实例 val keyPairGenerator = KeyPairGenerator.getInstance( KeyProperties.KEY_ALGORITHM_EC, \"AndroidKeyStore\") // 用 KeyGenParameterSpec 初始化 KeyPairGenerator keyPairGenerator.initialize(builder.build()) // 生成密钥对 keyPairGenerator.generateKeyPair() } 此时，KeyStore中包含了名称为alias的密钥对 2.3 certs collect val certChain = keyStore.getCertificateChain(alias) ?: throw CertificateException(\"Unable to get certificate chain\") for (cert in certChain) { val buf = ByteArrayInputStream(cert.encoded) certs.add(certificateFactory.generateCertificate(buf)) } if (useAttestKey) { val persistChain = keyStore.getCertificateChain(attestKeyAlias) ?: throw CertificateException(\"Unable to get certificate chain\") for (cert in persistChain) { val buf = ByteArrayInputStream(cert.encoded) certs.add(certificateFactory.generateCertificate(buf)) } } 在上一步生成key之后根据alias获取到对应的证书链，证书链是一个认证过程，最终指向可信的根证书，因此获取到的证书链实际的形式是 终端证书-\u003e中间证书-\u003e根证书 2.4 parseCertificateC","date":"2024-08-30","objectID":"/posts/keyattestation%E5%8E%9F%E7%90%86%E7%90%86%E8%A7%A3/:0:2","tags":["KeyAttestation"],"title":"KeyAttestation原理理解","uri":"/posts/keyattestation%E5%8E%9F%E7%90%86%E7%90%86%E8%A7%A3/"},{"categories":["设备异常性检测"],"content":"三. 总结 可以利用KeyAttestation来做什么呢？ 验证密钥可信性 密钥认证用于验证设备上的密钥是否由可信的安全硬件生成。通过密钥认证，App可以确保密钥没有被复制或篡改，并且确实是在受信任的环境中创建的 设备身份和完整性验证 密钥认证可以用于验证设备的身份和完整性。通过认证过程中提供的证明数据（比如设备标识符、硬件特性等），可以保证设备没有被篡改或替换 ","date":"2024-08-30","objectID":"/posts/keyattestation%E5%8E%9F%E7%90%86%E7%90%86%E8%A7%A3/:0:3","tags":["KeyAttestation"],"title":"KeyAttestation原理理解","uri":"/posts/keyattestation%E5%8E%9F%E7%90%86%E7%90%86%E8%A7%A3/"},{"categories":["Linux内核"],"content":"之前在分析其他安全厂商App的防护策略时，想要设计个风控分析沙盒来实现对于App行为的全面监控，包括 App访问、操作了哪些文件 执行了哪些操作 对于相关操作进行针对性的修改等等 其中很棘手的问题在于如何应对App中越来越常见的内联系统调用，对于内联系统调用的监控我不希望通过ptrace这类进程注入的方式来实现，而是想寻求通过定制系统或者相关的方式来实现以达到无侵入App的目的 另一方面来说，通过定制系统的方式完成相关系统函数的修改确实是一种方式，但是定制系统在生产环境使用中会存在两个问题： 调试测试：通常流程上都是相关函数修改-\u003e编译内核-\u003e借助AnyKernel3或者Android_boot_image_editor等工具完成boot.img重打包-\u003e刷入这些步骤，整体测试流程还是很繁琐的，其中还可能遇到代码bug导致系统无法启动等棘手问题，这些都对于实际开发来说很是崩溃 线上部署：和App一样，当本地测试好的内核遇到线上环境时可能会出现各式各样的问题，包括内核更新失败、内核文件传输、下载失败等等问题，直接导致系统无法启动，需要人工修复，想象下部署在遥远郊区的大规模设备集群大批量系统无法启动的场景，要靠人工一一修复是什么体验 综上，最最贴合真实场景的是一种无侵入App且不阻断内核启动的方案，经过一顿搜索，最终定位到了Linux Kprobe这类内核监控方案 第一次了解到kprobe技术是在evilpan的文章Linux 内核监控在 Android 攻防中的应用 中，在现有的内核监控方案中分为数据、采集、前端三个层级 而作为最底层的数据来源，kprobe、uprobe等是我们在做内核监控时需要重点关注的点，相比较于其他几种实现方式，kprobe无论从可扩展性、影响范围上都是最适合做二次开发的，参考作者给出的对比表 监控方案 静态 动态 内核 用户 Kprobes ✔ ✔ Uprobes ✔ ✔ Tracepoints ✔ ✔ USDT ✔ ✔ 因此最终确定了使用Linux Kprobe来作为内核系统函数的监控方案 ","date":"2024-04-26","objectID":"/posts/linux-kprobe%E5%8E%9F%E7%90%86%E6%8E%A2%E7%A9%B6/:0:0","tags":["源码分析"],"title":"Linux Kprobe原理探究","uri":"/posts/linux-kprobe%E5%8E%9F%E7%90%86%E6%8E%A2%E7%A9%B6/"},{"categories":["Linux内核"],"content":"一、Kprobe基本知识 kprobe可以认为是一种kernel hook手段，它基于内核中断的方式实现，可以想象它是内核层的异常hook（参考SandHook），既然是异常hook，那么它所能hook的范围就没有限制了，可以针对函数、也可以针对单条指令 简单理解就是把指定地址的指令替换成一个可以让cpu进入debug模式的指令（不同架构上指令不同），跳转到probe处理函数上进行数据收集、修改，再跳转回来继续执行 X86中使用的是int3指令，ARM64中使用的是BRK指令进入debug monitor模式 参考HPYU的Kprobe执行流程示意图 ","date":"2024-04-26","objectID":"/posts/linux-kprobe%E5%8E%9F%E7%90%86%E6%8E%A2%E7%A9%B6/:0:1","tags":["源码分析"],"title":"Linux Kprobe原理探究","uri":"/posts/linux-kprobe%E5%8E%9F%E7%90%86%E6%8E%A2%E7%A9%B6/"},{"categories":["Linux内核"],"content":"二、使用 kprobe主要有两种使用方法，一是通过模块加载；二是通过debugfs接口。从可扩展性和工程化的角度来看，模块加载是更优的选择，debugfs在某些特殊场景下（快速验证某些函数）可能会适合 基于内核模块加载 首先了解下动态内核模块（Loadable kernel module），LKM可以看出是内核向外提供的一个接口，通常是我们基于已编译好的内核产物+自定义的模块代码编译得到的ko文件，通过insmod的方式来实现动态新增定制功能，这种做法的好处是无需修改内核，需要新增功能时只需要变动相关LKM即可，它的作用域和静态编译的内核其他模块是完全等价的，而缺点是会带来些许性能上的损失，不过相比易用性来说这点可以忽略不计 2.1 案例 参考Linux源码下的samples/kprobes，里面包含kprobe、kretprobe等案例 // samples/kprobes/kprobe_example.c #include \u003clinux/kernel.h\u003e #include \u003clinux/module.h\u003e #include \u003clinux/kprobes.h\u003e /* For each probe you need to allocate a kprobe structure */ static struct kprobe kp = { .symbol_name = \"_do_fork\", }; /* kprobe pre_handler: called just before the probed instruction is executed */ static int handler_pre(struct kprobe *p, struct pt_regs *regs) { #ifdef CONFIG_X86 printk(KERN_INFO \"pre_handler: p-\u003eaddr = 0x%p, ip = %lx,\" \" flags = 0x%lx\\n\", p-\u003eaddr, regs-\u003eip, regs-\u003eflags); #endif #ifdef CONFIG_PPC printk(KERN_INFO \"pre_handler: p-\u003eaddr = 0x%p, nip = 0x%lx,\" \" msr = 0x%lx\\n\", p-\u003eaddr, regs-\u003enip, regs-\u003emsr); #endif #ifdef CONFIG_MIPS printk(KERN_INFO \"pre_handler: p-\u003eaddr = 0x%p, epc = 0x%lx,\" \" status = 0x%lx\\n\", p-\u003eaddr, regs-\u003ecp0_epc, regs-\u003ecp0_status); #endif #ifdef CONFIG_TILEGX printk(KERN_INFO \"pre_handler: p-\u003eaddr = 0x%p, pc = 0x%lx,\" \" ex1 = 0x%lx\\n\", p-\u003eaddr, regs-\u003epc, regs-\u003eex1); #endif /* A dump_stack() here will give a stack backtrace */ return 0; } /* kprobe post_handler: called after the probed instruction is executed */ static void handler_post(struct kprobe *p, struct pt_regs *regs, unsigned long flags) { #ifdef CONFIG_X86 printk(KERN_INFO \"post_handler: p-\u003eaddr = 0x%p, flags = 0x%lx\\n\", p-\u003eaddr, regs-\u003eflags); #endif #ifdef CONFIG_PPC printk(KERN_INFO \"post_handler: p-\u003eaddr = 0x%p, msr = 0x%lx\\n\", p-\u003eaddr, regs-\u003emsr); #endif #ifdef CONFIG_MIPS printk(KERN_INFO \"post_handler: p-\u003eaddr = 0x%p, status = 0x%lx\\n\", p-\u003eaddr, regs-\u003ecp0_status); #endif #ifdef CONFIG_TILEGX printk(KERN_INFO \"post_handler: p-\u003eaddr = 0x%p, ex1 = 0x%lx\\n\", p-\u003eaddr, regs-\u003eex1); #endif } /* * fault_handler: this is called if an exception is generated for any * instruction within the pre- or post-handler, or when Kprobes * single-steps the probed instruction. */ static int handler_fault(struct kprobe *p, struct pt_regs *regs, int trapnr) { printk(KERN_INFO \"fault_handler: p-\u003eaddr = 0x%p, trap #%dn\", p-\u003eaddr, trapnr); /* Return 0 because we don't handle the fault. */ return 0; } static int __init kprobe_init(void) { int ret; kp.pre_handler = handler_pre; kp.post_handler = handler_post; kp.fault_handler = handler_fault; ret = register_kprobe(\u0026kp); if (ret \u003c 0) { printk(KERN_INFO \"register_kprobe failed, returned %d\\n\", ret); return ret; } printk(KERN_INFO \"Planted kprobe at %p\\n\", kp.addr); return 0; } static void __exit kprobe_exit(void) { unregister_kprobe(\u0026kp); printk(KERN_INFO \"kprobe at %p unregistered\\n\", kp.addr); } module_init(kprobe_init) module_exit(kprobe_exit) MODULE_LICENSE(\"GPL\"); // include/linux/kprobes.h struct kprobe { // 所有注册过的kprobe都会加入到kprobe_table哈希表中，hlist指向哈希表的位置 struct hlist_node hlist; /* list of kprobes for multi-handler support */ struct list_head list; /*count the number of times this probe was temporarily disarmed */ unsigned long nmissed; /* location of the probe point */ kprobe_opcode_t *addr; /* Allow user to indicate symbol name of the probe point */ // 地址和name不能同时出现，之前提过kprobe可以hook函数和地址 const char *symbol_name; /* Offset into the symbol */ unsigned int offset; /* Called before addr is executed. */ // 在单步执行原始指令前被调用 kprobe_pre_handler_t pre_handler; /* Called after addr is executed, unless... */ // 在单步执行原始指令后被调用 kprobe_post_handler_t post_handler; /* Saved opcode (which has been replaced with breakpoint) */ kprobe_opcode_t opcode; // 保存平台相关的被探测指令和下一条指令 /* copy of the original instruction */ struct arch_specific_insn ainsn; /* * Indicates various status flags. * Protected by kprobe_mutex after this kprobe is registered. */ u32 flags; }; 整个案例可以拆分成几个部分来看 LKM的定义 一个完整的LKM包含module_init、module_exit、MODULE_LICENSE三个部分 modul","date":"2024-04-26","objectID":"/posts/linux-kprobe%E5%8E%9F%E7%90%86%E6%8E%A2%E7%A9%B6/:0:2","tags":["源码分析"],"title":"Linux Kprobe原理探究","uri":"/posts/linux-kprobe%E5%8E%9F%E7%90%86%E6%8E%A2%E7%A9%B6/"},{"categories":["Linux内核"],"content":"三、实现原理 首先我们从kprobe的起始点init_kprobe函数切入，由于各个架构的实现不同，下面以arm64为例 3.1 init_kprobes static int __init init_kprobes(void) { int i, err = 0; /* FIXME allocate the probe table, currently defined statically */ /* initialize all list heads */ //1. 初始化哈希表节点， 保存已注册的kprobe实例 for (i = 0; i \u003c KPROBE_TABLE_SIZE; i++) { INIT_HLIST_HEAD(\u0026kprobe_table[i]); ...... } ...... //2. 初始化kprobe黑名单(非__krpobe属性又不能被kprobe的函数) if (kretprobe_blacklist_size) { /* lookup the function address from its name */ for (i = 0; kretprobe_blacklist[i].name != NULL; i++) { kretprobe_blacklist[i].addr = kprobe_lookup_name(kretprobe_blacklist[i].name, 0); ..... } } ...... // 3. 架构相关的初始化，调用两个函数arm_kprobe_decode_init与register_undef_hook err = arch_init_kprobes(); if (!err) // 4. 注册die通知链 err = register_die_notifier(\u0026kprobe_exceptions_nb); if (!err) // 5. 注册模块通知链 err = register_module_notifier(\u0026kprobe_module_nb); kprobes_initialized = (err == 0); if (!err) init_test_probes(); return err; } // arch/arm/probes/kprobes/core.c int __init arch_init_kprobes() { return 0; } 3.1 kprobe manager init_kprobes的第一步是初始化哈希表，这里的哈希表指代的就是管理kprobe实例 // kernel/kprobes.c static struct hlist_head kprobe_table[KPROBE_TABLE_SIZE]; for (i = 0; i \u003c KPROBE_TABLE_SIZE; i++) { INIT_HLIST_HEAD(\u0026kprobe_table[i]); ...... } struct kprobe *get_kprobe(void *addr) { struct hlist_head *head; struct kprobe *p; // 定位槽所对应的头结点 head = \u0026kprobe_table[hash_ptr(addr, KPROBE_HASH_BITS)]; // 遍历链表，hlist指的是kprobe的hlist_node hlist_for_each_entry_rcu(p, head, hlist) { if (p-\u003eaddr == addr) return p; } return NULL; } KPROBE_TABLE_SIZE是64，对于每个槽初始化一个头结点 kprobe table的形式参考下图 以hook的address为key，将kprobe保存到哈希表中，后续在查找时可以通过address来快速定位到kprobe_table槽，再通过对比hlist_node来确定kprobe 3.1 register_die_notifier static struct notifier_block kprobe_exceptions_nb = { .notifier_call = kprobe_exceptions_notify, .priority = 0x7fffffff /* we need to be notified first */ }; int __kprobes kprobe_exceptions_notify(struct notifier_block *self, unsigned long val, void *data) { struct die_args *args = data; unsigned long addr = args-\u003eerr; int ret = NOTIFY_DONE; switch (val) { case DIE_IERR: if (arc_kprobe_handler(addr, args-\u003eregs)) return NOTIFY_STOP; break; case DIE_TRAP: if (arc_post_kprobe_handler(addr, args-\u003eregs)) return NOTIFY_STOP; break; default: break; } return ret; } 注册了kprobe_exceptions_notify函数作为回调函数，暂时不知道什么时候会出发die链的回调函数，先接着往下看 3.2 register_module_notifier static struct notifier_block kprobe_module_nb = { .notifier_call = kprobes_module_callback, .priority = 0 }; /* Module notifier call back, checking kprobes on the module */ static int kprobes_module_callback(struct notifier_block *nb, unsigned long val, void *data) { struct module *mod = data; struct hlist_head *head; struct kprobe *p; unsigned int i; int checkcore = (val == MODULE_STATE_GOING); if (val != MODULE_STATE_GOING \u0026\u0026 val != MODULE_STATE_LIVE) return NOTIFY_DONE; /* * When MODULE_STATE_GOING was notified, both of module .text and * .init.text sections would be freed. When MODULE_STATE_LIVE was * notified, only .init.text section would be freed. We need to * disable kprobes which have been inserted in the sections. */ mutex_lock(\u0026kprobe_mutex); for (i = 0; i \u003c KPROBE_TABLE_SIZE; i++) { head = \u0026kprobe_table[i]; hlist_for_each_entry_rcu(p, head, hlist) if (within_module_init((unsigned long)p-\u003eaddr, mod) || (checkcore \u0026\u0026 within_module_core((unsigned long)p-\u003eaddr, mod))) { /* * The vaddr this probe is installed will soon * be vfreed buy not synced to disk. Hence, * disarming the breakpoint isn't needed. * * Note, this will also move any optimized probes * that are pending to be removed from their * corresponding lists to the freeing_list and * will not be touched by the delayed * kprobe_optimizer work handler. */ kill_kprobe(p); } } mutex_unlock(\u0026kprobe_mutex); return NOTIFY_DONE; } 3.3 小结 init_kprobes主要做了5件事 初始化哈希表节点， 保存已注册的kprobe实例 初始化kprobe黑名单(非__krpobe属性又不能被kprobe的函数) 架构相关的初始化，在arm64上无操作 注册die通知链 回调函数kprobe_exceptions_notify，监听DIE_ERROR、DIE_TRAP 注册模块通知链 回调函数kprobes_module_callback 3.2 regi","date":"2024-04-26","objectID":"/posts/linux-kprobe%E5%8E%9F%E7%90%86%E6%8E%A2%E7%A9%B6/:0:3","tags":["源码分析"],"title":"Linux Kprobe原理探究","uri":"/posts/linux-kprobe%E5%8E%9F%E7%90%86%E6%8E%A2%E7%A9%B6/"},{"categories":["Linux内核"],"content":"参考 Linux 内核监控在 Android 攻防中的应用 深入ftrace kprobe原理解析 arm64-kprobes Kernel调试追踪技术之 Kprobe on ARM64 ","date":"2024-04-26","objectID":"/posts/linux-kprobe%E5%8E%9F%E7%90%86%E6%8E%A2%E7%A9%B6/:0:4","tags":["源码分析"],"title":"Linux Kprobe原理探究","uri":"/posts/linux-kprobe%E5%8E%9F%E7%90%86%E6%8E%A2%E7%A9%B6/"},{"categories":["系统定制"],"content":"一、背景 如上文Linux Kprobe原理探究 所提及的，Kprobe有多种玩法，在设备改机场景中可以通过对内核系统函数的篡改以完成改机的目的，本文就是基于Kernel Kprobe机制来搭建一套完整的改机架构 ","date":"2024-03-27","objectID":"/posts/%E5%9F%BA%E4%BA%8Ekernel-kprobe%E6%9C%BA%E5%88%B6%E7%9A%84%E6%94%B9%E6%9C%BA%E6%9E%B6%E6%9E%84%E5%AE%9E%E7%8E%B0/:0:1","tags":["内核编译","内核改机"],"title":"基于Kernel Kprobe机制的改机架构实现","uri":"/posts/%E5%9F%BA%E4%BA%8Ekernel-kprobe%E6%9C%BA%E5%88%B6%E7%9A%84%E6%94%B9%E6%9C%BA%E6%9E%B6%E6%9E%84%E5%AE%9E%E7%8E%B0/"},{"categories":["系统定制"],"content":"二、思路 从整体流程上看，Kprobe的实现是基于LKM的，那么编译方式、生效时机、更新方式都需要参考LKM的做法 ","date":"2024-03-27","objectID":"/posts/%E5%9F%BA%E4%BA%8Ekernel-kprobe%E6%9C%BA%E5%88%B6%E7%9A%84%E6%94%B9%E6%9C%BA%E6%9E%B6%E6%9E%84%E5%AE%9E%E7%8E%B0/:0:2","tags":["内核编译","内核改机"],"title":"基于Kernel Kprobe机制的改机架构实现","uri":"/posts/%E5%9F%BA%E4%BA%8Ekernel-kprobe%E6%9C%BA%E5%88%B6%E7%9A%84%E6%94%B9%E6%9C%BA%E6%9E%B6%E6%9E%84%E5%AE%9E%E7%8E%B0/"},{"categories":["系统定制"],"content":"三、具体执行 3.1 LKM编译 3.2 patch init.rc 3.3 insmod ko ","date":"2024-03-27","objectID":"/posts/%E5%9F%BA%E4%BA%8Ekernel-kprobe%E6%9C%BA%E5%88%B6%E7%9A%84%E6%94%B9%E6%9C%BA%E6%9E%B6%E6%9E%84%E5%AE%9E%E7%8E%B0/:0:3","tags":["内核编译","内核改机"],"title":"基于Kernel Kprobe机制的改机架构实现","uri":"/posts/%E5%9F%BA%E4%BA%8Ekernel-kprobe%E6%9C%BA%E5%88%B6%E7%9A%84%E6%94%B9%E6%9C%BA%E6%9E%B6%E6%9E%84%E5%AE%9E%E7%8E%B0/"},{"categories":["Hook框架学习"],"content":"LSPlant是LSPosed官方推出的新的ART hook框架，用来替代LSPosed之前使用的YAHFA框架 从官方README上看，对于LSPlant的使用分为几种 Init LSPlant within JNI_OnLoad（在JNI_OnLoad时初始化LSPlant） bool Init(JNIEnv *env, const InitInfo \u0026info); Hook jobject Hook(JNIEnv *env, jobject target_method, jobject hooker_object, jobject callback_method); 这里存在三个入参，分别是目标方法、上下文、回调方法 Check bool IsHooked(JNIEnv *env, jobject method); Unhook bool UnHook(JNIEnv *env, jobject target_method); Deoptimize bool Deoptimize(JNIEnv *env, jobject method); 防止某些短函数被内联导致hook失效 ","date":"2024-03-07","objectID":"/posts/lsplant%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/:0:0","tags":["源码分析"],"title":"LSPlant源码学习","uri":"/posts/lsplant%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/"},{"categories":["Hook框架学习"],"content":"一、LSPlant框架初始化 lsplant的函数都实现在lsplant.cc中，看下init函数 // lsplant\\src\\main\\jni\\lsplant.cc [[maybe_unused]] bool Init(JNIEnv *env, const InitInfo \u0026info) { bool static kInit = InitConfig(info) \u0026\u0026 InitJNI(env) \u0026\u0026 InitNative(env, info); return kInit; } 以三个子流程的初始化状态来判断框架的状态 1.1 InitConfig bool InitConfig(const InitInfo \u0026info) { if (info.generated_class_name.empty()) { LOGE(\"generated class name cannot be empty\"); return false; } generated_class_name = info.generated_class_name; if (info.generated_field_name.empty()) { LOGE(\"generated field name cannot be empty\"); return false; } generated_field_name = info.generated_field_name; if (info.generated_method_name.empty()) { LOGE(\"generated method name cannot be empty\"); return false; } generated_method_name = info.generated_method_name; generated_source_name = info.generated_source_name; return true; } 这里说明入参必须要参照结构体InitInfo，需要配置的generated_class_name、generated_field_name、generated_method_name等字段 struct InitInfo { /// \\brief Type of inline hook function. /// In \\ref std::function form so that user can use lambda expression with capture list.\u003cbr\u003e /// \\p target is the target function to be hooked.\u003cbr\u003e /// \\p hooker is the hooker function to replace the \\p target function.\u003cbr\u003e /// \\p return is the backup function that points to the previous target function. /// it should return null if hook fails and nonnull if successes. using InlineHookFunType = std::function\u003cvoid *(void *target, void *hooker)\u003e; /// \\brief Type of inline unhook function. /// In \\ref std::function form so that user can use lambda expression with capture list.\u003cbr\u003e /// \\p func is the target function that is previously hooked.\u003cbr\u003e /// \\p return should indicate the status of unhooking.\u003cbr\u003e using InlineUnhookFunType = std::function\u003cbool(void *func)\u003e; /// \\brief Type of symbol resolver to \\p libart.so. /// In \\ref std::function form so that user can use lambda expression with capture list.\u003cbr\u003e /// \\p symbol_name is the symbol name that needs to retrieve.\u003cbr\u003e /// \\p return is the absolute address in the memory that points to the target symbol. It should /// be null if the symbol cannot be found. \u003cbr\u003e /// \\note It should be able to resolve symbols from both .dynsym and .symtab. using ArtSymbolResolver = std::function\u003cvoid *(std::string_view symbol_name)\u003e; using ArtSymbolPrefixResolver = std::function\u003cvoid *(std::string_view symbol_prefix)\u003e; /// \\brief The inline hooker function. Must not be null. InlineHookFunType inline_hooker; /// \\brief The inline unhooker function. Must not be null. InlineUnhookFunType inline_unhooker; /// \\brief The symbol resolver to \\p libart.so. Must not be null. ArtSymbolResolver art_symbol_resolver; /// \\brief The symbol prefix resolver to \\p libart.so. May be null. ArtSymbolPrefixResolver art_symbol_prefix_resolver; /// \\brief The generated class name. Must not be empty. It contains a field and a method /// and they could be set by \\p generated_field_name and \\p generated_method_name respectively. std::string_view generated_class_name = \"LSPHooker_\"; /// \\brief The generated source name. Could be empty. std::string_view generated_source_name = \"LSP\"; /// \\brief The generated field name. Must not be empty. std::string_view generated_field_name = \"hooker\"; /// \\brief The generated class name. Must not be emtpy. If {target} is set, /// it will follows the name of the target. std::string_view generated_method_name = \"{target}\"; }; 可以看到name相关的字段都是默认的，因此可以不关注，最主要需要配置的是art_symbol_resolver、art_symbol_prefix_resolver这两个对于libart.so的hook，参考LSPosed的使用 void MagiskLoader::OnNativeForkAndSpecializePost(JNIEnv *env, jstring nice_name, jstring app_dir) { const JUTFString process_name(env, nice_name); auto *instance = Service::instance(); auto binder = skip_ ? ScopedLocalRef\u003cjobject\u003e{env, nullptr} : instance-\u003eRequestBinder(env, nice_name); if (binder) { lsplant::InitInfo initInfo{ .inline_hooker = [](auto t, auto r) { void* bk = nullptr; return HookFunction(t, r, \u0026bk) == RS_SUCCESS ? bk : nullptr; }, .inline_unhooker = [](aut","date":"2024-03-07","objectID":"/posts/lsplant%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/:0:1","tags":["源码分析"],"title":"LSPlant源码学习","uri":"/posts/lsplant%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/"},{"categories":["Hook框架学习"],"content":"二、LSPlant ART hook原理 [[maybe_unused]] jobject Hook(JNIEnv *env, jobject target_method, jobject hooker_object, jobject callback_method) { ...... jmethodID hook_method = nullptr; jmethodID backup_method = nullptr; jfieldID hooker_field = nullptr; auto target_class = JNI_Cast\u003cjclass\u003e(JNI_CallObjectMethod(env, target_method, method_get_declaring_class)); constexpr static uint32_t kAccClassIsProxy = 0x00040000; bool is_proxy = JNI_GetIntField(env, target_class, class_access_flags) \u0026 kAccClassIsProxy; auto *target = ArtMethod::FromReflectedMethod(env, target_method); bool is_static = target-\u003eIsStatic(); // 避免重复hook if (IsHooked(target, true)) { LOGW(\"Skip duplicate hook\"); return nullptr; } ScopedLocalRef\u003cjclass\u003e built_class{env}; { auto callback_name = JNI_Cast\u003cjstring\u003e(JNI_CallObjectMethod(env, callback_method, method_get_name)); JUTFString callback_method_name(callback_name); auto target_name = JNI_Cast\u003cjstring\u003e(JNI_CallObjectMethod(env, target_method, method_get_name)); JUTFString target_method_name(target_name); auto callback_class = JNI_Cast\u003cjclass\u003e( JNI_CallObjectMethod(env, callback_method, method_get_declaring_class)); auto callback_class_loader = JNI_CallObjectMethod(env, callback_class, class_get_class_loader); auto callback_class_name = JNI_Cast\u003cjstring\u003e(JNI_CallObjectMethod(env, callback_class, class_get_name)); JUTFString class_name(callback_class_name); if (!JNI_IsInstanceOf(env, hooker_object, callback_class)) { LOGE(\"callback_method is not a method of hooker_object\"); return nullptr; } std::tie(built_class, hooker_field, hook_method, backup_method) = WrapScope( env, BuildDex(env, callback_class_loader, __builtin_expect(is_proxy, 0) ? GetProxyMethodShorty(env, target_method) : ArtMethod::GetMethodShorty(env, target_method), is_static, target-\u003eIsConstructor() ? \"constructor\" : target_method_name.get(), class_name.get(), callback_method_name.get())); if (!built_class || !hooker_field || !hook_method || !backup_method) { LOGE(\"Failed to generate hooker\"); return nullptr; } } auto reflected_hook = JNI_ToReflectedMethod(env, built_class, hook_method, is_static); auto reflected_backup = JNI_ToReflectedMethod(env, built_class, backup_method, is_static); JNI_CallVoidMethod(env, reflected_backup, set_accessible, JNI_TRUE); auto *hook = ArtMethod::FromReflectedMethod(env, reflected_hook); auto *backup = ArtMethod::FromReflectedMethod(env, reflected_backup); JNI_SetStaticObjectField(env, built_class, hooker_field, hooker_object); if (DoHook(target, hook, backup)) { std::apply( [backup_method, target_method_id = env-\u003eFromReflectedMethod(target_method)](auto... v) { ((*v == target_method_id \u0026\u0026 (LOGD(\"Propagate internal used method because of hook\"), *v = backup_method)) || ...); }, kInternalMethods); jobject global_backup = JNI_NewGlobalRef(env, reflected_backup); RecordHooked(target, target-\u003eGetDeclaringClass()-\u003eGetClassDef(), global_backup, backup); if (!is_proxy) [[likely]] { RecordJitMovement(target, backup); } // Always record backup as deoptimized since we dont want its entrypoint to be updated // by FixupStaticTrampolines on hooker class // Used hook's declaring class here since backup's is no longer the same with hook's RecordDeoptimized(hook-\u003eGetDeclaringClass()-\u003eGetClassDef(), backup); return global_backup; } return nullptr; } 核心函数DoHook bool DoHook(ArtMethod *target, ArtMethod *hook, ArtMethod *backup) { ScopedGCCriticalSection section(art::Thread::Current(), art::gc::kGcCauseDebugger, art::gc::kCollectorTypeDebugger); ScopedSuspendAll suspend(\"LSPlant Hook\", false); LOGV(\"Hooking: target = %s(%p), hook = %s(%p), backup = %s(%p)\", target-\u003ePrettyMethod().c_str(), target, hook-\u003ePrettyMethod().c_str(), hook, backup-\u003ePrettyMethod().c_str(), backup); // 为hook函数生成trampoline if (auto *entrypoint = GenerateTrampolineFor(hook); !entrypoint) { LOGE(\"Failed to generate trampoline\"); return false; // NOLINTNEXTLINE } else { LOGV(\"Generated trampoline %p\", entrypoint); target-\u003eSetNonCompilable(); hook-\u003eSetNonCompilable(); // copy a","date":"2024-03-07","objectID":"/posts/lsplant%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/:0:2","tags":["源码分析"],"title":"LSPlant源码学习","uri":"/posts/lsplant%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/"},{"categories":["Hook框架学习"],"content":"参考 ART hook 框架 - YAHFA 源码分析 ART上的动态Java方法hook框架 ","date":"2024-03-07","objectID":"/posts/lsplant%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/:0:3","tags":["源码分析"],"title":"LSPlant源码学习","uri":"/posts/lsplant%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/"},{"categories":["Magisk"],"content":"隔了很久再读Magisk源码中关于Zygisk的部分，上次翻源码还是v25.0，这次已经更新到了v27.0。粗略扫了眼，变化的地方还是挺多的，想搜索一下关键字也基本上搜索不到，懒得重新过一遍源码，既然是关于zygisk，那就以(zygisk_enabled)作为关键搜索词切入 void load_modules() { ...... if (zygisk_enabled) { string native_bridge_orig = get_prop(NBPROP); if (native_bridge_orig.empty()) { native_bridge_orig = \"0\"; } native_bridge = native_bridge_orig != \"0\" ? ZYGISKLDR + native_bridge_orig : ZYGISKLDR; set_prop(NBPROP, native_bridge.data()); // Weather Huawei's Maple compiler is enabled. // If so, system server will be created by a special Zygote which ignores the native bridge // and make system server out of our control. Avoid it by disabling. if (get_prop(\"ro.maple.enable\") == \"1\") { set_prop(\"ro.maple.enable\", \"0\"); } inject_zygisk_libs(system); } ...... } 定位到load_modules函数，发现这里竟然使用了native_bridge_orig，对应的变量名也做了个效果，NBPROP？ #define NBPROP \"ro.dalvik.vm.native.bridge\" 这是也要仿照riru了吗？ ","date":"2024-03-06","objectID":"/posts/zygisk-v27.0%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/:0:0","tags":["源码分析","zygisk"],"title":"Zygisk-v27.0源码阅读","uri":"/posts/zygisk-v27.0%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/"},{"categories":["Magisk"],"content":"一、Zygisk注入方式改变 继续load_modules，ZYGISKLDR对应的是libzygisk.so，也就是src/core/zygisk目录，从之前的riru原理理解这篇文章中，已经知道对于native_bridge的使用大概流程如下 调用LoadNativeBridge函数 dlopen native_bridge对应的so动态库 dlsym kNativeBridgeInterfaceSymbol获取callbacks，kNativeBridgeInterfaceSymbol的值是NativeBridgeItf 调用isCompatibleWith处理 对应的看下Zygisk相对应的实现 // src/core/zygisk/entry.cpp extern \"C\" [[maybe_unused]] NativeBridgeCallbacks NativeBridgeItf{ .version = 2, .padding = {}, .isCompatibleWith = \u0026is_compatible_with, }; static bool is_compatible_with(uint32_t) { zygisk_logging(); hook_functions(); ZLOGD(\"load success\\n\"); return false; } 这里注意两点： hook_functions根据之前版本的的Zygisk实现来看，应该就是JNI hook的地方 既然是JNI hook，那么表明Zygisk并没有像riru那样存在中转的riruloader.so，相当于直接调用了riru.so // src/core/zygisk/hook.cpp void hook_functions() { default_new(g_hook); g_hook-\u003ehook_plt(); } void HookContext::hook_plt() { ino_t android_runtime_inode = 0; dev_t android_runtime_dev = 0; ino_t native_bridge_inode = 0; dev_t native_bridge_dev = 0; for (auto \u0026map : lsplt::MapInfo::Scan()) { if (map.path.ends_with(\"/libandroid_runtime.so\")) { android_runtime_inode = map.inode; android_runtime_dev = map.dev; } else if (map.path.ends_with(\"/libnativebridge.so\")) { native_bridge_inode = map.inode; native_bridge_dev = map.dev; } } PLT_HOOK_REGISTER(native_bridge_dev, native_bridge_inode, dlclose); PLT_HOOK_REGISTER(android_runtime_dev, android_runtime_inode, fork); PLT_HOOK_REGISTER(android_runtime_dev, android_runtime_inode, unshare); PLT_HOOK_REGISTER(android_runtime_dev, android_runtime_inode, androidSetCreateThreadFunc); PLT_HOOK_REGISTER(android_runtime_dev, android_runtime_inode, selinux_android_setcontext); PLT_HOOK_REGISTER_SYM(android_runtime_dev, android_runtime_inode, \"__android_log_close\", android_log_close); if (!lsplt::CommitHook()) ZLOGE(\"plt_hook failed\\n\"); // Remove unhooked methods plt_backup.erase( std::remove_if(plt_backup.begin(), plt_backup.end(), [](auto \u0026t) { return *std::get\u003c3\u003e(t) == nullptr;}), g_hook-\u003eplt_backup.end()); } 替换了XHOOK框架使用了自己实现的PLT_HOOK，对应的这个项目LSPlt fork机制和之前是相同的，提前fork unshare对于新的namespace划分时unmount掉其中的Magisk特征 androidSetCreateThreadFunc DCL_HOOK_FUNC(static void, androidSetCreateThreadFunc, void *func) { ZLOGD(\"androidSetCreateThreadFunc\\n\"); g_hook-\u003ehook_jni_env(); old_androidSetCreateThreadFunc(func); } void HookContext::hook_jni_env() { using method_sig = jint(*)(JavaVM **, jsize, jsize *); auto get_created_vms = reinterpret_cast\u003cmethod_sig\u003e( dlsym(RTLD_DEFAULT, \"JNI_GetCreatedJavaVMs\")); if (!get_created_vms) { for (auto \u0026map: lsplt::MapInfo::Scan()) { if (!map.path.ends_with(\"/libnativehelper.so\")) continue; void *h = dlopen(map.path.data(), RTLD_LAZY); if (!h) { ZLOGW(\"Cannot dlopen libnativehelper.so: %s\\n\", dlerror()); break; } get_created_vms = reinterpret_cast\u003cmethod_sig\u003e(dlsym(h, \"JNI_GetCreatedJavaVMs\")); dlclose(h); break; } if (!get_created_vms) { ZLOGW(\"JNI_GetCreatedJavaVMs not found\\n\"); return; } } JavaVM *vm = nullptr; jsize num = 0; jint res = get_created_vms(\u0026vm, 1, \u0026num); if (res != JNI_OK || vm == nullptr) { ZLOGW(\"JavaVM not found\\n\"); return; } JNIEnv *env = nullptr; res = vm-\u003eGetEnv(reinterpret_cast\u003cvoid **\u003e(\u0026env), JNI_VERSION_1_6); if (res != JNI_OK || env == nullptr) { ZLOGW(\"JNIEnv not found\\n\"); return; } // Replace the function table in JNIEnv to hook RegisterNatives memcpy(\u0026new_env, env-\u003efunctions, sizeof(*env-\u003efunctions)); new_env.RegisterNatives = \u0026env_RegisterNatives; old_env = env-\u003efunctions; env-\u003efunctions = \u0026new_env; } static jint env_RegisterNatives( JNIEnv *env, jclass clazz, const JNINativeMethod *methods, jint numMethods) { auto className = get_class_name(env, clazz); if (className == \"com/android/internal/os/Zygote\") { // Restore JNIEnv as we no longer need to replace anything env-\u003efunctions = g_hook-\u003eold_env; vector\u003cJNINativeMethod\u003e newMethods(methods, methods + numMethods); vector\u003cJNINativeMethod\u003e \u0026backup = g_hook-\u003ejni_backup[className]; HOOK_JNI(nativeForkAndSpecialize); HOOK_JNI(nativeSpecializeAppProcess); HOOK_JNI(nativeForkSystemServer","date":"2024-03-06","objectID":"/posts/zygisk-v27.0%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/:0:1","tags":["源码分析","zygisk"],"title":"Zygisk-v27.0源码阅读","uri":"/posts/zygisk-v27.0%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/"},{"categories":["Magisk"],"content":"二、LD_PRELOAD其他的用处 Magisk团队找了更直接的方法来修改sepolicy，像他们在details.md所说的 ## Pre-Init `magiskinit` will replace `init` as the first program to run. - Early mount required partitions. On legacy system-as-root devices, we switch root to system; on 2SI devices, we patch the original `init` to redirect the 2nd stage init file to magiskinit and execute it to mount partitions for us. - Inject magisk services into `init.rc` - On devices using monolithic policy, load sepolicy from `/sepolicy`; otherwise we hijack nodes in selinuxfs with FIFO, set `LD_PRELOAD` to hook `security_load_policy` and assist hijacking on 2SI devices, and start a daemon to wait until init tries to load sepolicy. - Patch sepolicy rules. If we are using \"hijack\" method, load patched sepolicy into kernel, unblock init and exit daemon - Execute the original `init` to continue the boot process 使用LD_PRELOAD hook security_load_policy // src/init/selinux.cpp if (access(\"/system/bin/init\", F_OK) == 0) { // On 2SI devices, the 2nd stage init file is always a dynamic executable. // This meant that instead of going through convoluted methods trying to alter // and block init's control flow, we can just LD_PRELOAD and replace the // security_load_policy function with our own implementation. dump_preload(); setenv(\"LD_PRELOAD\", \"/dev/preload.so\", 1); } preload.so对应的是preload.c // src/init/preload.c static void preload_init() { // Make sure our next exec won't get bugged unsetenv(\"LD_PRELOAD\"); unlink(\"/dev/preload.so\"); } int security_load_policy(void *data, size_t len) { int (*load_policy)(void *, size_t) = dlsym(RTLD_NEXT, \"security_load_policy\"); // Skip checking errors, because if we cannot find the symbol, there // isn't much we can do other than crashing anyways. int result = load_policy(data, len); // Wait for ack int fd = open(\"/sys/fs/selinux/enforce\", O_RDONLY); char c; read(fd, \u0026c, 1); close(fd); return result; } 在使用monolithic策略的设备上，Magisk直接从/sepolicy文件中加载sepolicy规则。这个文件通常位于系统的根目录下，用于存储selinux策略。这种方式比较简单直接，不需要进行额外的hook操作 但是在其他的设备上，Magisk使用FIFO（命名管道）劫持selinuxfs中的节点，以实现selinux hook。具体来说，Magisk会创建一个FIFO文件，并挂载到selinuxfs中的\"load\"和\"enforce\"节点上，用于接收selinux策略和enforce值。这样一来，即使系统中没有/sepolicy文件，Magisk也可以通过劫持selinuxfs中的节点，来实现selinux hook 在2SI设备上，由于第二阶段的init文件是一个动态可执行文件，而不是静态的/init可执行文件，因此Magisk还需要协助劫持selinuxfs。具体来说，Magisk会在init进程启动之前，通过LD_PRELOAD的方式，将自己的preload.so库注入到init进程中，并替换security_load_policy函数为自己的实现，以实现selinux hook。后面Magisk启动守护程序，等待init进程尝试加载selinux策略文件。当init进程启动时，Magisk的钩子函数会拦截security_load_policy的调用，并将selinux策略文件和enforce值写入FIFO文件中，以实现自定义的selinux策略 ","date":"2024-03-06","objectID":"/posts/zygisk-v27.0%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/:0:2","tags":["源码分析","zygisk"],"title":"Zygisk-v27.0源码阅读","uri":"/posts/zygisk-v27.0%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/"},{"categories":["Android"],"content":"一、关于JavaVM Java是一门跨平台的语言，系统实际运行的是Java字节码，由Java虚拟机去解释执行。解释执行的过程可以看做是一个循环，对每条指令进行解析，并针对指令的名称通过巨大的switch-case分发到不同的分支中处理。Java虚拟机的原理就类似这样，但JVM对于性能做了很多优化，比如JIT运行时将字节码优化成对应平台的二进制代码，提高后续运行速度等 Android代码既然是用Java代码编写的，那么运行时应该也会有一个解析字节码的虚拟机。和标准的JVM不同，Android中实际会将Java代码编译为Dalvik字节码，运行时解析的也是用自研的虚拟机实现。之所以使用自研实现，也许一方面有商业版权的考虑，另一方面也确实是适应了移动端的的运行场景。Dalvik指令基于寄存器，占1-2字节，Java虚拟机指令基于栈，每条指令只占1字节；因此Dalvik虚拟机用空间换时间从而获得比OracleJVM更快的执行速度 1.1 VM启动 其实Java代码执行并不慢，但其启动时间却是一大瓶颈。如果每个APP运行都要启动并初始化Java虚拟机，那延时将是无法接受的。了解应用启动的流程的话，都知道APP应用进程实际上是通过zygote进程fork出来的，这样的好处是子进程继承了父进程的进程空间，对于只读部分可以直接使用，而数据段也可以通过COW(CopyOnWrite)进行延时映射。查看zygote与其子进程的/proc/self/maps可以发现大部分系统库的映射都是相同的，这就是fork所带来的好处 从zygote的启动流程上看 // cmds/app_process/app_main.cpp if (zygote) { runtime.start(\"com.android.internal.os.ZygoteInit\", args, zygote); } else if (className) { runtime.start(\"com.android.internal.os.RuntimeInit\", args, zygote); } else { fprintf(stderr, \"Error: no class name or --zygote supplied.\\n\"); app_usage(); LOG_ALWAYS_FATAL(\"app_process: no class name or --zygote supplied.\"); } 上述代码在frameworks/base/cmds/app_process/app_main.cpp中，runtime.start的作用就是启动Java虚拟机并将执行流转交给对应的Java函数 void AndroidRuntime::start(const char* className, const Vector\u003cString8\u003e\u0026 options, bool zygote) { ...... /* start the virtual machine */ JniInvocation jni_invocation; jni_invocation.Init(NULL); JNIEnv* env; if (startVm(\u0026mJavaVM, \u0026env, zygote, primary_zygote) != 0) { return; } onVmCreated(env); /* * Register android functions. */ if (startReg(env) \u003c 0) { ALOGE(\"Unable to register all android natives\\n\"); return; } ...... /* * Start VM. This thread becomes the main thread of the VM, and will * not return until the VM exits. */ jclass startClass = env-\u003eFindClass(slashClassName); if (startClass == NULL) { ALOGE(\"JavaVM unable to locate class '%s'\\n\", slashClassName); /* keep going */ } else { jmethodID startMeth = env-\u003eGetStaticMethodID(startClass, \"main\", \"([Ljava/lang/String;)V\"); if (startMeth == NULL) { ALOGE(\"JavaVM unable to find main() in '%s'\\n\", className); /* keep going */ } else { env-\u003eCallStaticVoidMethod(startClass, startMeth, strArray); #if 0 if (env-\u003eExceptionCheck()) threadExitUncaughtException(env); #endif } } free(slashClassName); ALOGD(\"Shutting down VM\\n\"); if (mJavaVM-\u003eDetachCurrentThread() != JNI_OK) ALOGW(\"Warning: unable to detach main thread\\n\"); if (mJavaVM-\u003eDestroyJavaVM() != 0) ALOGW(\"Warning: VM did not shut down cleanly\\n\"); } 中间省略了一些错误处理代码，更加突出主要逻辑。其中: startVm负责创建Java虚拟机，可根据参数和属性值调整虚拟机的特性； startReg负责动态绑定一系列JNInative函数(使用JNIEnv-\u003eRegisterNatives来注册)； 调用对应Java类的主函数static void main(String[]args)。 根据代码逻辑，可以了解到主线程会启动VM，VM一旦启动后就不会返回直到VM销毁为止，因此可以知道Java虚拟机是在Zygote进程创建的，并由子进程继承，因此APP从zygote进程中fork启动后就无需再次启动Java虚拟机，而是复用原有的虚拟机执行轻量的初始化即可 1.2 VM对外接口 AndroidJava虚拟机包括早期的Dalvik虚拟机和当前的ART虚拟机，我们将其统称为Java虚拟机，因为对于应用程序而言应该是透明的，也就是说二者应该提供了统一的对外接口。 这个接口可以分为两部分，一部分是提供给Java应用的接口，即我们常见的JavaVM、JNIEnv结构体提供的诸如FindClass、GetMethodID、CallVoidMethod等接口；另一部分则是提供给系统开发者的接口，系统通过这些接口去初始化并创建虚拟机，从而使自身具备执行Java代码的功能。 JniInvocation.Init方法中即进行了第二部分接口的初始化操作，其中主要逻辑是根据系统属性persist.sys.dalvik.vm.lib.2来判断待加载的虚拟机动态库，Dalvik虚拟机对应的是libdvm，ART虚拟机对应的是libart，然后通过dlopen进行加载，并通过dlsym获取其中三个函数符号，作为抽象Java虚拟机的接口: JNI_GetDefaultJavaVMInitArgs:获取默认的JVM初始化参数； JNI_CreateJavaVM:创建Java虚拟机； JNI_GetCreatedJavaVMs:获取已经创建的Java虚拟机实例； 例如，在上述zygote的AndroidRuntime::startVm方法实现中，就是通过指定参数最终调用JNI_CreateJavaVM来完成Java虚拟机的创建工作。 通过这三个接口实现了对于不同Java虚拟机细节的隐藏，既可以用ART无缝替换Dalvik虚拟机，也可以在未来用某个新的虚拟机无缝替换掉ART虚拟机。 总的来说，Java虚拟机只在Zygote进程中创建一次，子进程通过fork获得虚拟机的一个副本，因此zygote才被称为所有Java进程的父进程；同时，也因为每个子进程拥有独立的虚拟机副本，所以某个进程的虚拟机崩溃后不影响其他进程，从而实现安全的运行时隔离 ","date":"2024-03-01","objectID":"/posts/art%E6%96%B9%E6%B3%95%E8%B0%83%E7%94%A8%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90/:0:1","tags":["源码分析"],"title":"Art方法调用流程分析","uri":"/posts/art%E6%96%B9%E6%B3%95%E8%B0%83%E7%94%A8%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90/"},{"categories":["Android"],"content":"二、ART ART全称为AndroidRuntime，是继Dalvik之后推出的高性能AndroidJava虚拟机。在本文中我们重点关注ART虚拟机执行Java代码的流程，在介绍ART的代码执行流程之前，我们需要先了解在ART中针对DEX的一系列提前优化方案，以及由此产生的各类中间文件 2.1 提前优化 在我们使用Android Studio编译应用时，实际上是通过Java编译器先将.java代码编译为对应的Java字节码，即.class类文件；然后用dx(在新版本中是d8)将Java字节码转换为Dalvik字节码，并将所有生成的类打包到统一的DEX文件中，最终和资源文件一起zip压缩为.apk文件 在安装用户的APK时，Android系统主要通过PacketManager对应用进行解包和安装。其中在处理DEX文件时候，会通过installd进程调用对应的二进制程序对字节码进行优化，这对于Dalvik虚拟机而言使用的是dexopt程序，而ART中使用的是dex2oat程序。 dexopt将dex文件优化为odex文件，即optimized-dex的缩写，其中包含的是优化后的Dalvik字节码，称为quickenddex；dex2oat基于LLVM，优化后生成的是对应平台的二进制代码，以oat格式保存，oat的全称为Ahead-Of-Time。oat文件实际上是以ELF格式进行存储的，并在其中oatdata段(section)包含了原始的DEX内容。 在Android8之后，将OAT文件一分为二，原oat仍然是ELF格式，但原始DEX文件内容被保存到了VDEX中，VDEX有其独立的文件格式。整体流程如下图所示: 如前文所言，Android实现了自己的Java虚拟机，这个虚拟机本身是用C/C实现的，其中的一些Java原语有对应的C类，比如 java.lang.Class 对应 art:🪞:Class java.lang.String 对应 art:🪞:String java.lang.reflect.Method 对应 art:🪞:Method 当创建一个Java对象时，内存中会创建对应的C对象并调用其构造函数，JVM管理者这些C对象的引用。为了加速启动过程，避免对这些常见类的初始化，Android使用了.art格式来保存这些C对象的实例，简单来说，art文件可以看做是一系列常用C对象的内存dump 不论是oat、vdex还是art，都是Android定义的内部文件格式，官方并不保证其兼容性，事实上在Android各个版本中这些文件格式都有不同程度的变化，这些变化是不反映在文档中的，只能通过代码去一窥究竟。因此对于这些文件格式我们现在只需要知道其大致作用，无需关心其实现细节 2.2 文件加载 APP最终在ActivityThread中完成Application的创建和初始化，最终调用Activity.onCreate进入视图组件的生命周期。但这里其实忽略了一个问题: APP的代码(DEX/OAT文件)是如何加载到进程中的？ 在Java中负责加载指定类的对象是ClassLoader，Android中也是类似，BaseDexClassLoader继承自ClassLoader类，实现了许多DEX相关的加载操作，其子类包括: DexClassLoader: 负责从 .jar 或者 .apk 中加载类； PathClassLoader: 负责从本地文件中初始化类加载器； InMemoryDexClassLoader: 从内存中初始化类加载器； 2.2.1 ClassLoader 以常见的PathClassLoader为例，其构造函数会调用父类的构造函数，整体调用链路简化如下表: new PathClassLoader new BaseDexClassLoader new DexPathList DexPathList.makeDexElements DexPathList.loadDexFile new DexFile DexFile.openDexFile DexFile.openDexFileNative DexFile_openDexFileNative OatFileManager::OpenDexFilesFromOat 在OpenDexFilesFromOat中执行了真正的代码加载工作，伪代码如下: std::vector\u003cstd::unique_ptr\u003cconst DexFile\u003e\u003e OatFileManager::OpenDexFilesFromOat() { std::vector\u003cstd::unique_ptr\u003cconst DexFile\u003e\u003e dex_files = OpenDexFilesFromOat_Impl(...); for (std::unique_ptr\u003cconst DexFile\u003e\u0026 dex_file : dex_files) { if (!dex_file-\u003eDisableWrite()) { error_msgs-\u003epush_back(\"Failed to make dex file \" + dex_file-\u003eGetLocation() + \" read-only\"); } } return dex_files; } 通过OpenDexFilesFromOat_Impl加载获取DexFile结构体数组，值得注意的是加载完DEX之后会将内存中的dex_file设置为不可写，当然目前还没有强制，但可见这是未来的趋势 继续看实现部分是如何加载Dex文件的 std::vector\u003cstd::unique_ptr\u003cconst DexFile\u003e\u003e OatFileManager::OpenDexFilesFromOat_Impl() { // Extract dex file headers from `dex_mem_maps`. const std::vector\u003cconst DexFile::Header*\u003e dex_headers = GetDexFileHeaders(dex_mem_maps); // Determine dex/vdex locations and the combined location checksum. std::string dex_location; std::string vdex_path; bool has_vdex = OatFileAssistant::AnonymousDexVdexLocation(dex_headers, kRuntimeISA, \u0026dex_location, \u0026vdex_path); if (has_vdex \u0026\u0026 OS::FileExists(vdex_path.c_str())) { vdex_file = VdexFile::Open(vdex_path, /* writable= */ false, /* low_4gb= */ false, /* unquicken= */ false, \u0026error_msg); } // Load dex files. Skip structural dex file verification if vdex was found // and dex checksums matched. std::vector\u003cstd::unique_ptr\u003cconst DexFile\u003e\u003e dex_files; for (size_t i = 0; i \u003c dex_mem_maps.size(); ++i) { static constexpr bool kVerifyChecksum = true; const ArtDexFileLoader dex_file_loader; std::unique_ptr\u003cconst DexFile\u003e dex_file(dex_file_loader.Open( DexFileLoader::GetMultiDexLocation(i, dex_location.c_str()), dex_headers[i]-\u003echecksum_, std::move(dex_mem_maps[i]), /* verify= */ (vdex_file == nullptr) \u0026\u0026 Runtime::Current()-\u003eIsVerificationEnabled(), kVerifyChecksum, \u0026error_msg)); if (dex_file != nullptr) { dex::tracking::RegisterDexFile(dex_file.get()); // Register for tracking. dex_files.push_back(std::move(dex_file)); } } // Initialize an OatFile instance backed by the loaded vdex. std::unique_ptr\u003cOatFile\u003e oat_file(OatFile::OpenFromVdex( MakeNonOwningPointerVector(dex_files), std::move(vdex_file), dex_location)); if (oat_file != nullptr) { VLOG(class_linker) \u003c\u003c \"Registering \" \u003c\u003c oat_file-\u003eGetLocation(); *out_oat_fi","date":"2024-03-01","objectID":"/posts/art%E6%96%B9%E6%B3%95%E8%B0%83%E7%94%A8%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90/:0:2","tags":["源码分析"],"title":"Art方法调用流程分析","uri":"/posts/art%E6%96%B9%E6%B3%95%E8%B0%83%E7%94%A8%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90/"},{"categories":["汇编基础"],"content":"https://blog.csdn.net/boildoctor/article/details/123402047 https://www.cnblogs.com/sky-heaven/p/15885335.html https://blog.csdn.net/boildoctor/article/details/123402047 https://www.jianshu.com/p/b6071091abdc https://blog.csdn.net/heshuangzong/article/details/126911474 ","date":"2024-02-27","objectID":"/posts/arm%E4%B8%8Earm64%E7%9A%84%E6%A0%88%E5%B9%B3%E8%A1%A1%E7%90%86%E8%A7%A3/:0:0","tags":["栈平衡"],"title":"Arm与Arm64的栈平衡理解","uri":"/posts/arm%E4%B8%8Earm64%E7%9A%84%E6%A0%88%E5%B9%B3%E8%A1%A1%E7%90%86%E8%A7%A3/"},{"categories":["Hook框架学习"],"content":"从上一篇Dobby的文章可以了解到Dobby对于inline hook的实现是通过替换origin method的前三行指令（前12个字节）来跳转到对应的trampoline上，那对于指令数少于三行的函数它是怎么做到inline hook的呢？从它的案例中可以发现 // examples/socket_example.cc __attribute__((constructor)) static void ctor() { logger_set_options(0, 0, 0, LOG_LEVEL_DEBUG, false, false); void *func = NULL; func_map = new std::map\u003cvoid *, const char *\u003e(); for (int i = 0; i \u003c sizeof(func_array) / sizeof(char *); ++i) { func = DobbySymbolResolver(NULL, func_array[i]); if (func == NULL) { INFO_LOG(\"func %s not resolve\", func_array[i]); continue; } func_map-\u003einsert(std::pair\u003cvoid *, const char *\u003e(func, func_array[i])); } for (auto iter = func_map-\u003ebegin(), e = func_map-\u003eend(); iter != e; iter++) { bool is_short = false; for (int i = 0; i \u003c sizeof(func_short_array) / sizeof(char *); ++i) { if (strcmp(func_short_array[i], iter-\u003esecond) == 0) { is_short = true; break; } } if (is_short) { dobby_enable_near_branch_trampoline(); DobbyInstrument(iter-\u003efirst, common_handler); dobby_disable_near_branch_trampoline(); } else { DobbyInstrument(iter-\u003efirst, common_handler); } } ...... } 在调用DobbyInstrument完成指令的hook时，判定accept函数为短函数，看下accept函数源码 .text:000000000001E024 accept ; DATA XREF: LOAD:0000000000003C68↑o .text:000000000001E024 ; __unwind { .text:000000000001E024 03 00 80 52 MOV W3, #0 .text:000000000001E028 D6 EA FF 17 B .accept4 .text:000000000001E028 ; } // starts at 1E024 函数只有两行代码，无法满足正常inline hook的要求，开启了near branch的模式 ","date":"2024-02-21","objectID":"/posts/dobby-%E7%9F%AD%E6%8C%87%E4%BB%A4hook%E6%96%B9%E5%BC%8F/:0:0","tags":["源码分析"],"title":"Dobby 短指令hook方式","uri":"/posts/dobby-%E7%9F%AD%E6%8C%87%E4%BB%A4hook%E6%96%B9%E5%BC%8F/"},{"categories":["Hook框架学习"],"content":"Dobby插件NearBranchTrampoline // source/InterceptRouting/RoutingPlugin/NearBranchTrampoline/NearBranchTrampoline.cc PUBLIC void dobby_enable_near_branch_trampoline() { RoutingPluginInterface *plugin = new NearBranchTrampolinePlugin; RoutingPluginManager::registerPlugin(\"near_branch_trampoline\", plugin); RoutingPluginManager::near_branch_trampoline = plugin; } 开启了near branch插件，于是在调用GenerateTrampolineBuffer时优先调用 // source/InterceptRouting/InterceptRouting.cpp bool InterceptRouting::GenerateTrampolineBuffer(addr_t src, addr_t dst) { // if near branch trampoline plugin enabled if (RoutingPluginManager::near_branch_trampoline) { auto plugin = static_cast\u003cRoutingPluginInterface *\u003e(RoutingPluginManager::near_branch_trampoline); if (plugin-\u003eGenerateTrampolineBuffer(this, src, dst) == false) { DEBUG_LOG(\"Failed enable near branch trampoline plugin\"); } } if (GetTrampolineBuffer() == nullptr) { auto tramp_buffer = GenerateNormalTrampolineBuffer(src, dst); SetTrampolineBuffer(tramp_buffer); } return true; } arm64架构下的GenerateNearTrampolineBuffer的实现 // source/InterceptRouting/RoutingPlugin/NearBranchTrampoline/near_trampoline_arm64.cc CodeBufferBase *GenerateNearTrampolineBuffer(InterceptRouting *routing, addr_t src, addr_t dst) { CodeBufferBase *result = nullptr; TurboAssembler turbo_assembler_((void *)src); #define _ turbo_assembler_. // branch to trampoline_target directly if (llabs((long long)dst - (long long)src) \u003c ARM64_B_XXX_RANGE) { _ b(dst - src); } else { auto fast_forward_trampoline = GenerateFastForwardTrampoline(src, dst); if (!fast_forward_trampoline) return nullptr; _ b(fast_forward_trampoline-\u003eaddr - src); } // free the original trampoline result = turbo_assembler_.GetCodeBuffer()-\u003eCopy(); return result; } 根据代码逻辑，最终的跳转都是通过b指令来跳的，也就是只会替换一行指令完成短指令的inline hook，具体看看b指令跳转是怎么实现的 1. b指令直接跳转 判断是否dst、src间距在b指令跳转范围内，arm64 b指令跳转范围在128M 2. fast_forward模式 第一步是寻找dst周边的可执行内存块 // source/InterceptRouting/RoutingPlugin/NearBranchTrampoline/near_trampoline_arm64.cc // [adrp + add + br branch] auto tramp_size = 3 * 4; auto tramp_mem = NearMemoryAllocator::SharedAllocator()-\u003eallocateNearExecMemory(tramp_size, src, ARM64_B_XXX_RANGE); if (tramp_mem == nullptr) { ERROR_LOG(\"search near code block failed\"); return nullptr; } 两种搜索方式 // source/MemoryAllocator/NearMemoryAllocator.cc MemBlock *NearMemoryAllocator::allocateNearBlock(uint32_t size, addr_t pos, size_t search_range, bool executable) { MemBlock *result = nullptr; result = allocateNearBlockFromDefaultAllocator(size, pos, search_range, executable); if (!result) { result = allocateNearBlockFromUnusedRegion(size, pos, search_range, executable); } if (!result) { ERROR_LOG(\"[near memory allocator] allocate near block failed (%p, %p, %p)\", size, pos, search_range); } return result; } 2.1 allocateNearBlockFromDefaultAllocator 依赖于allocateNearBlockFromUnusedRegion函数中注册的default_allocator 2.2 allocateNearBlockFromUnusedRegion 遍历当前进程内存地址段（maps文件中），寻找unuse的内存地址，创建内存块 当创建好内存块后，判断新内存块与dst的距离是否满足adrp指令的范围，满足则跳转 // /Users/linhanqiu/Projects/study/Dobby/source/InterceptRouting/RoutingPlugin/NearBranchTrampoline/near_trampoline_arm64.cc uint64_t distance = llabs((int64_t)(tramp_mem - dst)); uint64_t adrp_range = ((uint64_t)1 \u003c\u003c (2 + 19 + 12 - 1)); if (distance \u003c adrp_range) { // use adrp + add + br branch == (3 * 4) trampoline size _ AdrpAdd(TMP_REG_0, (uint64_t)tramp_mem, dst); _ br(TMP_REG_0); DEBUG_LOG(\"forward trampoline use [adrp, add, br]\"); } 这里可以这么理解，b指令是为了跳转到这个新创建的内存块上，借由这个内存块再跳转到dst上，相当于做了二次跳转 当距离还是不够大时，只能使用mov+br的方式跳转到dst上 // /Users/linhanqiu/Projects/study/Dobby/source/InterceptRouting/RoutingPlugin/NearBranchTrampoline/near_trampoline_arm64.cc // use mov + br == (4 * 5) trampoline size _ Mov(TMP_REG_0, dst); _ br(TMP_REG_0); DEBUG_LOG(\"forward trampoline use [mov, br]\"); ","date":"2024-02-21","objectID":"/posts/dobby-%E7%9F%AD%E6%8C%87%E4%BB%A4hook%E6%96%B9%E5%BC%8F/:0:1","tags":["源码分析"],"title":"Dobby 短指令hook方式","uri":"/posts/dobby-%E7%9F%AD%E6%8C%87%E4%BB%A4hook%E6%96%B9%E5%BC%8F/"},{"categories":["Hook框架学习"],"content":"Dobby框架推出的时间也不短了，从Github提交记录上看最早在17年就有提交了。这期间陆陆续续在使用Dobby框架，虽然对原理有大概的了解，但是还是没有从源码上入手分析，这次想完整的梳理下Dobby的实现流程，也就有了这次的文章。 对于Dobby这类inline hook框架的认识，大多数人都知道它的实现是在hook函数时，修改了函数对应汇编代码的前几行指令实现跳转到自定义函数上的，那么就沿着这个角度先从汇编调试上看看Dobby从我们原始程序的修改 ","date":"2024-02-21","objectID":"/posts/dobby%E6%A1%86%E6%9E%B6%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/:0:0","tags":["源码分析"],"title":"Dobby框架源码学习","uri":"/posts/dobby%E6%A1%86%E6%9E%B6%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/"},{"categories":["Hook框架学习"],"content":"一、从调试角度看Dobby的原理 使用一个最基本的Demo来作为调试对象 注意：这里直接将Dobby源码作用三方库引入，目前Dobby最新Commit无法编译，需要切换到Commit：0932d69c320e786672361ab53825ba8f4245e9d3 对Java_com_example_dobbytest1_MainActivity_stringFromJNI方法的hook，hook后主动回调原始方法 #include \u003cjni.h\u003e #include \u003cstring\u003e #include \"Dobby/include/dobby.h\" #include \"logging.h\" extern \"C\" JNIEXPORT jstring JNICALL Java_com_example_dobbytest1_MainActivity_stringFromJNI( JNIEnv* env, jobject /* this */) { std::string hello = \"no be hooked\"; return env-\u003eNewStringUTF(hello.c_str()); } static jstring (*orgin_Java_com_example_dobbytest1_MainActivity_stringFromJNI)(JNIEnv* env,jobject /* this */); extern \"C\" JNIEXPORT jstring JNICALL new_Java_com_example_dobbytest1_MainActivity_stringFromJNI( JNIEnv* env, jobject jobject1/* this */) { LOGI(\"be hooked\"); return orgin_Java_com_example_dobbytest1_MainActivity_stringFromJNI(env,jobject1); } __attribute__((constructor)) static void ctor() { // 构造函数 静态插入hook调用 // 原函数名 // 新函数地址 // 旧函数地址 DobbyHook((void *) DobbySymbolResolver(NULL, \"Java_com_example_dobbytest1_MainActivity_stringFromJNI\"), (void *) new_Java_com_example_dobbytest1_MainActivity_stringFromJNI, (void **) \u0026orgin_Java_com_example_dobbytest1_MainActivity_stringFromJNI ); } 可能是由于Android Studio版本太新，没找到在Android Studio上使用lldb调试的方式，我就直接使用命令行来操作了 设备端开启lldb-server并启动App ./lldb-server platform --listen '*:1234' --server 本地使用lldb连接 选择调试平台 (lldb) platform select remote-android Platform: remote-android Connected: no 连接lldb-server创建的端口 (lldb) platform connect connect://:1234 Platform: remote-android Triple: aarch64-unknown-linux-android OS Version: 30 (4.14.186-perf-g42f990859d35) Hostname: localhost Connected: yes WorkingDir: /data/local/tmp Kernel: #1 SMP PREEMPT Tue Mar 1 19:09:49 CST 2022 (lldb) 此时设备端会显示Connection established.，接下里就可以attach对应的pid进行调试了 首先确定断点位置，因为代码中是对Java_com_example_dobbytest1_MainActivity_stringFromJNI进行hook，那么可以断点在该方法的首个指令地址 地址计算可以参考下面的方法 通过image list -o -f命令获取so的基地址 0x00000070ece49000 基地址+偏移=断点地址 0x00000070ece49000+0x000000000000b110=0x70ece54110 0xb110位置断点 (lldb) br set -a 0x70ece54110 Breakpoint 1: address = 0x00000070ece54110 得到结果如下 断点信息 Process 20161 stopped * thread #1, name = 'mple.dobbytest1', stop reason = breakpoint 1.1 frame #0: 0x00000070ece54110 -\u003e 0x70ece54110: adrp x17, 0 0x70ece54114: add x17, x17, #0x290 0x70ece54118: br x17 0x70ece5411c: mrs x8, TPIDR_EL0 Target 0: (app_process64) stopped. 对比原始汇编代码 .text:000000000000B110 SUB SP, SP, #0x70 .text:000000000000B114 STP X29, X30, [SP,#0x60+var_s0] .text:000000000000B118 ADD X29, SP, #0x60 .text:000000000000B11C MRS X8, #3, c13, c0, #2 可以看到Java_com_example_dobbytest1_MainActivity_stringFromJNI函数的头三个指令发生了变化，原本的栈拉伸、寄存器入栈保护等固定指令被替换了，替换成了针对x17地址的跳转指令，看下x17对应的值是什么 Process 20161 stopped * thread #1, name = 'mple.dobbytest1', stop reason = instruction step over frame #0: 0x00000070ece54114 -\u003e 0x70ece54114: add x17, x17, #0x290 0x70ece54118: br x17 0x70ece5411c: mrs x8, TPIDR_EL0 0x70ece54120: ldr x8, [x8, #0x28] Target 0: (app_process64) stopped. (lldb) register read x17 x17 = 0x00000070ece54000 (lldb) n Process 20161 stopped * thread #1, name = 'mple.dobbytest1', stop reason = instruction step over frame #0: 0x00000070ece54118 -\u003e 0x70ece54118: br x17 0x70ece5411c: mrs x8, TPIDR_EL0 0x70ece54120: ldr x8, [x8, #0x28] 0x70ece54124: stur x8, [x29, #-0x8] Target 0: (app_process64) stopped. (lldb) register read x17 x17 = 0x00000070ece54290 (lldb) x17对应的值是0x00000070ece54290，偏移是0xb290，也就对应着new_Java_com_example_dobbytest1_MainActivity_stringFromJNI方法 那么从这里可以看出，Dobby对函数的hook是通过修改原始函数的前三个指令来完成跳转的，那么指令替换的逻辑是什么我们后续在源码分析中继续跟踪，现在接着往下看 在替换函数中最后我们主动回调了原始函数，在0xb2cc的位置可以再下个断点 (lldb) br set -a 0x70ece542cc Breakpoint 3: address = 0x00000070ece542cc (lldb) c Process 20161 resuming Process 20161 stopped * thread #1, name = 'mple.dobbytest1', stop reason = breakpoint 3.1 frame #0: 0x00000070ece542cc -\u003e 0x70ece542cc: blr x8 0x70ece542d0: ldp x29, x30, [sp, #0x10] 0x70ece542d4: add sp, sp, #0x20 0x70ece542d8: ret Target 0: (app_process64) stopped. (lldb) s Process 20161","date":"2024-02-21","objectID":"/posts/dobby%E6%A1%86%E6%9E%B6%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/:0:1","tags":["源码分析"],"title":"Dobby框架源码学习","uri":"/posts/dobby%E6%A1%86%E6%9E%B6%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/"},{"categories":["Hook框架学习"],"content":"二、源码分析 源码上从dobby.h的DobbyHook入手，源码实现在 // source/InterceptRouting/Routing/FunctionInlineHook/FunctionInlineHook.cc PUBLIC int DobbyHook(void *address, dobby_dummy_func_t replace_func, dobby_dummy_func_t *origin_func) { ...... #if defined(ANDROID) void *page_align_address = (void *)ALIGN_FLOOR(address, OSMemory::PageSize()); if (!OSMemory::SetPermission(page_align_address, OSMemory::PageSize(), kReadExecute)) { return -1; } #endif DEBUG_LOG(\"----- [DobbyHook:%p] -----\", address); // check if already register auto entry = Interceptor::SharedInstance()-\u003efind((addr_t)address); if (entry) { ERROR_LOG(\"%p already been hooked.\", address); return -1; } entry = new InterceptEntry(kFunctionInlineHook, (addr_t)address); auto *routing = new FunctionInlineHookRouting(entry, replace_func); routing-\u003ePrepare(); routing-\u003eDispatchRouting(); // set origin func entry with as relocated instructions if (origin_func) { *origin_func = (dobby_dummy_func_t)entry-\u003erelocated_addr; #if defined(__APPLE__) \u0026\u0026 defined(__arm64__) *origin_func = pac_sign(*origin_func); #endif } routing-\u003eCommit(); Interceptor::SharedInstance()-\u003eadd(entry); return 0; } 首先会对地址所在的内存页权限进行修改，修改成可读可执行（PROT_READ | PROT_EXEC），这是为了能够修改内存中的代码并且保证系统能够正常执行该段代码 以地址创建InterceptEntry对象entry，并用Interceptor管理起来 以entry和replace_func创建FunctionInlineHookRouting，并分别调用Prepare、DispatchRouting、Commit 如果有origin_func，设置origin_func作为entry的relocated_addr 关键在于第三步FunctionInlineHookRouting对象的处理，FunctionInlineHookRouting，从命名上看是关于inline hook跳转规则的配置。FunctionInlineHookRouting的Prepare函数为空，且父类InterceptRouting的Prepare函数也为空，可以先忽略 主要看下面这个函数DispatchRouting // source/InterceptRouting/Routing/FunctionInlineHook/RoutingImpl.cc void FunctionInlineHookRouting::DispatchRouting() { BuildRouting(); // generate relocated code which size == trampoline size GenerateRelocatedCode(); } void FunctionInlineHookRouting::BuildRouting() { SetTrampolineTarget((addr_t)replace_func); // generate trampoline buffer, run before GenerateRelocatedCode addr_t from = entry_-\u003epatched_addr; #if defined(TARGET_ARCH_ARM) if (entry_-\u003ethumb_mode) from += 1; #endif addr_t to = GetTrampolineTarget(); GenerateTrampolineBuffer(from, to); } // source/InterceptRouting/InterceptRouting.cpp bool InterceptRouting::GenerateTrampolineBuffer(addr_t src, addr_t dst) { // if near branch trampoline plugin enabled if (RoutingPluginManager::near_branch_trampoline) { auto plugin = static_cast\u003cRoutingPluginInterface *\u003e(RoutingPluginManager::near_branch_trampoline); if (plugin-\u003eGenerateTrampolineBuffer(this, src, dst) == false) { DEBUG_LOG(\"Failed enable near branch trampoline plugin\"); } } if (GetTrampolineBuffer() == nullptr) { auto tramp_buffer = GenerateNormalTrampolineBuffer(src, dst); SetTrampolineBuffer(tramp_buffer); } return true; } // source/TrampolineBridge/Trampoline/arm64/trampoline_arm64.cc CodeBufferBase *GenerateNormalTrampolineBuffer(addr_t from, addr_t to) { TurboAssembler turbo_assembler_((void *)from); #define _ turbo_assembler_. uint64_t distance = llabs((int64_t)(from - to)); uint64_t adrp_range = ((uint64_t)1 \u003c\u003c (2 + 19 + 12 - 1)); if (distance \u003c adrp_range) { // adrp, add, br _ AdrpAdd(TMP_REG_0, from, to); _ br(TMP_REG_0); DEBUG_LOG(\"[trampoline] use [adrp, add, br]\"); } else { // ldr, br, branch-address CodeGen codegen(\u0026turbo_assembler_); codegen.LiteralLdrBranch((uint64_t)to); DEBUG_LOG(\"[trampoline] use [ldr, br, #label]\"); } #undef _ // Bind all labels turbo_assembler_.RelocBind(); auto result = turbo_assembler_.GetCodeBuffer()-\u003eCopy(); return result; } 从BuildRouting函数流程中来看下它做的事，to对应的是replace_func，from对应的是patched_addr，也就是origin_func对应的地址，得到这两个地址之后就调用GenerateNormalTrampolineBuffer生成trampoline_buffer_ 可以看到生成了三行指令adrp, add, br，对应了上文调试中origin_func的前三行代码替换后的代码，借助assembler-arm64.h生成buffer，对应到调试指令中 0x70ece54110: adrp x17, 0 0x70ece54114: add x17, x17, #0x290 0x70ece54118: br x17 第一行x17表示当前内存页的地址，0表示origin_func与replace_func地址之间的内存页差值 第二行表示replace_func在当前内存页的偏移量 第三行就是跳转指令 最后会生成这三行跳转指令对应的字节码 BuildRouting生成完Trampoline指令后调用GenerateRelocatedCode // source/Inte","date":"2024-02-21","objectID":"/posts/dobby%E6%A1%86%E6%9E%B6%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/:0:2","tags":["源码分析"],"title":"Dobby框架源码学习","uri":"/posts/dobby%E6%A1%86%E6%9E%B6%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/"},{"categories":["Hook框架学习"],"content":"参考 ARM64汇编入门小记 浅谈ARM64汇编 指令级工具Dobby源码阅读 ","date":"2024-02-21","objectID":"/posts/dobby%E6%A1%86%E6%9E%B6%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/:0:3","tags":["源码分析"],"title":"Dobby框架源码学习","uri":"/posts/dobby%E6%A1%86%E6%9E%B6%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/"},{"categories":["系统定制"],"content":"前言 ","date":"2023-09-24","objectID":"/posts/android11aosp%E7%BC%96%E8%AF%91%E6%B5%81%E7%A8%8B/:0:1","tags":["AOSP编译"],"title":"Android11AOSP编译流程","uri":"/posts/android11aosp%E7%BC%96%E8%AF%91%E6%B5%81%E7%A8%8B/"},{"categories":["系统定制"],"content":"一、编译环境搭建 1 物料准备 设备：pixel2（walleye） 源码：aosp源码 build id：RP1A.200720.009 tag：android-11.0.0_r1 sdk version：Android11 驱动源码准备：驱动源码 2 工具准备 编译支撑系统：centos7，使用公司的云容器（16核32G、600G磁盘） 三方库准备 yum install -y gcc make libstdc++.i686 libstdc++-devel.i686 zlib-devel openssl-devel perl cpio expat-devel gettext-devel autoconf glibc.i686 glibc-devel.i686 zlib-devel.i686 libstdc++.i686 libX11-devel.i686 ncurses-devel.i686 ncurses-libs.i686 gperf flex gcc-c++ bison patch Java/Python环境准备 ","date":"2023-09-24","objectID":"/posts/android11aosp%E7%BC%96%E8%AF%91%E6%B5%81%E7%A8%8B/:0:2","tags":["AOSP编译"],"title":"Android11AOSP编译流程","uri":"/posts/android11aosp%E7%BC%96%E8%AF%91%E6%B5%81%E7%A8%8B/"},{"categories":["系统定制"],"content":"二、编译流程 源码下载 // repo工具下载 curl https://mirrors.tuna.tsinghua.edu.cn/git/git-repo \u003e repo chmod a+x repo // 指定版本AOSP源码拉取 ./repo init -u https://mirrors.tuna.tsinghua.edu.cn/git/AOSP/platform/manifest -b android-11.0.0_r48 。/repo sync // 驱动解压放在源码根目录下，执行驱动脚本，会自动填充到vendor目录 ./extract-google_devices-blueline.sh ./extract-qcom-blueline.sh 编译环境配置 source build/envsetup.sh // 选择对应设备 lunch 执行编译 // 根据系统性能选择线程数 make -j 4 ","date":"2023-09-24","objectID":"/posts/android11aosp%E7%BC%96%E8%AF%91%E6%B5%81%E7%A8%8B/:0:3","tags":["AOSP编译"],"title":"Android11AOSP编译流程","uri":"/posts/android11aosp%E7%BC%96%E8%AF%91%E6%B5%81%E7%A8%8B/"},{"categories":["unidbg生态"],"content":"Unidbg对抗点 不支持信号机制 内存布局检测 Unidbg通过Java实现JNI的逻辑，导致JNI函数地址控制在0xfffe0000L - 0xffff0000L范围内，检测JNI函数地址是否处于该范围或者相邻两个函数的地址差值 类检测：Unidbg通常会对不存在的类也会正常返回 函数检测：对比methodid是否是hashcode 文件描述符：Unidbg的文件描述符通常是3-6 uname判断 hook框架检测（xhook、dobby） 依赖库对抗：Unidbg只实现了十余个常用so库 字节对齐？ getenv 增加目标函数前置执行条件 ","date":"2023-08-31","objectID":"/posts/unidbg%E7%89%B9%E5%BE%81%E6%A3%80%E6%B5%8B%E6%B1%87%E6%80%BB/:0:0","tags":["unidbg特征对抗"],"title":"Unidbg特征检测汇总","uri":"/posts/unidbg%E7%89%B9%E5%BE%81%E6%A3%80%E6%B5%8B%E6%B1%87%E6%80%BB/"},{"categories":["hook框架"],"content":" 端口检测：frida默认暴露端口为27047 通信方式检测：frida使用App低频使用的D-Bus通信协议来进行通信，可以遍历端口对它们发送D-Bus AUTH消息来判断是否存在REJECT的情况 内存检测 so列表检测 maps文件内容遍历检测 通过linker获取so list遍历检测 可执行段字符检测：遍历maps文件中带有可执行属性的segment，检测是否包含libfrida/frida:rpc等字符特征 线程检测：遍历proc/self/task的文件内容，查找字符特征 命名通道检测：遍历proc/self/fd，反查fd判断是否包含linjector字符特征 section crc检验：对比内存中的so 各个section与本地的section的crc值对比 segment属性检测：针对inline hook，由于frida是基于inline hook的，因此会改动libart，进而暴露在maps中会有rwxp属性的地址段 inline hook跳转检测：frida inline hook和其他inline hook的原理相同，在函数的头几个字节通常是ldr、br这类的指令 目录检测：针对/data/local/tmp下面的re.frida.server 代码漏洞 elf头字节魔改：frida gum_try_parse_linker_proc_maps_line函数中在获取linker时会判断elf头字节是否匹配，可以选择修改elf头字节 libc属性修改：使用目标libc的mmap将自身的相关so注册到目标maps表中;再执行目标libc的dlopen和dlsym函数将自身so中的函数进行执行，做法是主动mmap只读的libc从而让frida启动崩溃 检测线程保护 匿名内存检测 额外需要注意的是 自定义syscall：从上面的特征检测来看，文件是重要的检测介质，为了要获取到真实的文件，还需要使用自定义syscall，例如open/read/close等 自定义pthread_create ","date":"2023-08-21","objectID":"/posts/frida%E7%89%B9%E5%BE%81%E6%A3%80%E6%B5%8B%E6%B1%87%E6%80%BB/:0:0","tags":["frida","对抗案例"],"title":"Frida特征检测汇总","uri":"/posts/frida%E7%89%B9%E5%BE%81%E6%A3%80%E6%B5%8B%E6%B1%87%E6%80%BB/"},{"categories":["hook框架"],"content":"一、编译环境搭建 这次编译的目标版本是14.2.18 1 物料准备 设备：红米note11（MIUI12 Android11） frida源码：https://github.com/frida/frida 2 工具准备 参照官方编译指南 编译支撑系统：ubuntu23 Linux ubuntu23 6.2.0-27-generic #28-Ubuntu SMP PREEMPT_DYNAMIC Wed Jul 12 22:39:51 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux 之所以选择ubuntu23而不是其他版本是因为在安装三方库的时候不用再额外考虑版本问题了，亲测这点太坑了 frida源码下载 git clone -b 14.2.18 --recurse-submodules https://github.com/frida/frida 选择tag为14.2.18，不必全量clone再切换，后续的版本和当前版本差别较大，会造成无法正常编译，原因是因为直接使用checkout的话只是针对frida这个仓库，但是对于submodule来说版本依旧未变，需要执行如下命令 git submodule update --recursive toolchain/sdk 可以选择自己编译，但是为了减少不必要的麻烦，直接选择官方已经打好的编译产物，frida官方是存在toolchain/sdk的编译后的产物，可以直接下，下载链接的格式参考 https://build.frida.re/deps/{frida_toolchain_version}/toolchain-linux-x86_64.tar.bz2 frida_toolchain_version可以从releng/deps.mk中获取 frida_toolchain_version = 20210419 最终可得的下载地址是 https://build.frida.re/deps/20210419/toolchain-linux-x86_64.tar.bz2 # toolchains 工具 https://build.frida.re/deps/20210419/sdk-linux-x86_64.tar.bz2 # sdk 工具 # 下面是需要编译的对应架构的文件 https://build.frida.re/deps/20210419/sdk-android-x86.tar.bz2 https://build.frida.re/deps/20210419/sdk-android-x86_64.tar.bz2 https://build.frida.re/deps/20210419/sdk-android-arm.tar.bz2 https://build.frida.re/deps/20210419/sdk-android-arm64.tar.bz2 将上面的四个文件分别下载好后放在frida/build目录下（没有可新建），执行命令 bash releng/setup-env.sh 输出结果如下 Assuming host is linux-x86_64 Set FRIDA_HOST to override. Deploying local toolchain toolchain-linux-x86_64.tar.bz2... Deploying local SDK sdk-linux-x86_64.tar.bz2... 三方库安装 sudo apt-get install build-essential curl git lib32stdc++-9-dev libc6-dev-i386 nodejs npm python3-dev python3-pip ndk安装 wget https://dl.google.com/android/repository/android-ndk-r22b-linux-x86_64.zip unzip android-ndk-r22-linux-x86_64.zip 再添加到环境变量中 export ANDROID_NDK_ROOT=xxxxxx export PATH=$ANDROID_NDK_ROOT:$PATH 执行ndk-build --v如果有版本信息输出，说明环境变量配置生效了 ","date":"2023-08-20","objectID":"/posts/frida%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%AF%B4%E6%98%8E/:0:1","tags":["frida","源码编译"],"title":"Frida源码编译说明","uri":"/posts/frida%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%AF%B4%E6%98%8E/"},{"categories":["hook框架"],"content":"二、编译流程 切换到frida项目根目录下执行命令make core-android-arm64 1 缺少build/frida-version.h make[1]: *** No rule to make target '.git/refs/heads/master', needed by 'build/frida-version.h'. Stop. 需要在build目录下手动添加build/frida-version.h文件，内容如 #ifndef __FRIDA_VERSION_H__ #define __FRIDA_VERSION_H__ #define FRIDA_VERSION \"14.2.2\" #define FRIDA_MAJOR_VERSION 14 #define FRIDA_MINOR_VERSION 2 #define FRIDA_MICRO_VERSION 2 #define FRIDA_NANO_VERSION 0 #endif 2 分支修改 下载的14.2.18版本，需要将frida-deps.vcxproj（4处）和frida.mk（1处）中的master修改为main 3 执行编译 执行make core-android-arm64命令之后正常输出如下 Installing lib/gadget/frida-gadget.so to /home/linhanqiu/proj/frida/build/frida-android-arm64/lib/frida/64 This file does not have an rpath. This file does not have a runpath. Installing src/api/frida-core.h to /home/linhanqiu/proj/frida/build/frida-android-arm64/include/frida-1.0 Installing src/api/frida-core-1.0.vapi to /home/linhanqiu/proj/frida/build/frida-android-arm64/share/vala/vapi Installing src/api/frida-core-1.0.deps to /home/linhanqiu/proj/frida/build/frida-android-arm64/share/vala/vapi Installing src/api/libfrida-core-1.0.a to /home/linhanqiu/proj/frida/build/frida-android-arm64/lib Installing server/frida-server to /home/linhanqiu/proj/frida/build/frida-android-arm64/bin This file does not have an rpath. This file does not have a runpath. Installing inject/frida-inject to /home/linhanqiu/proj/frida/build/frida-android-arm64/bin This file does not have an rpath. This file does not have a runpath. Installing /home/linhanqiu/proj/frida/frida-core/lib/selinux/frida-selinux.h to /home/linhanqiu/proj/frida/build/frida-android-arm64/include/frida-1.0 Installing /home/linhanqiu/proj/frida/build/tmp-android-arm64/frida-core/meson-private/frida-core-1.0.pc to /home/linhanqiu/proj/frida/build/frida-android-arm64/lib/pkgconfig make[1]: Leaving directory '/home/linhanqiu/proj/frida' 由于选择的架构是arm64，对应的输出目录是build/tmp-android-arm64 ","date":"2023-08-20","objectID":"/posts/frida%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%AF%B4%E6%98%8E/:0:2","tags":["frida","源码编译"],"title":"Frida源码编译说明","uri":"/posts/frida%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%AF%B4%E6%98%8E/"},{"categories":["hook框架"],"content":"三、产物测试 在官方版本列表上看frida-server14.2.18对应的python工具库版本 pip install frida==14.2.18 pip install frida-tools==9.2.4 测试具体案例 ","date":"2023-08-20","objectID":"/posts/frida%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%AF%B4%E6%98%8E/:0:3","tags":["frida","源码编译"],"title":"Frida源码编译说明","uri":"/posts/frida%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%AF%B4%E6%98%8E/"},{"categories":["hook框架"],"content":"一、资源准备 com.jingdong.app.mall 12.1.0 pixel2 android10.0 frida 14.2.2 ","date":"2023-08-19","objectID":"/posts/frida%E7%89%B9%E5%BE%81%E5%AF%B9%E6%8A%97%E6%A1%88%E4%BE%8B2/:0:1","tags":["frida","对抗案例"],"title":"Frida特征对抗案例2","uri":"/posts/frida%E7%89%B9%E5%BE%81%E5%AF%B9%E6%8A%97%E6%A1%88%E4%BE%8B2/"},{"categories":["hook框架"],"content":"二、分析思路 使用frida以spawn模式启动，可以发现进程直接崩溃，说明存在反调试 Spawned `com.jingdong.app.mall`. Resuming main thread! [Pixel 2::com.jingdong.app.mall]-\u003e Process terminated [Pixel 2::com.jingdong.app.mall]-\u003e 通常检测逻辑是放在native层的，因此进一步判断是哪个so导致的 function hook_dlopen() { Interceptor.attach(Module.findExportByName(null, \"android_dlopen_ext\"), { onEnter: function (args) { var pathptr = args[0]; if (pathptr !== undefined \u0026\u0026 pathptr != null) { var path = ptr(pathptr).readCString(); console.log(\"load \" + path); } } } ); } 由so的加载流程可知，so都是是顺序加载，从命令行中当加载libJDMobileSec之后，进程就崩溃了，可以猜测反调试点在libJDMobileSec中 Spawned `com.jingdong.app.mall`. Resuming main thread! [Pixel 2::com.jingdong.app.mall]-\u003e load /system/framework/oat/arm/org.apache.http.legacy.odex load /data/app/com.jingdong.app.mall-OXNoca8Sb7xq1IC0YJW2PA==/oat/arm/base.odex load /data/app/com.jingdong.app.mall-OXNoca8Sb7xq1IC0YJW2PA==/lib/arm/libJDMobileSec.so Process terminated 同样需要判断具体检测的函数在哪个部分，优先确定JNI_OnLoad的偏移是0x56BC function hook_dlopen(soName = '') { Interceptor.attach(Module.findExportByName(null, \"android_dlopen_ext\"), { onEnter: function (args) { var pathptr = args[0]; if (pathptr !== undefined \u0026\u0026 pathptr != null) { var path = ptr(pathptr).readCString(); if (path.indexOf(soName) \u003e= 0) { this.is_can_hook = true; } } }, onLeave: function (retval) { if (this.is_can_hook) { hook_JNI_OnLoad() } } } ); } function hook_JNI_OnLoad(){ let module = Process.findModuleByName(\"libJDMobileSec.so\") Interceptor.attach(module.base.add(0x56BC + 1), { onEnter(args){ console.log(\"call JNI_OnLoad\") } }) } setImmediate(hook_dlopen,\"libJDMobileSec.so\") 看到是在JNI_OnLoad之后进程崩溃的，说明检测逻辑应该是JNI_OnLoad里面 Spawned `com.jingdong.app.mall`. Resuming main thread! [Pixel 2::com.jingdong.app.mall]-\u003e call JNI_OnLoad Process terminated 测试下是否有新起线程检测 function hook_pthread_create(){ var base = Process.findModuleByName(\"libJDMobileSec.so\").base console.log(\"libJDMobileSec.so --- \" + base) Interceptor.attach(Module.findExportByName(\"libc.so\", \"pthread_create\"),{ onEnter(args){ let func_addr = args[2] console.log(\"The thread function address is \" + func_addr + \" offset:\" + (func_addr-base).toString(16)) } }) } 可以看到有个新起的线程 Spawned `com.jingdong.app.mall`. Resuming main thread! [Pixel 2::com.jingdong.app.mall]-\u003e call JNI_OnLoad libJDMobileSec.so --- 0xce055000 The thread function address is 0xce06151d offset:c51d Process terminated 优先nop掉看是否该点是检测点，追溯到JNI_OnLoad方法里面偏移0x688A上 function bypass(){ let module = Process.findModuleByName(\"libJDMobileSec.so\") nop(module.base.add(0x688A)) } nop掉之后还是崩溃，看来检测点可能不是这里或者不止一个，继续尝试其他hook点 function replace_str() { var pt_strstr = Module.findExportByName(\"libc.so\", 'strstr'); Interceptor.attach(pt_strstr, { onEnter: function (args) { var str1 = args[0].readCString(); var str2 = args[1].readCString(); console.log(\"strstr--\u003e\", str1, str2); // console.log('strstr called from:\\\\n' + Thread.backtrace(this.context, Backtracer.ACCURATE).map(DebugSymbol.fromAddress).join('\\\\n') + '\\\\n'); // console.log('strstr called from:\\\\n' + Thread.backtrace(this.context, Backtracer.FUZZY).map(DebugSymbol.fromAddress).join('\\\\n') + '\\\\n'); } }); } 看看字符比较会不会有发现 strstr--\u003e bb123000-bb222000 r--p 00000000 103:1d 2720259 /data/app/com.jingdong.app.mall-OXNoca8Sb7xq1IC0YJW2PA==/oat/arm/base.odex com.saurik.substrate strstr called from:\\n0xcdf5dbfb libJDMobileSec.so!0xabfb\\n0xcdf6e5a1 libJDMobileSec.so!0x1b5a1\\n strstr--\u003e bb222000-bb272000 r--p 00000000 103:06 1437 /system/framework/oat/arm/org.apache.http.legacy.odex re.frida.server/frida-agent-32.so strstr called from:\\n0xcdf5da3f libJDMobileSec.so!0xaa3f\\n0xcdf6e5a1 libJDMobileSec.so!0x1b5a1\\n strstr--\u003e bb222000-bb272000 r--p 00000000 103:06 1437 /system/framework/oat/arm/org.apache.http.legacy.odex re.frida.server/frida-agent-64.so strstr called from:\\n0xcdf5da85 libJDMobileSec.so!0xaa85\\n0xcdf6e5a1 libJDMobileSec.so!0x1b5a1\\n strstr--\u003e bb222000-bb272000 r--p 00000000 103:06 1437 /system/framework/oat/arm/org.apache.http.legacy.odex com.saurik.substrate strstr called from:\\n0xcdf5dbfb lib","date":"2023-08-19","objectID":"/posts/frida%E7%89%B9%E5%BE%81%E5%AF%B9%E6%8A%97%E6%A1%88%E4%BE%8B2/:0:2","tags":["frida","对抗案例"],"title":"Frida特征对抗案例2","uri":"/posts/frida%E7%89%B9%E5%BE%81%E5%AF%B9%E6%8A%97%E6%A1%88%E4%BE%8B2/"},{"categories":["hook框架"],"content":"三 总结 完整代码看这里libJDMobileSec.js ","date":"2023-08-19","objectID":"/posts/frida%E7%89%B9%E5%BE%81%E5%AF%B9%E6%8A%97%E6%A1%88%E4%BE%8B2/:0:3","tags":["frida","对抗案例"],"title":"Frida特征对抗案例2","uri":"/posts/frida%E7%89%B9%E5%BE%81%E5%AF%B9%E6%8A%97%E6%A1%88%E4%BE%8B2/"},{"categories":["hook框架"],"content":"一、资源准备 tv.danmaku.bili 7.43.0 pixel2 android10.0 frida 14.2.2 ","date":"2023-08-18","objectID":"/posts/frida%E7%89%B9%E5%BE%81%E5%AF%B9%E6%8A%97%E6%A1%88%E4%BE%8B1/:0:1","tags":["frida","对抗案例"],"title":"Frida特征对抗案例1","uri":"/posts/frida%E7%89%B9%E5%BE%81%E5%AF%B9%E6%8A%97%E6%A1%88%E4%BE%8B1/"},{"categories":["hook框架"],"content":"二、分析思路 使用frida以spawn模式启动，可以发现进程直接崩溃，说明存在反调试 Spawned `tv.danmaku.bili`. Resuming main thread! [Pixel 2::tv.danmaku.bili]-\u003e Process terminated [Pixel 2::tv.danmaku.bili]-\u003e 通常检测逻辑是放在native层的，因此进一步判断是哪个so导致的 function hook_dlopen() { Interceptor.attach(Module.findExportByName(null, \"android_dlopen_ext\"), { onEnter: function (args) { var pathptr = args[0]; if (pathptr !== undefined \u0026\u0026 pathptr != null) { var path = ptr(pathptr).readCString(); console.log(\"load \" + path); } } } ); } 由so的加载流程可知，so都是是顺序加载，从命令行中当加载libmsaoaidsec.so之后，进程就崩溃了，可以猜测反调试点在libmsaoaidsec.so中 [Pixel 2::tv.danmaku.bili]-\u003e load /system/framework/oat/arm/com.android.future.usb.accessory.odex load /system/framework/oat/arm/org.apache.http.legacy.odex load /data/app/tv.danmaku.bili-j_iiq65L9CsVGLfbrhaTgA==/oat/arm/base.odex load /data/app/tv.danmaku.bili-j_iiq65L9CsVGLfbrhaTgA==/lib/arm/libblkv.so load /data/app/tv.danmaku.bili-j_iiq65L9CsVGLfbrhaTgA==/lib/arm/libbili_core.so load /data/app/tv.danmaku.bili-j_iiq65L9CsVGLfbrhaTgA==/lib/arm/libbilicr.88.0.4324.188.so load /data/app/tv.danmaku.bili-j_iiq65L9CsVGLfbrhaTgA==/lib/arm/libijkffmpeg.so load /data/app/tv.danmaku.bili-j_iiq65L9CsVGLfbrhaTgA==/lib/arm/libavif-jni.so load /data/dalvik-cache/arm/system@product@app@TrichromeLibrary@TrichromeLibrary.apk@classes.dex load /data/dalvik-cache/arm/system@product@app@WebViewGoogle@WebViewGoogle.apk@classes.dex load /data/app/tv.danmaku.bili-j_iiq65L9CsVGLfbrhaTgA==/lib/arm/libmsaoaidsec.so Process terminated 而libmsaoaidsec.so从字面上可知是MSA（移动安全联盟）出品的，确定了so之后，需要进一步确定具体的函数，so的函数执行顺序是.init函数-\u003eJNI_OnLoad，先判断下是在JNI_OnLoad前后进行检测的 从libmsaoaidsec.so的export函数表中可以知道JNI_OnLoad的偏移量是0xC6DC，先hook JNI_OnLoad尝试下 function hook_dlopen(soName = '') { Interceptor.attach(Module.findExportByName(null, \"android_dlopen_ext\"), { onEnter: function (args) { var pathptr = args[0]; if (pathptr !== undefined \u0026\u0026 pathptr != null) { var path = ptr(pathptr).readCString(); if (path.indexOf(soName) \u003e= 0) { this.is_can_hook = true; } } }, onLeave: function (retval) { if (this.is_can_hook) { hook_JNI_OnLoad() } } } ); } function hook_JNI_OnLoad(){ let module = Process.findModuleByName(\"libmsaoaidsec.so\") Interceptor.attach(module.base.add(0xC6DC + 1), { onEnter(args){ console.log(\"call JNI_OnLoad\") } }) } setImmediate(hook_dlopen, \"libmsaoaidsec.so\") 结果依旧是进程崩溃 Spawned `tv.danmaku.bili`. Resuming main thread! [Pixel 2::tv.danmaku.bili]-\u003e Process terminated [Pixel 2::tv.danmaku.bili]-\u003e 那么可以断定检测位置在JNI_OnLoad之前，因此需要hook .init函数，选取.init_proc中的外部函数引用来做入口 int sub_B1B4() { _DWORD *v0; // r5 int result; // r0 int v2; // r1 int v3; // [sp+0h] [bp-20h] int v4; // [sp+4h] [bp-1Ch] int v5; // [sp+Ch] [bp-14h] v0 = off_1FC04; v5 = *(_DWORD *)off_1FC04; v4 = 0; v3 = 0; // 选取 _system_property_get(\"ro.build.version.sdk\", \u0026v3); result = atoi((const char *)\u0026v3); v2 = *v0 - v5; return result; } 以pthread_create函数为例，尝试下是否有启动线程来做检测 function hook_dlopen(soName = '') { Interceptor.attach(Module.findExportByName(null, \"android_dlopen_ext\"), { onEnter: function (args) { var pathptr = args[0]; if (pathptr !== undefined \u0026\u0026 pathptr != null) { var path = ptr(pathptr).readCString(); if (path.indexOf(soName) \u003e= 0) { locate_init() } } } } ); } function locate_init() { let secmodule = null Interceptor.attach(Module.findExportByName(null, \"__system_property_get\"), { // _system_property_get(\"ro.build.version.sdk\", v1); onEnter: function (args) { secmodule = Process.findModuleByName(\"libmsaoaidsec.so\") var name = args[0]; if (name !== undefined \u0026\u0026 name != null) { name = ptr(name).readCString(); if (name.indexOf(\"ro.build.version.sdk\") \u003e= 0) { hook_pthread_create() } } } } ); } function hook_pthread_create(){ var base = Process.findModuleByName(\"libmsaoaidsec.so\").base console.log(\"libmsaoaidsec.so --- \" + base) Interceptor.attach(Module.findExportByName(\"libc.so\", \"pthread_create\"),{ onEnter(args){ let func_addr = args[2] console.log(\"The thread function address is \" + func_addr + \" offset:\" + (func_addr-base).toString(16)) } }) } setImmediate(hook_dlo","date":"2023-08-18","objectID":"/posts/frida%E7%89%B9%E5%BE%81%E5%AF%B9%E6%8A%97%E6%A1%88%E4%BE%8B1/:0:2","tags":["frida","对抗案例"],"title":"Frida特征对抗案例1","uri":"/posts/frida%E7%89%B9%E5%BE%81%E5%AF%B9%E6%8A%97%E6%A1%88%E4%BE%8B1/"},{"categories":["hook框架"],"content":"三、总结 从上面的检测方式可以大概总结如下： frida特征 inlinehoook特征 trace特征 通常都是通过strstr来做判断，但是某些情况，例如验证inlinehook指令时无法直接定位，杀死进程通常都是使用exit或是通过svc exit_group来操作 完整代码看这里libmsaoaidsec.js ","date":"2023-08-18","objectID":"/posts/frida%E7%89%B9%E5%BE%81%E5%AF%B9%E6%8A%97%E6%A1%88%E4%BE%8B1/:0:3","tags":["frida","对抗案例"],"title":"Frida特征对抗案例1","uri":"/posts/frida%E7%89%B9%E5%BE%81%E5%AF%B9%E6%8A%97%E6%A1%88%E4%BE%8B1/"},{"categories":["riru"],"content":"前言 最近在搜索riru相关的项目时偶尔发现了HuskyDG riru项目中的一个实验性想法 也就是更换加载riru的方式，众所周知，riru.so load是通过赋值ro.dalvik.vm.native.bridge为libriruloader.so来完成的，而HuskyDG则提出了一个新的试验性加载方式—通过修改libandroid_runtime.so替换ro.zygote属性来完成加载 而ro.zygote属性是指的什么呢？它所表达的含义是指定zygote的执行程序时什么，通常情况下它的取值有四种，zygote32、zygote64、zygote32_64、zygote64_32，分别对应着四种.rc文件 init.zygote32.rc：zygote 进程对应的执行程序是 app_process（纯 32bit 模式） init.zygote64.rc：zygote 进程对应的执行程序是 app_process64（纯 64bit 模式） init.zygote32_64.rc：启动两个 zygote 进程（名为 zygote 和 zygote_secondary），对应的执行程序分别是 app_process32（主模式）、app_process64 init.zygote64_32.rc：启动两个 zygote 进程（名为 zygote 和 zygote_secondary），对应的执行程序分别是 app_process64（主模式）、app_process32 而之所以要定义这么多种模式时因为在Android5.0之后开始支持64位程序，为了保证兼容性而推出的 看起来ro.zygote与load并没有什么直接联系，那么HuskyDG的这种新的load方式是怎么实现的呢？ ","date":"2023-08-18","objectID":"/posts/%E6%8E%A2%E8%AE%A8%E6%96%B0%E7%9A%84riru%E5%8A%A0%E8%BD%BD%E6%96%B9%E5%BC%8F/:0:1","tags":["riru原理"],"title":"探讨新的riru加载方式","uri":"/posts/%E6%8E%A2%E8%AE%A8%E6%96%B0%E7%9A%84riru%E5%8A%A0%E8%BD%BD%E6%96%B9%E5%BC%8F/"},{"categories":["riru"],"content":"一、原理分析 核心代码在commit: 90ec934上，关键代码在两处 # template/magisk_module/service.sh mkdir -p \"$(magisk --path)/riru\" patch_lib(){ /data/adb/magisk/magiskboot hexpatch \"$1\" \\ 726f2e64616c76696b2e766d2e6e61746976652e62726964676500 \\ 726f2e7a79676f7465000000000000000000000000000000000000 } if [ -f /system/lib/libandroid_runtime.so ]; then cp -af /system/lib/libandroid_runtime.so \"$(magisk --path)/riru/libandroid_runtime.so.32\" magisk --clone-attr /system/lib/libandroid_runtime.so \"$(magisk --path)/riru/libandroid_runtime.so.32\" patch_lib \"$(magisk --path)/riru/libandroid_runtime.so.32\" mount --bind \"$(magisk --path)/riru/libandroid_runtime.so.32\" /system/lib/libandroid_runtime.so fi if [ -f /system/lib64/libandroid_runtime.so ]; then cp -af /system/lib64/libandroid_runtime.so \"$(magisk --path)/riru/libandroid_runtime.so.64\" magisk --clone-attr /system/lib64/libandroid_runtime.so \"$(magisk --path)/riru/libandroid_runtime.so.64\" patch_lib \"$(magisk --path)/riru/libandroid_runtime.so.64\" mount --bind \"$(magisk --path)/riru/libandroid_runtime.so.64\" /system/lib64/libandroid_runtime.so fi // restart zygote stop; start; 这里是service.sh新增的代码，从代码中可以看到操作步骤是提取libandroid_runtime.so-\u003epatch libandroid_runtime.so-\u003emount bind将修改同步，主要看patch的过程，将726f2e64616c76696b2e766d2e6e61746976652e62726964676500的hex值修改成726f2e7a79676f7465000000000000000000000000000000000000，也就是将ro.dalvik.vm.native.bridge修改成ro.zygote 为了保证libandroid_runtime.so的总体长度不变，这里额外补充了0来补位 而这么做的意义是什么呢？从libandroid_runtime.so的源码来看 // core/jni/AndroidRuntime.cpp // Native bridge library. \"0\" means that native bridge is disabled. // // Note: bridging is only enabled for the zygote. Other runs of // app_process may not have the permissions to mount etc. property_get(\"ro.dalvik.vm.native.bridge\", propBuf, \"\"); if (propBuf[0] == '\\0') { ALOGW(\"ro.dalvik.vm.native.bridge is not expected to be empty\"); } else if (zygote \u0026\u0026 strcmp(propBuf, \"0\") != 0) { snprintf(nativeBridgeLibrary, sizeof(\"-XX:NativeBridge=\") + PROPERTY_VALUE_MAX, \"-XX:NativeBridge=%s\", propBuf); addOption(nativeBridgeLibrary); } 将原先读取ro.dalvik.vm.native.bridge属性的地方改成了读取ro.zygote属性，避免了对ro.dalvik.vm.native.bridge的赋值，而ro.zygote属性在原生设备上已经赋值，当ro.zygote有值时，就会去加载/system/lib/$(getprop ro.zygote)的so文件 # template/magisk_module/post-fs-data.sh cd \"$MODDIR\" || exit flock \"module.prop\" mount --bind \"$TMPPROP\" \"$MODDIR/module.prop\" # 新增 ln -s ./libriruloader.so \"$MODDIR/system/lib/$(getprop ro.zygote)\" ln -s ./libriruloader.so \"$MODDIR/system/lib64/$(getprop ro.zygote)\" # unshare -m sh -c \"/system/bin/app_process -Djava.class.path=rirud.apk /system/bin --nice-name=rirud riru.Daemon $(magisk -V) $(magisk --path) $(getprop ro.dalvik.vm.native.bridge)\u0026\" umount \"$MODDIR/module.prop\" 而在post-fs-data阶段，又操作了软链，让/system/lib/$(getprop ro.zygote)实际指向的是libriruloader.so，从而完成libriruloader.so的加载 基本的实现流程就是这样，可以看出HuskyDG的这种方式还是很巧妙的，另外在实现这种方式的同时，HuskyDG也针对性的修改了原有代码和增加了maps隐藏的逻辑 // rirud/src/main/java/riru/DaemonUtils.java public static void resetNativeBridgeProp(String value) { //resetProperty(\"ro.dalvik.vm.native.bridge\", value); return; } 去除原有对于ro.dalvik.vm.native.bridge属性的修改，移除template/magisk_module/system.prop // riru/src/main/cpp/jni_hooks.cpp static std::vector\u003clsplt::MapInfo\u003e find_maps(const char *name) { auto maps = lsplt::MapInfo::Scan(); for (auto iter = maps.begin(); iter != maps.end();) { if (iter-\u003epath != name) { iter = maps.erase(iter); } else { ++iter; } } return maps; } void remap_all(const char *name) { // 过滤出带有libandroid_runtime.so的segment auto maps = find_maps(name); for (auto \u0026info : maps) { void *addr = reinterpret_cast\u003cvoid *\u003e(info.start); // 获取size size_t size = info.end - info.start; // 重新mmap申请内存地址 void *copy = mmap(nullptr, size, PROT_WRITE, MAP_ANONYMOUS | MAP_PRIVATE, -1, 0); // 设置读权限 if ((info.perms \u0026 PROT_READ) == 0) { mprotect(addr, size, PROT_READ); } // 复制到刚申请的内存上 memcpy(copy, addr, size); // 匹配大小 mremap(copy, size, size, MREMAP_MAYMOVE | MREMAP_FIXED, addr); // 重新授权 mprotect(addr, size, info.perms); } } void fakemap_file(const char *name) { a","date":"2023-08-18","objectID":"/posts/%E6%8E%A2%E8%AE%A8%E6%96%B0%E7%9A%84riru%E5%8A%A0%E8%BD%BD%E6%96%B9%E5%BC%8F/:0:2","tags":["riru原理"],"title":"探讨新的riru加载方式","uri":"/posts/%E6%8E%A2%E8%AE%A8%E6%96%B0%E7%9A%84riru%E5%8A%A0%E8%BD%BD%E6%96%B9%E5%BC%8F/"},{"categories":["riru"],"content":"二、新方式的思考 相比于老方式来说，新方案没有更改系统属性，而是借助于Magisk修改libandroid_runtime.so。来在HuskyDG的电报群内和一些开发者讨论过，都一致认为这种新方式所暴露出来的风险是大于老方案的，确实如HuskyDG所说，这种新方式只是一种探索吧 ","date":"2023-08-18","objectID":"/posts/%E6%8E%A2%E8%AE%A8%E6%96%B0%E7%9A%84riru%E5%8A%A0%E8%BD%BD%E6%96%B9%E5%BC%8F/:0:3","tags":["riru原理"],"title":"探讨新的riru加载方式","uri":"/posts/%E6%8E%A2%E8%AE%A8%E6%96%B0%E7%9A%84riru%E5%8A%A0%E8%BD%BD%E6%96%B9%E5%BC%8F/"},{"categories":null,"content":"一、前言 maps文件在Android中一般指/proc/pid/maps，记录着每个进程的内存映射信息，也就是每个进程都会有一个对应的文件。在之前的特征分析中，发现像dobby hook框架、frida等工具都会造成maps中的数据改变，因此想深入分析下这种特征的形成原因以及可以采用什么方式进行对抗 ","date":"2023-08-06","objectID":"/posts/maps%E7%89%B9%E5%BE%81%E6%A3%80%E6%B5%8B%E5%AF%B9%E6%8A%97/:0:1","tags":null,"title":"Maps特征检测对抗","uri":"/posts/maps%E7%89%B9%E5%BE%81%E6%A3%80%E6%B5%8B%E5%AF%B9%E6%8A%97/"},{"categories":null,"content":"二、maps文件形成 以微信进程为例，看看它的maps文件 selene:/ # cat /proc/9336/maps|head -n 10 020f4000-020f6000 r--p 00000000 fd:01 424 /system/bin/app_process32 020f6000-020fa000 r-xp 00001000 fd:01 424 /system/bin/app_process32 020fa000-020fb000 r--p 00004000 fd:01 424 /system/bin/app_process32 020fb000-020fc000 rw-p 00004000 fd:01 424 /system/bin/app_process32 020fc000-020fd000 rw-p 00000000 00:00 0 [anon:.bss] 12c00000-4af00000 rw-p 00000000 00:00 0 [anon:dalvik-main space (region space)] 57400000-57401000 ---p 00000000 00:00 0 [anon:partition_alloc] 57401000-57402000 rw-p 00000000 00:00 0 [anon:partition_alloc] 57402000-57404000 ---p 00000000 00:00 0 [anon:partition_alloc] 57404000-57430000 rw-p 00000000 00:00 0 [anon:partition_alloc] 从文件内容可以看到，每行内容都对应着一个地址段，可以划分为七列，在内核中每行数据使用vm_area_struct结构体，也就是VMA来表示 // include/linux/mm_types.h /* * This struct defines a memory VMM memory area. There is one of these * per VM-area/task. A VM area is any part of the process virtual memory * space that has a special rule for the page-fault handlers (ie a shared * library, the executable area etc). */ struct vm_area_struct { /* The first cache line has the info for VMA tree walking. */ unsigned long vm_start; /* Our start address within vm_mm. */ unsigned long vm_end; /* The first byte after our end address within vm_mm. */ /* linked list of VM areas per task, sorted by address */ struct vm_area_struct *vm_next, *vm_prev; struct rb_node vm_rb; /* * Largest free memory gap in bytes to the left of this VMA. * Either between this VMA and vma-\u003evm_prev, or between one of the * VMAs below us in the VMA rbtree and its -\u003evm_prev. This helps * get_unmapped_area find a free area of the right size. */ unsigned long rb_subtree_gap; /* Second cache line starts here. */ struct mm_struct *vm_mm; /* The address space we belong to. */ pgprot_t vm_page_prot; /* Access permissions of this VMA. */ unsigned long vm_flags; /* Flags, see mm.h. */ /* * For areas with an address space and backing store, * linkage into the address_space-\u003ei_mmap interval tree. * * For private anonymous mappings, a pointer to a null terminated string * in the user process containing the name given to the vma, or NULL * if unnamed. */ union { struct { struct rb_node rb; unsigned long rb_subtree_last; } shared; const char __user *anon_name; }; /* * A file's MAP_PRIVATE vma can be in both i_mmap tree and anon_vma * list, after a COW of one of the file pages. A MAP_SHARED vma * can only be in the i_mmap tree. An anonymous MAP_PRIVATE, stack * or brk vma (with NULL file) can only be in an anon_vma list. */ struct list_head anon_vma_chain; /* Serialized by mmap_sem \u0026 * page_table_lock */ struct anon_vma *anon_vma; /* Serialized by page_table_lock */ /* Function pointers to deal with this struct. */ const struct vm_operations_struct *vm_ops; /* Information about our backing store: */ unsigned long vm_pgoff; /* Offset (within vm_file) in PAGE_SIZE units */ struct file * vm_file; /* File we map to (can be NULL). */ void * vm_private_data; /* was vm_pte (shared mem) */ atomic_long_t swap_readahead_info; #ifndef CONFIG_MMU struct vm_region *vm_region; /* NOMMU mapping region */ #endif #ifdef CONFIG_NUMA struct mempolicy *vm_policy; /* NUMA policy for the VMA */ #endif struct vm_userfaultfd_ctx vm_userfaultfd_ctx; #ifdef CONFIG_SPECULATIVE_PAGE_FAULT seqcount_t vm_sequence; atomic_t vm_ref_count; /* see vma_get(), vma_put() */ #endif } __randomize_layout; 而最终展示到maps文件中的是以下七列 列数 对应的vm_area_struct属性 含义 “-”前一列，如00377000 vm_start 此段虚拟地址空间起始地址 “-”后一列，如00390000 vm_end 此段虚拟地址空间结束地址 第三列，如r-xp vm_flags 此段虚拟地址空间的属性。每种属性用一个字段表示，r表示可读，w表示可写，x表示可执行，p和s共用一个字段，互斥关系，p表示私有段，s表示共享段，如果没有相应权限，则用’-’代替 第四列，如00000000 vm_pgoff 对有名映射，表示此段虚拟内存起始地址在文件中以页为单位的偏移。对匿名映射，它等于0或者vm_start/PAGE_SIZE 第五列，如fd:00 vm_file-\u003ef_dentry-\u003ed_inode-\u003ei_sb-\u003es_dev 映射文件所属设备号。对匿名映射来说，因为没有文件在磁盘上，所以没有设备号，始终为00:00。对有名映射来说，是映射的文件所在设备的设备号 第六列，如9176473 vm_file-\u003ef_dentry-\u003ed_inode-\u003ei_ino 映射文件所属节点号。对匿名映射来说，因为没有文件在磁盘上，所以没有节点号，始终为00:00。对有名映射来说，是映射的文件的节点号 第七列，如/lib/ld-2.5.so 对有名来说","date":"2023-08-06","objectID":"/posts/maps%E7%89%B9%E5%BE%81%E6%A3%80%E6%B5%8B%E5%AF%B9%E6%8A%97/:0:2","tags":null,"title":"Maps特征检测对抗","uri":"/posts/maps%E7%89%B9%E5%BE%81%E6%A3%80%E6%B5%8B%E5%AF%B9%E6%8A%97/"},{"categories":null,"content":"三、maps特征 上面大概了解了maps的形成以及展示过程后，结合hook框架中常暴露的特征来说下 1 lsposed maps特征 目前手头上的项目是基于lsposed 1.6.0魔改的，因此以1.6.0的代码为例 // core/src/main/cpp/main/src/context.cpp void Context::OnNativeForkSystemServerPost(JNIEnv *env, jint res) { if (res != 0) return; if (!skip_) { LoadDex(env); Service::instance()-\u003eHookBridge(*this, env); auto binder = Service::instance()-\u003eRequestBinderForSystemServer(env); if (binder) { InstallInlineHooks(); Init(env); FindAndCall(env, \"forkSystemServerPost\", \"(Landroid/os/IBinder;)V\", binder); } else skip_ = true; } setAllowUnload(skip_); } void Context::OnNativeForkAndSpecializePost(JNIEnv *env) { const JUTFString process_name(env, nice_name_); auto binder = skip_ ? ScopedLocalRef\u003cjobject\u003e{env, nullptr} : Service::instance()-\u003eRequestBinder(env, nice_name_); if (binder) { InstallInlineHooks(); LoadDex(env); Init(env); LOGD(\"Done prepare\"); FindAndCall(env, \"forkAndSpecializePost\", \"(Ljava/lang/String;Ljava/lang/String;Landroid/os/IBinder;)V\", app_data_dir_, nice_name_, binder); LOGD(\"injected xposed into %s\", process_name.get()); setAllowUnload(false); } else { auto context = Context::ReleaseInstance(); auto service = Service::ReleaseInstance(); art_img.reset(); LOGD(\"skipped %s\", process_name.get()); setAllowUnload(true); } } 在ForkSystemServerPost和ForkAndSpecializePost函数时会触发inlinehook的操作 void InstallInlineHooks() { if (installed.exchange(true)) [[unlikely]] { LOGD(\"Inline hooks have been installed, skip\"); return; } LOGD(\"Start to install inline hooks\"); const auto \u0026handle_libart = *art_img; if (!handle_libart.isValid()) { LOGE(\"Failed to fetch libart.so\"); } art::Runtime::Setup(handle_libart); art::hidden_api::DisableHiddenApi(handle_libart); art::art_method::Setup(handle_libart); art::Thread::Setup(handle_libart); art::ClassLinker::Setup(handle_libart); art::mirror::Class::Setup(handle_libart); art::JNIEnvExt::Setup(handle_libart); art::instrumentation::DisableUpdateHookedMethodsCode(handle_libart); art::thread_list::ScopedSuspendAll::Setup(handle_libart); art::gc::ScopedGCCriticalSection::Setup(handle_libart); art::jit::jit_code_cache::Setup(handle_libart); art_img.reset(); LOGD(\"Inline hooks installed\"); } 主要是对libart.so的修改，以art::instrumentation::DisableUpdateHookedMethodsCode(handle_libart);为例 // core/src/main/cpp/main/include/art/runtime/instrumentation.h namespace art { namespace instrumentation { CREATE_MEM_HOOK_STUB_ENTRIES( \"_ZN3art15instrumentation15Instrumentation21UpdateMethodsCodeImplEPNS_9ArtMethodEPKv\", void, UpdateMethodsCode, (void * thiz, void * art_method, const void *quick_code), { if (lspd::isHooked(art_method)) [[unlikely]] { LOGD(\"Skip update method code for hooked method %s\", art_method::PrettyMethod(art_method).c_str()); return; } else { backup(thiz, art_method, quick_code); } }); inline void DisableUpdateHookedMethodsCode(const SandHook::ElfImg \u0026handle) { lspd::HookSym(handle, UpdateMethodsCode); } } } // core/src/main/cpp/main/include/base/object.h inline static bool HookSym(H \u0026\u0026handle, T \u0026arg) { auto original = Dlsym(std::forward\u003cH\u003e(handle), arg.sym); return HookSymNoHandle(original, arg); } inline static bool HookSymNoHandle(void *original, T \u0026arg) { if (original) { if constexpr(is_instance\u003cdecltype(arg.backup), MemberFunction\u003e::value) { void *backup; HookFunction(original, reinterpret_cast\u003cvoid *\u003e(arg.replace), \u0026backup); arg.backup = reinterpret_cast\u003ctypename decltype(arg.backup)::FunType\u003e(backup); } else { HookFunction(original, reinterpret_cast\u003cvoid *\u003e(arg.replace), reinterpret_cast\u003cvoid **\u003e(\u0026arg.backup)); } return true; } else { return false; } } inline int HookFunction(void *original, void *replace, void **backup) { _make_rwx(original, _page_size); if constexpr (isDebug) { Dl_info info; if (dladdr(original, \u0026info)) LOGD(\"Hooking %s (%p) from %s (%p)\", info.dli_sname ? info.dli_sname : \"(unknown symbol)\", info.dli_saddr, info.dli_fname ? info.dli_fname : \"(unknown file)\", info.dli_fbase); } return DobbyHook(original, replace, backup); } 这个版本的lsposed所使用到的inlinehook还是基于dobby hook来做的，而do","date":"2023-08-06","objectID":"/posts/maps%E7%89%B9%E5%BE%81%E6%A3%80%E6%B5%8B%E5%AF%B9%E6%8A%97/:0:3","tags":null,"title":"Maps特征检测对抗","uri":"/posts/maps%E7%89%B9%E5%BE%81%E6%A3%80%E6%B5%8B%E5%AF%B9%E6%8A%97/"},{"categories":null,"content":"四、对抗思路 复用riru_hide 具体流程可参考之前的文章-Riru原理理解，原理是将对应每个segment对应内存的数据替换，并去除文件关联 open重定向 例如内核层修改函数do_sys_open，返回指定伪装文件的fd来做展示，需要注意的是maps内容是随时变动的，那么伪装文件的生成也需要每次动态生成 内核层修改展示函数show_map_vma 代码可参考task_mmu.c，修改展示内容 ","date":"2023-08-06","objectID":"/posts/maps%E7%89%B9%E5%BE%81%E6%A3%80%E6%B5%8B%E5%AF%B9%E6%8A%97/:0:4","tags":null,"title":"Maps特征检测对抗","uri":"/posts/maps%E7%89%B9%E5%BE%81%E6%A3%80%E6%B5%8B%E5%AF%B9%E6%8A%97/"},{"categories":["hook框架"],"content":"一、背景 参考项目strongR-frida对frida14.2.18进行魔改 ","date":"2023-08-01","objectID":"/posts/strongr-frida%E7%89%B9%E5%BE%81%E9%AD%94%E6%94%B9/:0:1","tags":["frida","魔改思路"],"title":"StrongR Frida特征魔改","uri":"/posts/strongr-frida%E7%89%B9%E5%BE%81%E9%AD%94%E6%94%B9/"},{"categories":["hook框架"],"content":"二、魔改点 patch文件总共有八个，分别是对八个主要特征进行魔改，下面逐个分析下 1 0001-strongR-frida-string_frida_rpc.patch 针对frida-core/lib/interfaces/session.vala文件，修改了frida:rpc字符串，使用了base64 decode来隐去字符串的特征 具体修改如下 // .add_string_value (\"frida:rpc\") .add_string_value ((string) GLib.Base64.decode(\"ZnJpZGE6cnBj=\")) // if (raw_message.index_of (\"\\\"frida:rpc\\\"\") == -1) if (raw_message.index_of ((string) GLib.Base64.decode(\"ImZyaWRhOnJwYyI=\")) == -1) // if (type == null || type != \"frida:rpc\") if (type == null || type != (string) GLib.Base64.decode(\"ZnJpZGE6cnBj=\")) 原理 应对内存特征的扫描，App会对关键代码的可读代码段进行扫描，而frida:rpc是很明显的字符串特征，因此对字符串做了一层base来隐藏 2 0002-strongR-frida-io_re_frida_server.patch // private const string DEFAULT_DIRECTORY = \"re.frida.server\"; private static string DEFAULT_DIRECTORY = null; private static int main (string[] args) { DEFAULT_DIRECTORY = GLib.Uuid.string_random(); Environment.init (); 原理 re.frida.server是frida在启动时会创建的目录，里面有包括frida-agent等关键so，这些会在App的maps里面被检测到 3 0003-strongR-frida-pipe_linjector.patch // self-\u003efifo_path = g_strdup_printf (\"%s/linjector-%u\", self-\u003etemp_path, self-\u003eid); self-\u003efifo_path = g_strdup_printf (\"%s/%p%u\", self-\u003etemp_path, self ,self-\u003eid); 原理 linjector是linux上提供注入能力的工具，当frida注入进程时，可以在App的/proc/self/fd看到某个fd的软链是指向frida目录的linjector的 4 0004-strongR-frida-io_frida_agent_so.patch // agent = new AgentDescriptor (PathTemplate (\"frida-agent-\u003carch\u003e.so\"), var random_prefix = GLib.Uuid.string_random(); agent = new AgentDescriptor (PathTemplate (random_prefix + \"-\u003carch\u003e.so\"), // new AgentResource (\"frida-agent-arm.so\", new Bytes.static (emulated_arm.data), tempdir), // new AgentResource (\"frida-agent-arm64.so\", new Bytes.static (emulated_arm64.data), tempdir), new AgentResource (random_prefix + \"-arm.so\", new Bytes.static (emulated_arm.data), tempdir), new AgentResource (random_prefix + \"-arm64.so\", new Bytes.static (emulated_arm64.data), tempdir), 原理 和第二个是相同的，都是在maps中存在的特征 5 0005-strongR-frida-symbol_frida_agent_main.patch 针对frida-agent特征进行隐藏 // frida-core/src/agent-container.vala // var main_func_found = container.module.symbol (\"frida_agent_main\", out main_func_symbol); var main_func_found = container.module.symbol (\"main\", out main_func_symbol); // frida-core/src/darwin/darwin-host-session.vala // unowned string entrypoint = \"frida_agent_main\"; unowned string entrypoint = \"main\"; // frida-core/tests/test-injector.vala // yield injector.inject_library_file (process.id, path, \"frida_agent_main\", data); yield injector.inject_library_file (process.id, path, \"main\", data); // frida-core/tests/test-agent.vala // var main_func_found = module.symbol (\"frida_agent_main\", out main_func_symbol); var main_func_found = module.symbol (\"main\", out main_func_symbol); // frida-core/src/linux/linux-host-session.vala // string entrypoint = \"frida_agent_main\"; string entrypoint = \"main\"; // frida-core/src/windows/windows-host-session.vala // var id = yield winjector.inject_library_resource (pid, agent, \"frida_agent_main\", t.remote_address, cancellable); var id = yield winjector.inject_library_resource (pid, agent, \"main\", t.remote_address, cancellable); // frida-core/src/qnx/qnx-host-session.vala // var id = yield qinjector.inject_library_resource (pid, agent_desc, \"frida_agent_main\", t.remote_address, // cancellable); var id = yield qinjector.inject_library_resource (pid, agent_desc, \"main\", t.remote_address, cancellable); 原理 定位所有frida_agent_main进行隐藏 6 0006-strongR-frida-thread_gum_js_loop.patch 无 原理 7 0007-strongR-frida-thread_gmain.patch 无 原理 8 0008-strongR-frida-protocol_unexpected_command.patch case \"OPEN\": case \"CLSE\": case \"WRTE\": // throw new Error.PROTOCOL (\"Unexpected command\"); break; //throw new Error.PROTOCOL (\"Unexpected command\"); 原理 ","date":"2023-08-01","objectID":"/posts/strongr-frida%E7%89%B9%E5%BE%81%E9%AD%94%E6%94%B9/:0:2","tags":["frida","魔改思路"],"title":"StrongR Frida特征魔改","uri":"/posts/strongr-frida%E7%89%B9%E5%BE%81%E9%AD%94%E6%94%B9/"},{"categories":["系统定制"],"content":"一、编译环境搭建 1 物料准备 设备：红米note11（MIUI12 Android11） 原生super.img镜像文件，参考下载网站 2 工具准备 编译支撑系统：ubuntu14（经测试不受版本影响，正常来说ubuntu都可以安装所有的工具） simg2img lpunpack/lmake imjtool ","date":"2023-07-31","objectID":"/posts/super%E5%88%86%E5%8C%BA%E5%AE%9A%E5%88%B6/:0:1","tags":null,"title":"Super分区定制","uri":"/posts/super%E5%88%86%E5%8C%BA%E5%AE%9A%E5%88%B6/"},{"categories":["系统定制"],"content":"二、案例说明（内置应用） 1 镜像格式转化 正常image镜像都是Android sparse image格式的 (base) 大慈大悲观世音菩萨  ~/Projects/小米rom/原生12511/images  file super.img super.img: Android sparse image, version: 1.0, Total of 2197864 4096-byte output blocks in 4352 input chunks. 但是要挂载使用的话需要转换成data格式，利用到simg2img super.img super.raw.img命令，得到的文件如下 (base) 大慈大悲观世音菩萨  ~/tt  file super.img.raw super.img.raw: data 2 镜像拆解 Android10以上的设备通常都是动态分区，也就是system、vendor、product等逻辑分区合并成一个物理分区，可以使用imjtool来看当前镜像的具体信息 (base) 大慈大悲观世音菩萨  ~/tt  imjtool super.img.raw MMapped: 0x1103a2000, imgMeta 0x1103a3000 liblp dynamic partition (super.img) - Blocksize 0x1000, 3 slots LP MD Header @0x3000, version 10.2, with 6 logical partitions @0x0 on block device of 8704 GB, at partition super, first sector: 0x800 Partitions @0x3100 in 3 groups: Group 0: default Group 1: main_a Name: product_a (read-only, Linux Ext2/3/4/? Filesystem Image, @0x100000 spanning 1 extents of 237 MB) Name: vendor_a (read-only, Linux Ext2/3/4/? Filesystem Image, @0xef00000 spanning 1 extents of 869 MB) Name: system_a (read-only, Linux Ext2/3/4/? Filesystem Image, @0x45500000 spanning 1 extents of 4 GB) Group 2: main_b Name: product_b (read-only, empty) Name: vendor_b (read-only, empty) Name: system_b (read-only, Linux Ext2/3/4/? Filesystem Image, @0x161200000 spanning 1 extents of 345 MB) 默认镜像中存在三个槽，但实际上可用的只是两个槽，负责用来做AB分区转换的，但是小米使用的应该是VAB分区，B分区其实只是个假分区，通常都是空的 因此想要动其中的分区需要额外进行一步镜像拆解，需要利用到lpunpack工具，执行命令 lpunpack super.img.raw super/ 得到的拆解后的文件如下 (base) 大慈大悲观世音菩萨  ~/tt/super  ll total 15558584 -rw-r--r-- 1 linhanqiu staff 237M 4 24 16:35 product_a.img -rw-r--r-- 1 linhanqiu staff 0B 4 24 16:36 product_b.img drwxr-xr-x 2 linhanqiu staff 64B 4 24 16:39 sys1 -rw-r--r-- 1 linhanqiu staff 6.0G 5 8 18:13 system_a.img -rw-r--r-- 1 linhanqiu staff 346M 4 24 16:29 system_b.img -rw-r--r-- 1 linhanqiu staff 870M 4 24 16:36 vendor_a.img -rw-r--r-- 1 linhanqiu staff 0B 4 24 16:35 vendor_b.img 3 定制修改 修改的是system_a.img镜像，需要mount到指定目录上，但现在system_a.img的空间是满的，需要额外扩充空间保证我们的修改和新增生效，有的Linux系统可以直接使用fallocate命令，但是ubuntu不可以，替换成 dd if=system_a.img of=system_a.img bs=1G seek=7 count=0 resize2fs system_a.img 7G 原本的system_a.img是5G，现在额外扩展到7G mount -t ext4 -o loop system_a.img system 挂载到system目录上，可得到以下文件列表，根据自身需求修改即可 4 镜像重打包 针对system目录修改完成后，取消挂载 umount system 利用lpmake工具打包，具体的值需要计算 lpmake --metadata-size 65536 --device super:9002450944 --metadata-slots 3 --group main_a:7603306496 --partition product_a:none:248659968:main_a --partition system_a:none:6442450944:main_a --partition vendor_a:none:912195584:main_a --image product_a=./product_a.img --image system_a=./system_a.img --image vendor_a=./vendor_a.img --group main_b:362688512 --partition system_b:none:362688512:main_b --image system_b=./system_b.img --sparse --output ./super.new.img ","date":"2023-07-31","objectID":"/posts/super%E5%88%86%E5%8C%BA%E5%AE%9A%E5%88%B6/:0:2","tags":null,"title":"Super分区定制","uri":"/posts/super%E5%88%86%E5%8C%BA%E5%AE%9A%E5%88%B6/"},{"categories":["riru"],"content":"一、前言 什么是riru？正如它Github上面所提到的那样，它提供的能力是允许模块能够将自己的代码注入到各个App进程或者是system_server进程中，而这一切的实现就是基于它对于zygote进程的注入。 那具体是怎么对于zygote进行注入的呢？文档中也提到，在早期的版本中，riru通过替换libmemtrack.so这个系统库的方式，原因是一方面zygote会加载该系统库，另一方面则是因为这个库足够小，仅仅只有十个函数，也就意味着替换掉它所造成的影响面是很小的，但是后续来看，由于使用到这个so的进程比较多，除了zygote还有SurfaceFlinger（用于显示系统）、mediaserver（用于媒体处理）等等，因此会造成一些意想不到的错误。 因此在v22，riru使用了一个新的注入方式，设置native bridge，也就是指定ro.dalvik.vm.native.bridge的值为riri的so来实现注入，这个思路是来源于canyie的一篇文章通过系统的native bridge实现注入zygote，它的原理大概是 void AndroidRuntime::start(const char* className, const Vector\u003cString8\u003e\u0026 options, bool zygote) { ALOGD(\"\u003e\u003e\u003e\u003e\u003e\u003e START %s uid %d \u003c\u003c\u003c\u003c\u003c\u003c\\n\", className != NULL ? className : \"(unknown)\", getuid()); /* start the virtual machine */ JniInvocation jni_invocation; jni_invocation.Init(NULL); JNIEnv* env; // 启动虚拟机 if (startVm(\u0026mJavaVM, \u0026env, zygote, primary_zygote) != 0) { return; } onVmCreated(env); } int AndroidRuntime::startVm(JavaVM** pJavaVM, JNIEnv** pEnv, bool zygote, bool primary_zygote) { JavaVMInitArgs initArgs; // ... // Native bridge library. \"0\" means that native bridge is disabled. // // Note: bridging is only enabled for the zygote. Other runs of // app_process may not have the permissions to mount etc. // 读取ro.dalvik.vm.native.bridge属性 property_get(\"ro.dalvik.vm.native.bridge\", propBuf, \"\"); if (propBuf[0] == '\\0') { ALOGW(\"ro.dalvik.vm.native.bridge is not expected to be empty\"); } else if (zygote \u0026\u0026 strcmp(propBuf, \"0\") != 0) { snprintf(nativeBridgeLibrary, sizeof(\"-XX:NativeBridge=\") + PROPERTY_VALUE_MAX, \"-XX:NativeBridge=%s\", propBuf); addOption(nativeBridgeLibrary); } // ... initArgs.version = JNI_VERSION_1_4; initArgs.options = mOptions.editArray(); initArgs.nOptions = mOptions.size(); initArgs.ignoreUnrecognized = JNI_FALSE; /* * Initialize the VM. * * The JavaVM* is essentially per-process, and the JNIEnv* is per-thread. * If this call succeeds, the VM is ready, and we can start issuing * JNI calls. */ if (JNI_CreateJavaVM(pJavaVM, pEnv, \u0026initArgs) \u003c 0) { ALOGE(\"JNI_CreateJavaVM failed\\n\"); return -1; } return 0; } bool Runtime::Init(RuntimeArgumentMap\u0026\u0026 runtime_options_in) { // ... // Look for a native bridge. // // The intended flow here is, in the case of a running system: // // Runtime::Init() (zygote): // LoadNativeBridge -\u003e dlopen from cmd line parameter. // | // V // Runtime::Start() (zygote): // No-op wrt native bridge. // | // | start app // V // DidForkFromZygote(action) // action = kUnload -\u003e dlclose native bridge. // action = kInitialize -\u003e initialize library // // // The intended flow here is, in the case of a simple dalvikvm call: // // Runtime::Init(): // LoadNativeBridge -\u003e dlopen from cmd line parameter. // | // V // Runtime::Start(): // DidForkFromZygote(kInitialize) -\u003e try to initialize any native bridge given. // No-op wrt native bridge. { std::string native_bridge_file_name = runtime_options.ReleaseOrDefault(Opt::NativeBridge); // 加载native bridge is_native_bridge_loaded_ = LoadNativeBridge(native_bridge_file_name); } // ... } bool LoadNativeBridge(const char* nb_library_filename, const NativeBridgeRuntimeCallbacks* runtime_cbs) { // We expect only one place that calls LoadNativeBridge: Runtime::Init. At that point we are not // multi-threaded, so we do not need locking here. if (nb_library_filename == nullptr || *nb_library_filename == 0) { CloseNativeBridge(false); return false; } else { if (!NativeBridgeNameAcceptable(nb_library_filename)) { CloseNativeBridge(true); } else { // Try to open the library. // 调用dlopen打开指定so void* handle = dlopen(nb_library_filename, RTLD_LAZY); if (handle != nullptr) { callbacks = reinterpret_cast\u003cNativeBridgeCallbacks*\u003e(dlsym(handle, kNativeBridgeInterfaceSymbol)); if (callbacks != nullptr) { if (isCompatibleWith(NAMESPACE_VERSION)) { // Store the handle for later. native_bridge_handle = handle; } else { callbacks = nullptr; dlclose(handle); ALOGW(\"Unsupported native bridge interface.\"); } } else { dlclose(handle); } } // Two failure conditions: could not find library (dlopen failed), or could ","date":"2023-07-25","objectID":"/posts/riru%E5%8E%9F%E7%90%86%E7%90%86%E8%A7%A3/:0:1","tags":["riru原理"],"title":"Riru原理理解","uri":"/posts/riru%E5%8E%9F%E7%90%86%E7%90%86%E8%A7%A3/"},{"categories":["riru"],"content":"二、实现细节 1 riru结构 先从riru的项目结构入手，riru是个Magisk模块，自然是以Magisk模块模板为基础，首先来看看Magisk模块模板都具备哪些 参考开发者文档，Magisk模块都会放在/data/adb/modules目录下，结构如 /data/adb/modules ├── . ├── . | ├── $MODID 模块名称 \u003c--- The folder is named with the ID of the module │ │ │ │ *** Module Identity *** │ │ │ ├── module.prop 模块的基础信息 \u003c--- This file stores the metadata of the module │ │ │ │ *** Main Contents *** │ │ │ ├── system 挂载到system目录 \u003c--- This folder will be mounted if skip_mount does not exist │ │ ├── ... │ │ ├── ... │ │ └── ... │ │ │ ├── zygisk \u003c--- This folder contains the module's Zygisk native libraries │ │ ├── arm64-v8a.so │ │ ├── armeabi-v7a.so │ │ ├── x86.so │ │ ├── x86_64.so │ │ └── unloaded \u003c--- If exists, the native libraries are incompatible │ │ │ │ *** Status Flags *** │ │ │ ├── skip_mount \u003c--- If exists, Magisk will NOT mount your system folder │ ├── disable \u003c--- If exists, the module will be disabled │ ├── remove \u003c--- If exists, the module will be removed next reboot │ │ │ │ *** Optional Files *** │ │ │ ├── post-fs-data.sh 定制脚本 \u003c--- This script will be executed in post-fs-data │ ├── service.sh \u003c--- This script will be executed in late_start service | ├── uninstall.sh \u003c--- This script will be executed when Magisk removes your module │ ├── system.prop 系统属性修改 \u003c--- Properties in this file will be loaded as system properties by resetprop │ ├── sepolicy.rule sepolicy规则修改 \u003c--- Additional custom sepolicy rules │ │ │ │ *** Auto Generated, DO NOT MANUALLY CREATE OR MODIFY *** │ │ │ ├── vendor \u003c--- A symlink to $MODID/system/vendor │ ├── product \u003c--- A symlink to $MODID/system/product │ ├── system_ext \u003c--- A symlink to $MODID/system/system_ext │ │ │ │ *** Any additional files / folders are allowed *** │ │ │ ├── ... │ └── ... | ├── another_module │ ├── . │ └── . ├── . ├── . 再看看模块的安装过程 module.zip │ ├── META-INF │ └── com │ └── google │ └── android │ ├── update-binary \u003c--- The module_installer.sh you downloaded │ └── updater-script \u003c--- Should only contain the string \"#MAGISK\" │ ├── customize.sh \u003c--- (Optional, more details later) │ This script will be sourced by update-binary ├── ... ├── ... /* The rest of module's files */ customize.sh和update-binary是互相配合来完成安装过程中定制的部分 具体看看riru修改了 module.prop id=${id} name=${name} version=${version} versionCode=${versionCode} author=${author} description=${description} riruApi=${riruApi} riruMinApi=${riruMinApi} 设置全局变量 post-fs-data #!/system/bin/sh MODDIR=${0%/*} TMPPROP=\"$(magisk --path)/riru.prop\" MIRRORPROP=\"$(magisk --path)/.magisk/modules/riru-core/module.prop\" sh -Cc \"cat '$MODDIR/module.prop' \u003e '$TMPPROP'\" if [ $? -ne 0 ]; then exit fi mount --bind \"$TMPPROP\" \"$MIRRORPROP\" if [ \"$ZYGISK_ENABLE\" = \"1\" ]; then sed -Ei 's/^description=(\\[.*][[:space:]]*)?/description=[ ⛔ Riru is not loaded because of Zygisk. ] /g' \"$MIRRORPROP\" exit fi sed -Ei 's/^description=(\\[.*][[:space:]]*)?/description=[ ⛔ app_process fails to run. ] /g' \"$MIRRORPROP\" cd \"$MODDIR\" || exit flock \"module.prop\" mount --bind \"$TMPPROP\" \"$MODDIR/module.prop\" unshare -m sh -c \"/system/bin/app_process -Djava.class.path=rirud.apk /system/bin --nice-name=rirud riru.Daemon $(magisk -V) $(magisk --path) $(getprop ro.dalvik.vm.native.bridge)\u0026\" umount \"$MODDIR/module.prop\" 主要在于使用unshare资源隔离的方式启动rirud的守护进程，和magiskd类似，都是在post-fs-data阶段启动的 system.prop ro.dalvik.vm.native.bridge=libriruloader.so 最关键的修改，修改了ro.dalvik.vm.native.bridge属性指向libriruloader.so customize // template/magisk_module/customize.sh // 文件解压 if [ \"$ARCH\" = \"x86\" ] || [ \"$ARCH\" = \"x64\" ]; then ui_print \"- Extracting x86 libraries\" extract \"$ZIPFILE\" 'lib/x86/libriru.so' \"$MODPATH/lib\" true extract \"$ZIPFILE\" 'lib/x86/libriruhide.so' \"$MODPATH/lib\" true extract \"$ZIPFILE\" 'lib/x86/libriruloader.so' \"$MODPATH/system/lib\" true if [ \"$IS64BIT\" = true ]; then ui_print \"- Extracting x64 libraries\" extract \"$ZIPFILE\" 'lib/x86_64/libriru.so' \"$MODPATH/lib64\" true extract \"$ZIPFILE\" 'lib/x86_64/libriruhide.so' \"$MODPATH/lib64\" true extract \"$ZIPFILE\" 'lib/x86_64/libriruloader.so' \"$MODPATH/system/lib64\" true fi else","date":"2023-07-25","objectID":"/posts/riru%E5%8E%9F%E7%90%86%E7%90%86%E8%A7%A3/:0:2","tags":["riru原理"],"title":"Riru原理理解","uri":"/posts/riru%E5%8E%9F%E7%90%86%E7%90%86%E8%A7%A3/"},{"categories":["Magisk生态"],"content":"一、前言 同样的，作为一个riru模块，从该项目的简介中，就可以发现它的主要作用了 Riru - MomoHider (aka IsolatedMagiskHider) 主要针对isolated进程所做的隐藏，MomoHider提供了几个配置选项来从多个角度隐藏MagiskHide，如下 配置项 说明 isolated 对每一个isolated processes卸载magisk相关的文件，但是无法控制卸载时机，可能会导致部分模块无法正常使用 setns 在isolated processes中能够更快隐藏Magisk app_zygote_magic 让momo无法检测到MagiskHide是运行状态 initrc 隐藏修改init.rc的堆栈 这些配置应该是作者最初的想法，现在某些配置已经无法正常使用了，所以还是从源码中看看现在这个模块具体做了哪些事 ","date":"2023-07-16","objectID":"/posts/riru-momohider%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:0:1","tags":["Magisk Hide隐藏"],"title":"Riru MomoHider源码分析","uri":"/posts/riru-momohider%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":["Magisk生态"],"content":"二、源码分析 从riru模块的入口main.cpp入手 // 配置了五个自定义方法 static auto module = RiruVersionedModuleInfo { .moduleApiVersion = RIRU_NEW_MODULE_API_VERSION, .moduleInfo = RiruModuleInfo { .supportHide = true, .version = RIRU_MODULE_VERSION_CODE, .versionName = RIRU_MODULE_VERSION_NAME, .onModuleLoaded = onModuleLoaded, .shouldSkipUid = nullptr, .forkAndSpecializePre = forkAndSpecializePre, .forkAndSpecializePost = forkAndSpecializePost, .forkSystemServerPre = nullptr, .forkSystemServerPost = nullptr, .specializeAppProcessPre = specializeAppProcessPre, .specializeAppProcessPost = specializeAppProcessPost } }; // 变量定义 // module目录 const char* module_dir_ = nullptr; // 配置值，可以看到关于initrc的参数是没有设置了 constexpr const char* kSetNs = \"setns\"; constexpr const char* kMagicHandleAppZygote = \"app_zygote_magic\"; constexpr const char* kMagiskTmp = \"magisk_tmp\"; constexpr const char* kIsolated = \"isolated\"; const char* magisk_tmp_ = nullptr; bool magic_handle_app_zygote_ = false; bool hide_isolated_ = false; bool in_child_ = false; bool isolated_ = false; bool app_zygote_ = false; bool no_new_ns_ = false; jstring* nice_name_ = nullptr; bool use_nsholder_ = false; char* nsholder_mnt_ns_ = nullptr; pid_t nsholder_pid_ = -1; pid_t (*orig_fork)() = nullptr; int (*orig_unshare)(int) = nullptr; int* riru_allow_unload = nullptr; 1 onModuleLoaded void onModuleLoaded() { // magisk加载模块时会分配给模块特定目录 LOGI(\"Magisk module dir is %s\", module_dir_); // 分配给magisk tmp的目录，路径是module_dir_/config/magisk_tmp magisk_tmp_ = ReadMagiskTmp(); LOGI(\"Magisk temp path is %s\", magisk_tmp_); // 读取配置文件，也就是看config目录下是否存在这些配置文件，存在则表明开启这些配置 hide_isolated_ = Exists(kIsolated); magic_handle_app_zygote_ = Exists(kMagicHandleAppZygote); use_nsholder_ = Exists(kSetNs); RegisterHooks(); } void RegisterHooks() { if (!hide_isolated_ \u0026\u0026 !magic_handle_app_zygote_) return; // 使用xhook xhook_enable_debug(1); xhook_enable_sigsegv_protection(0); bool failed = false; // 定义hook函数 #define HOOK(NAME, REPLACE) \\ failed = failed || RegisterHook(#NAME, reinterpret_cast\u003cvoid*\u003e(REPLACE), reinterpret_cast\u003cvoid**\u003e(\u0026orig_##NAME)) // hook fork函数 HOOK(fork, ForkReplace); if (hide_isolated_) { // hook unshare函数 HOOK(unshare, UnshareReplace); } #undef HOOK if (failed || xhook_refresh(0)) { LOGE(\"Failed to register hooks!\"); return; } xhook_clear(); } bool RegisterHook(const char* name, void* replace, void** backup) { int ret = xhook_register(\".*\\\\libandroid_runtime.so$\", name, replace, backup); if (ret != 0) { LOGE(\"Failed to hook %s\", name); return true; } return false; } 在加载该模块时，主要做的事情是读取用户自定义的配置文件，并通过xhook hook了fork函数和unshare函数，具体hook操作如下 1.1 ForkReplace pid_t ForkReplace() { int read_fd = -1, write_fd = -1; #if !USE_NEW_APP_ZYGOTE_MAGIC // 创建管道，用于后续进程通信 if (app_zygote_ \u0026\u0026 magic_handle_app_zygote_) { int pipe_fd[2]; if (pipe(pipe_fd) == -1) { LOGE(\"Failed to create pipe for new app zygote: %s\", strerror(errno)); } else { read_fd = pipe_fd[0]; write_fd = pipe_fd[1]; } } #endif // 调用原始fork方法 pid_t pid = orig_fork(); // pid\u003c0，fork失败，清理管道 if (pid \u003c 0) { #if !USE_NEW_APP_ZYGOTE_MAGIC // fork() failed, clean up if (read_fd != -1) close(read_fd); if (write_fd != -1) close(write_fd); #endif } else if (pid == 0) { // 正常情况的两种情况，第一种事pid=0，也就是子进程中 // child process // Do not hide here because the namespace not separated in_child_ = true; #if !USE_NEW_APP_ZYGOTE_MAGIC if (read_fd != -1 \u0026\u0026 write_fd != -1) { close(read_fd); // 获取新pid pid_t new_pid = MagicHandleAppZygote(); // 向管道中写入新pid值 WriteIntAndClose(write_fd, new_pid); } #endif } else { #if !USE_NEW_APP_ZYGOTE_MAGIC // parent process if (read_fd != -1 \u0026\u0026 write_fd != -1) { close(write_fd); // 读取子进程写入的pid值 pid = ReadIntAndClose(read_fd); LOGI(\"Zygote received new substitute pid %d\", pid); } #endif } return pid; } #if !USE_NEW_APP_ZYGOTE_MAGIC pid_t MagicHandleAppZygote() { // 在子进程中进一步调用fork，返回子进程的子进程的pid LOGI(\"Magic handling app zygote\"); // App zygote, fork a new process to run it (after forking magiskhide detachs) // This makes some detection not working (but also can be easily detected) pi","date":"2023-07-16","objectID":"/posts/riru-momohider%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:0:2","tags":["Magisk Hide隐藏"],"title":"Riru MomoHider源码分析","uri":"/posts/riru-momohider%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":["系统定制"],"content":"以红米Note11内核改机为例说明 sys.c：内核版本 statfs.c：文件信息 stat.c：文件信息 readdir.c：目录下的文件列表 open.c：文件重定向 ","date":"2023-07-10","objectID":"/posts/%E5%9F%BA%E4%BA%8E%E5%86%85%E6%A0%B8%E7%9A%84%E6%94%B9%E6%9C%BA%E7%AD%96%E7%95%A5/:0:0","tags":["内核编译","内核改机"],"title":"基于内核的改机策略","uri":"/posts/%E5%9F%BA%E4%BA%8E%E5%86%85%E6%A0%B8%E7%9A%84%E6%94%B9%E6%9C%BA%E7%AD%96%E7%95%A5/"},{"categories":["Magisk生态"],"content":"一、前言 在之前的Magisk检测方式的文章中，提到过isolated process的概念，MagiskHide无法处理这种进程，因为它和zygote共同使用同一个namespace，如果对这类进程进行unmount的话，会导致所有app都无法正正常访问到su，对于这种情况，可以使用riru-unshare模块来处理使指定的独立进程不与zygote共享namespace ","date":"2023-07-04","objectID":"/posts/riru-unshare%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:0:1","tags":["Magisk Hide隐藏"],"title":"Riru Unshare源码分析","uri":"/posts/riru-unshare%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":["Magisk生态"],"content":"二、源码分析 riru-unshare是一个riru模块，看源码就从从main.cpp入手 #ifndef RIRU_MODULE_LEGACY_INIT RiruVersionedModuleInfo *init(Riru *riru) { auto core_max_api_version = riru-\u003eriruApiVersion; riru_api_version = core_max_api_version \u003c= RIRU_MODULE_API_VERSION ? core_max_api_version : RIRU_MODULE_API_VERSION; module.moduleApiVersion = riru_api_version; riru_magisk_module_path = strdup(riru-\u003emagiskModulePath); if (riru_api_version \u003e= 25) { riru_allow_unload = riru-\u003eallowUnload; } return \u0026module; } #else RiruVersionedModuleInfo *init(Riru *riru) { static int step = 0; step += 1; switch (step) { case 1: { auto core_max_api_version = riru-\u003eriruApiVersion; riru_api_version = core_max_api_version \u003c= RIRU_MODULE_API_VERSION ? core_max_api_version : RIRU_MODULE_API_VERSION; if (riru_api_version \u003c 25) { module.moduleInfo.unused = (void *) shouldSkipUid; } else { riru_allow_unload = riru-\u003eallowUnload; } if (riru_api_version \u003e= 24) { module.moduleApiVersion = riru_api_version; riru_magisk_module_path = strdup(riru-\u003emagiskModulePath); return \u0026module; } else { return (RiruVersionedModuleInfo *) \u0026riru_api_version; } } case 2: { return (RiruVersionedModuleInfo *) \u0026module.moduleInfo; } case 3: default: { return nullptr; } } } #endif } 配置需要替换的函数 static auto module = RiruVersionedModuleInfo{ .moduleApiVersion = RIRU_MODULE_API_VERSION, .moduleInfo= RiruModuleInfo{ .supportHide = true, .version = RIRU_MODULE_VERSION, .versionName = RIRU_MODULE_VERSION_NAME, .onModuleLoaded = nullptr, .forkAndSpecializePre = forkAndSpecializePre, .forkAndSpecializePost = forkAndSpecializePost, .forkSystemServerPre = nullptr, .forkSystemServerPost = nullptr, .specializeAppProcessPre = specializeAppProcessPre, .specializeAppProcessPost = specializeAppProcessPost } }; 主要是四个函数forkAndSpecializePre、forkAndSpecializePost、specializeAppProcessPre和specializeAppProcessPost 在zygote fork产生新进程前后做处理 1 forkAndSpecializePre 在forck出一个新的子进程前被调用，处理工作如设置UID、GID、环境变量等等，选择在forkAndSpecializePre阶段做doUnshare处理也是防止进程正常启动后无法再改变namespace static void forkAndSpecializePre( JNIEnv *env, jclass clazz, jint *uid, jint *gid, jintArray *gids, jint *runtimeFlags, jobjectArray *rlimits, jint *mountExternal, jstring *seInfo, jstring *niceName, jintArray *fdsToClose, jintArray *fdsToIgnore, jboolean *is_child_zygote, jstring *instructionSet, jstring *appDataDir, jboolean *isTopApp, jobjectArray *pkgDataInfoList, jobjectArray *whitelistedDataInfoList, jboolean *bindMountAppDataDirs, jboolean *bindMountAppStorageDirs) { //应用启动前调用 doUnshare(env, uid, mountExternal, niceName, *is_child_zygote); } static void doUnshare(JNIEnv *env, jint *uid, jint *mountExternal, jstring *niceName, bool is_child_zygote) { //uid判断 if (shouldSkipUid(*uid)) return; // 改变mount状态 if (*mountExternal == 0) { *mountExternal = 1; ScopedUtfChars name(env, *niceName); is_app_zygote = is_child_zygote \u0026\u0026 is_app(*uid); nice_name_ = niceName; LOGI(\"unshare uid=%d name=%s app_zygote=%s\", *uid, name.c_str(), is_app_zygote?\"true\":\"false\"); } } static int shouldSkipUid(int uid) { int appid = uid % AID_USER_OFFSET; if (appid \u003e= AID_APP_START \u0026\u0026 appid \u003c= AID_APP_END) return false; if (appid \u003e= AID_ISOLATED_START \u0026\u0026 appid \u003c= AID_ISOLATED_END) return false; return true; } static bool is_app(int uid) { return uid%100000 \u003e= 10000 \u0026\u0026 uid%100000 \u003c= 19999; } 关键在于mountExternal这个参数的修改，那这个参数的作用是什么呢？从zygote源码中看看 private Process.ProcessStartResult startViaZygote(@NonNull final String processClass, @Nullable final String niceName, final int uid, final int gid, @Nullable final int[] gids, int runtimeFlags, int mountExternal, int targetSdkVersion, @Nullable String seInfo, @NonNull String abi, @Nullable String instructionSet, @Nullable String appDataDir, @Nullable String invokeWith, boolean startChildZygote, @Nullable String packageName, int zygotePolicyFlags, boolean isTopApp, @Nullable long[] disabledCompatChanges, @Nullable Map\u003cString, Pair\u003cString, Long\u003e\u003e pkgDataInfoMap, @Nullable Map\u003cString, Pair\u003cString, Long\u003e\u003e allowlistedDataInfoList, boolean bindMountAppsData, boolean bindMou","date":"2023-07-04","objectID":"/posts/riru-unshare%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:0:2","tags":["Magisk Hide隐藏"],"title":"Riru Unshare源码分析","uri":"/posts/riru-unshare%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":["系统定制"],"content":"前言 涉及到需要隐藏设备特征，所以需要编译内核来抹除暴露出的特征。小米内核有现成的源码，可以根据自身设备的型号来选择，下面简单描述下编译流程 ","date":"2023-06-30","objectID":"/posts/%E7%BA%A2%E7%B1%B3note11%E5%86%85%E6%A0%B8%E7%BC%96%E8%AF%91%E6%B5%81%E7%A8%8B/:0:1","tags":["内核编译"],"title":"红米Note11内核编译流程","uri":"/posts/%E7%BA%A2%E7%B1%B3note11%E5%86%85%E6%A0%B8%E7%BC%96%E8%AF%91%E6%B5%81%E7%A8%8B/"},{"categories":["系统定制"],"content":"一、编译环境搭建 1 物料准备 设备：红米note11（MIUI12 Android11） 源码：selene版本内核源码 需要注意的是note11(selenes)是国内的叫法，而国际版对应的是红米10(selene) 原生boot.img镜像文件，参考下载网站 2 工具准备 编译支撑系统：ubuntu18 参照官方文档的版本来的，不过经过测试，使用ubuntu14的话会导致某些三方库安装失败 三方库预装 sudo apt-get install git ccache automake flex lzop bison \\ gperf build-essential zip curl zlib1g-dev zlib1g-dev:i386 \\ g++-multilib python-networkx libxml2-utils bzip2 libbz2-dev \\ libbz2-1.0 libghc-bzlib-dev squashfs-tools pngcrush \\ schedtool dpkg-dev liblz4-tool make optipng maven libssl-dev \\ pwgen libswitch-perl policycoreutils minicom libxml-sax-base-perl \\ libxml-simple-perl bc libc6-dev-i386 lib32ncurses5-dev \\ x11proto-core-dev libx11-dev lib32z-dev libgl1-mesa-dev xsltproc unzip 编译工具链准备 clang：c/c++编译工具 lineage：交叉编译工具 一键编译脚本 CLANG_BIN=\"clang-r383902/bin\" //需要需要路径 GCC_BIN=\"android_prebuilts_gcc_linux-x86_aarch64_aarch64-linux-android-4.9-lineage-19.1/bin\" //需要需要路径 export PATH=\"$CLANG_BIN:$GCC_BIN:$PATH\" export PLATFORM_VERSION=11.0 ARCH=arm64 make CC=clang HOSTCC=gcc AR=llvm-ar NM=llvm-nm OBJCOPY=llvm-objcopy OBJDUMP=llvm-objdump STRIP=llvm-strip O=out CLANG_TRIPLE=aarch64-linux-gnu- CROSS_COMPILE=aarch64-linux-androidkernel- LD=ld.lld selene_defconfig ARCH=arm64 make CC=clang HOSTCC=gcc AR=llvm-ar NM=llvm-nm OBJCOPY=llvm-objcopy OBJDUMP=llvm-objdump STRIP=llvm-strip O=out CLANG_TRIPLE=aarch64-linux-gnu- CROSS_COMPILE=aarch64-linux-androidkernel- LD=ld.lld -j 6 boot.img解包打开工具 Android_boot_image_editor ","date":"2023-06-30","objectID":"/posts/%E7%BA%A2%E7%B1%B3note11%E5%86%85%E6%A0%B8%E7%BC%96%E8%AF%91%E6%B5%81%E7%A8%8B/:0:2","tags":["内核编译"],"title":"红米Note11内核编译流程","uri":"/posts/%E7%BA%A2%E7%B1%B3note11%E5%86%85%E6%A0%B8%E7%BC%96%E8%AF%91%E6%B5%81%E7%A8%8B/"},{"categories":["系统定制"],"content":"二、编译错误修复 1 文件缺失 错误提示如下 ../drivers/input/touchscreen/mediatek/FT8719P/focaltech_flash.c:60:10: fatal error: 'include/firmware/fw_sample.i' file not found 在drivers/input/touchscreen/mediatek/focaltech_touch/include/firmware目录下添加fw_sample.i文件 fw_sample.i文件内容从fw_sample.i中复制 2 方法重复定义 错误提示如下 ld.lld: error: duplicate symbol: mtk_vcu_mem_init \u003e\u003e\u003e defined at mtk_vcodec_mem.c:29 (/home/linhanqiu/proj/Xiaomi_Kernel_OpenSource/out/../drivers/media/platform/mtk-vcu/mtk_vcodec_mem.c:29) \u003e\u003e\u003e drivers/media/platform/mtk-vcu/mtk_vcodec_mem.o:(mtk_vcu_mem_init) in archive built-in.o \u003e\u003e\u003e defined at mtk_vcodec_mem.c:29 (/home/linhanqiu/proj/Xiaomi_Kernel_OpenSource/out/../drivers/media/platform/mtk-vcu/mtk_vcodec_mem.c:29) \u003e\u003e\u003e drivers/media/platform/mtk-vcu/mtk_vcodec_mem.o:(.text+0x0) in archive built-in.o ld.lld: error: duplicate symbol: mtk_vcu_mem_release \u003e\u003e\u003e defined at mtk_vcodec_mem.c:53 (/home/linhanqiu/proj/Xiaomi_Kernel_OpenSource/out/../drivers/media/platform/mtk-vcu/mtk_vcodec_mem.c:53) \u003e\u003e\u003e drivers/media/platform/mtk-vcu/mtk_vcodec_mem.o:(mtk_vcu_mem_release) in archive built-in.o \u003e\u003e\u003e defined at mtk_vcodec_mem.c:53 (/home/linhanqiu/proj/Xiaomi_Kernel_OpenSource/out/../drivers/media/platform/mtk-vcu/mtk_vcodec_mem.c:53) \u003e\u003e\u003e drivers/media/platform/mtk-vcu/mtk_vcodec_mem.o:(.text+0xBC) in archive built-in.o ld.lld: error: duplicate symbol: mtk_vcu_set_buffer \u003e\u003e\u003e defined at mtk_vcodec_mem.c:100 (/home/linhanqiu/proj/Xiaomi_Kernel_OpenSource/out/../drivers/media/platform/mtk-vcu/mtk_vcodec_mem.c:100) \u003e\u003e\u003e drivers/media/platform/mtk-vcu/mtk_vcodec_mem.o:(mtk_vcu_set_buffer) in archive built-in.o \u003e\u003e\u003e defined at mtk_vcodec_mem.c:100 (/home/linhanqiu/proj/Xiaomi_Kernel_OpenSource/out/../drivers/media/platform/mtk-vcu/mtk_vcodec_mem.c:100) \u003e\u003e\u003e drivers/media/platform/mtk-vcu/mtk_vcodec_mem.o:(.text+0x24C) in archive built-in.o ld.lld: error: duplicate symbol: mtk_vcu_get_buffer \u003e\u003e\u003e defined at mtk_vcodec_mem.c:184 (/home/linhanqiu/proj/Xiaomi_Kernel_OpenSource/out/../drivers/media/platform/mtk-vcu/mtk_vcodec_mem.c:184) \u003e\u003e\u003e drivers/media/platform/mtk-vcu/mtk_vcodec_mem.o:(mtk_vcu_get_buffer) in archive built-in.o \u003e\u003e\u003e defined at mtk_vcodec_mem.c:184 (/home/linhanqiu/proj/Xiaomi_Kernel_OpenSource/out/../drivers/media/platform/mtk-vcu/mtk_vcodec_mem.c:184) \u003e\u003e\u003e drivers/media/platform/mtk-vcu/mtk_vcodec_mem.o:(.text+0x5D0) in archive built-in.o ld.lld: error: duplicate symbol: mtk_vcu_get_page \u003e\u003e\u003e defined at slab.h:522 (/home/linhanqiu/proj/Xiaomi_Kernel_OpenSource/out/../include/linux/slab.h:522) \u003e\u003e\u003e drivers/media/platform/mtk-vcu/mtk_vcodec_mem.o:(mtk_vcu_get_page) in archive built-in.o \u003e\u003e\u003e defined at slab.h:522 (/home/linhanqiu/proj/Xiaomi_Kernel_OpenSource/out/../include/linux/slab.h:522) \u003e\u003e\u003e drivers/media/platform/mtk-vcu/mtk_vcodec_mem.o:(.text+0x748) in archive built-in.o ld.lld: error: duplicate symbol: mtk_vcu_free_buffer \u003e\u003e\u003e defined at mtk_vcodec_mem.c:251 (/home/linhanqiu/proj/Xiaomi_Kernel_OpenSource/out/../drivers/media/platform/mtk-vcu/mtk_vcodec_mem.c:251) \u003e\u003e\u003e drivers/media/platform/mtk-vcu/mtk_vcodec_mem.o:(mtk_vcu_free_buffer) in archive built-in.o \u003e\u003e\u003e defined at mtk_vcodec_mem.c:251 (/home/linhanqiu/proj/Xiaomi_Kernel_OpenSource/out/../drivers/media/platform/mtk-vcu/mtk_vcodec_mem.c:251) \u003e\u003e\u003e drivers/media/platform/mtk-vcu/mtk_vcodec_mem.o:(.text+0x850) in archive built-in.o 修改参考：重复定义异常 3 驱动文件缺失 原因是未加载wlan相关的驱动，官方代码只是内核相关的，需要将wlan驱动内嵌到内核源码中 修改参考：驱动异常 复制到Xiaomi_Kernel_OpenSource/drivers/misc/mediatek/connectivity这个目录下面，并且修改connectivity里面的Kconfig文件，增加启用模块编译 config WLAN_DRV_BUILD_IN bool \"Build Wlan module in kernel\" default y //默认启用 help This will build the wlan driver and the corresponding componenets into the kernel. If unsure say n ","date":"2023-06-30","objectID":"/posts/%E7%BA%A2%E7%B1%B3note11%E5%86%85%E6%A0%B8%E7%BC%96%E8%AF%91%E6%B5%81%E7%A8%8B/:0:3","tags":["内核编译"],"title":"红米Note11内核编译流程","uri":"/posts/%E7%BA%A2%E7%B1%B3note11%E5%86%85%E6%A0%B8%E7%BC%96%E8%AF%91%E6%B5%81%E7%A8%8B/"},{"categories":["系统定制"],"content":"三、正式编译与boot重打包 将上面的环境、工具以及修复后的源码准备好就可以正式开始编译了，编译的产物是内核，而最终刷入系统的boot.img，因此整个流程大致可以看成如下： boot.img解包-\u003e内核编译-\u003e内核替换-\u003eboot.img重打包 1 boot.img解包 使用Android_boot_image_editor来处理解包打包，先把boot.img放在在Android_boot_image_editor目录下后执行./gradlew unpack命令，下面是输出结果 Starting a Gradle Daemon (subsequent builds will be faster) \u003e Task :unpack 20:00:53.716 [main] WARN cfig.packable.PackableLauncher - [boot.img] will be handled by [BootImgParser] 20:00:53.817 [main] WARN cfig.packable.PackableLauncher - 'unpack' sequence initialized 20:00:53.820 [main] INFO cfig.packable.IPackable - deleting build/unzip_boot/ ... 20:00:54.190 [main] INFO Helper - deleting uiderrors 20:00:54.198 [main] INFO cfig.packable.BootImgParser - header version 2 20:00:54.397 [main] WARN cfig.bootimg.v2.BootHeaderV2 - BootImgHeader constructor 20:00:54.417 [main] INFO cfig.Avb - python aosp/avb/avbtool.v1.2.py verify_image --image boot.img Verifying image boot.img using embedded public key vbmeta: Successfully verified footer and SHA256_RSA2048 vbmeta struct in boot.img boot: Successfully verified sha256 hash of boot.img for image of 30773248 bytes 20:00:55.460 [main] INFO KernelExtractor - [aosp/make/tools/extract_kernel.py, --input, build/unzip_boot/kernel, --output-configs, build/unzip_boot/kernel_configs.txt, --output-version, build/unzip_boot/kernel_version.txt] 20:00:55.464 [main] INFO KernelExtractor - kernel version: [4.14.186] 20:00:55.464 [main] INFO KernelExtractor - kernel config dumped to : build/unzip_boot/kernel_configs.txt 20:00:56.329 [main] INFO ZipHelper - decompress(gz) done: build/unzip_boot/ramdisk.img.gz -\u003e build/unzip_boot/ramdisk.img 20:00:56.332 [main] INFO cfig.bootimg.cpio.AndroidCpio - Cleaning /Users/linhanqiu/Projects/Android_boot_image_editor/build/unzip_boot/root ... 20:00:56.358 [main] WARN cfig.bootimg.cpio.AndroidCpio - root/config has improper file mode 555, fix it 20:00:57.293 [main] WARN cfig.bootimg.cpio.AndroidCpio - root/system/bin/logd has improper file mode 550, fix it 20:00:57.629 [main] INFO cfig.bootimg.cpio.AndroidCpio - cpio trailer found, mode=000001ed 20:00:57.631 [main] INFO cfig.bootimg.Common - ramdisk extracted : build/unzip_boot/ramdisk.img -\u003e build/unzip_boot/root 20:00:57.647 [main] INFO cfig.utils.DTC - parsing DTB: build/unzip_boot/dtb FATAL ERROR: Blob has incorrect magic number 20:00:57.683 [main] ERROR cfig.utils.DTC - can not parse DTB: build/unzip_boot/dtb 20:00:57.687 [main] INFO avb.AVBInfo - parseFrom(FILE:boot.img) ... 20:00:57.723 [main] INFO avb.AVBInfo - FILE:boot.img: Glance(footer=Footer(versionMajor=1, versionMinor=0, originalImageSize=30773248, vbMetaOffset=30773248, vbMetaSize=1600), vbMetaOffset=30773248).footer 20:00:57.837 [main] INFO avb.AVBInfo - VBMeta: boot.img -\u003e build/unzip_boot/boot.avb.json 20:00:58.013 [main] INFO cfig.Avb - signed with release key: 'Xiaomi Phone' by Mi 20:00:58.028 [main] WARN cfig.Avb - Found key: PublicKey(device='Xiaomi Phone' by 'Mi', algorithm='SHA256_RSA2048', sha1='b2a02f1e56e366d727a1a8e089762fe0b91bbc84') 20:00:58.079 [main] INFO cfig.bootimg.v2.BootV2 - Unpack Summary of boot.img ┌───────────────────────────────────────┬──────────────────────────────────────┐ │What │Where │ └───────────────────────────────────────┴──────────────────────────────────────┘ ┌───────────────────────────────────────┬──────────────────────────────────────┐ │image info │build/unzip_boot/boot.json │ ├───────────────────────────────────────┼──────────────────────────────────────┤ │AVB info [verified] │build/unzip_boot/boot.avb.json │ │\\-- signing key │Xiaomi Phone by Mi │ ├───────────────────────────────────────┼──────────────────────────────────────┤ │kernel │build/unzip_boot/kernel │ │\\-- version [4.14.186] │build/unzip_boot/kernel_version.txt │ │\\-- config │build/unzip_boot/kernel_configs.txt │ ├───────────────────────────────────────┼──────────────────────────────────────┤ │ramdisk │build/unzip_boot/ramdisk.img.gz │ │\\-- extracted ramdisk rootfs │build/unzip_boot/root │ ├───────────────────","date":"2023-06-30","objectID":"/posts/%E7%BA%A2%E7%B1%B3note11%E5%86%85%E6%A0%B8%E7%BC%96%E8%AF%91%E6%B5%81%E7%A8%8B/:0:4","tags":["内核编译"],"title":"红米Note11内核编译流程","uri":"/posts/%E7%BA%A2%E7%B1%B3note11%E5%86%85%E6%A0%B8%E7%BC%96%E8%AF%91%E6%B5%81%E7%A8%8B/"},{"categories":["Magisk"],"content":"前言 Magisk内部实现细节的第四篇，在前两篇着重讲了Magisk的三个重要功能的两个—su以及hide，这篇就来分析下最后一个重要功能—resetprop，这三个功能Magisk也分别导出了三个可执行文件 // native/jni/core/applets.cpp static main_fun applet_main[] = { su_client_main, resetprop_main, magiskhide_main, nullptr }; static int call_applet(int argc, char *argv[]) { // Applets string_view base = basename(argv[0]); for (int i = 0; applet_names[i]; ++i) { if (base == applet_names[i]) { // 根据可执行文件的名称执行具体的类方法 return (*applet_main[i])(argc, argv); } } #if ENABLE_INJECT if (str_starts(base, \"app_process\")) { return app_process_main(argc, argv); } #endif fprintf(stderr, \"%s: applet not found\\n\", base.data()); return 1; } ","date":"2023-06-27","objectID":"/posts/%E9%87%8D%E8%AF%BBmagisk%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%824/:0:1","tags":["源码分析"],"title":"重读Magisk内部实现细节4","uri":"/posts/%E9%87%8D%E8%AF%BBmagisk%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%824/"},{"categories":["Magisk"],"content":"一、Magisk Resetprop入口 // native/jni/resetprop/resetprop.cpp int resetprop_main(int argc, char *argv[]) { log_cb.d = [](auto fmt, auto ap) -\u003e int { return verbose ? vfprintf(stderr, fmt, ap) : 0; }; bool prop_svc = true; bool persist = false; char *argv0 = argv[0]; --argc; ++argv; // Parse flags and -- options while (argc \u0026\u0026 argv[0][0] == '-') { for (int idx = 1; true; ++idx) { switch (argv[0][idx]) { case '-': if (strcmp(argv[0], \"--file\") == 0 \u0026\u0026 argc == 2) { load_prop_file(argv[1], prop_svc); return 0; } else if (strcmp(argv[0], \"--delete\") == 0 \u0026\u0026 argc == 2) { return delprop(argv[1], persist); } else if (strcmp(argv[0], \"--help\") == 0) { usage(argv0); } case 'v': verbose = true; continue; case 'p': persist = true; continue; case 'n': prop_svc = false; continue; case '\\0': break; case 'h': default: usage(argv0); } break; } --argc; ++argv; } switch (argc) { case 0: print_props(persist); return 0; case 1: { string prop = getprop(argv[0], persist); if (prop.empty()) return 1; printf(\"%s\\n\", prop.data()); return 0; } case 2: return setprop(argv[0], argv[1], prop_svc); default: usage(argv0); } } 功能不多，除了开始对命令行参数的解析，再就是print_props、getprop、setprop，从字面上很容易了解它们的含义，先从print_props类看 1 impl初始化 print_props也就是批量获取getprop // native/jni/resetprop/resetprop.cpp static void print_props(bool persist) { getprops([](const char *name, const char *value, auto) { printf(\"[%s]: [%s]\\n\", name, value); }, nullptr, persist); } void getprops(void (*callback)(const char *, const char *, void *), void *cookie, bool persist) { get_impl()-\u003egetprops(callback, cookie, persist); } 首先先初始化impl // native/jni/resetprop/resetprop.cpp static sysprop_stub *get_impl() { static sysprop_stub *impl = nullptr; if (impl == nullptr) { // 判断/data/property/persistent_properties是否可读 use_pb = access(PERSISTENT_PROPERTY_DIR \"/persistent_properties\", R_OK) == 0; #ifdef APPLET_STUB_MAIN if (__system_properties_init()) { LOGE(\"resetprop: __system_properties_init error\\n\"); exit(1); } impl = new resetprop(); #else // Load platform implementations // dlsym查找相关system_property方法 load_functions(); if (__system_properties_init()) { LOGW(\"resetprop: __system_properties_init error\\n\"); impl = new sysprop(); } else { impl = new resetprop(); } #endif } return impl; } // native/jni/external/systemproperties/system_property_api.cpp int __system_properties_init() { // 传入/dev/__properties__ return system_properties.Init(PROP_FILENAME) ? 0 : -1; } // native/jni/external/systemproperties/system_properties.cpp bool SystemProperties::Init(const char* filename) { // This is called from __libc_init_common, and should leave errno at 0 (http://b/37248982). ErrnoRestorer errno_restorer; if (initialized_) { /* resetprop remove */ // contexts_-\u003eResetAccess(); return true; } if (strlen(filename) \u003e= PROP_FILENAME_MAX) { return false; } strcpy(property_filename_, filename); if (is_dir(property_filename_)) { if (access(\"/dev/__properties__/property_info\", R_OK) == 0) { contexts_ = new (contexts_data_) ContextsSerialized(); if (!contexts_-\u003eInitialize(false, property_filename_, nullptr)) { return false; } } else { contexts_ = new (contexts_data_) ContextsSplit(); if (!contexts_-\u003eInitialize(false, property_filename_, nullptr)) { return false; } } } else { contexts_ = new (contexts_data_) ContextsPreSplit(); if (!contexts_-\u003eInitialize(false, property_filename_, nullptr)) { return false; } } initialized_ = true; return true; } 2 getprop 3 setprop ","date":"2023-06-27","objectID":"/posts/%E9%87%8D%E8%AF%BBmagisk%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%824/:0:2","tags":["源码分析"],"title":"重读Magisk内部实现细节4","uri":"/posts/%E9%87%8D%E8%AF%BBmagisk%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%824/"},{"categories":["Magisk"],"content":"前言 Magisk内部实现细节的第三篇，主要通过源码来了解下Magisk Hide的原理，这部分代码在native/jni/magiskhide当中 ","date":"2023-06-18","objectID":"/posts/%E9%87%8D%E8%AF%BBmagisk%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%823/:0:1","tags":["源码分析"],"title":"重读Magisk内部实现细节3","uri":"/posts/%E9%87%8D%E8%AF%BBmagisk%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%823/"},{"categories":["Magisk"],"content":"一、Magisk Hide入口 不管是在Magisk Manager中管理Magisk Hide object MagiskHide : BaseSettingsItem.Toggle() { override val title = R.string.magiskhide.asText() override val description = R.string.settings_magiskhide_summary.asText() override var value = Config.magiskHide set(value) = setV(value, field, { field = it }) { val cmd = if (it) \"enable\" else \"disable\" Shell.su(\"magiskhide $cmd\").submit { cb -\u003e if (cb.isSuccess) Config.magiskHide = it else field = !it } } } 还是通过adb shell来管理Magisk Hide (base) 大慈大悲观世音菩萨  ~  adb shell selene:/ $ su selene:/ # magiskhide status MagiskHide is not enabled 1|selene:/ # magiskhide enable selene:/ # magiskhide status MagiskHide is enabled selene:/ # 其底层都是通过magiskhide这个二进制文件来触发的，而magiskhide的入口是 // native/jni/magiskhide/magiskhide.cpp // 入口函数 int magiskhide_main(int argc, char *argv[]) { if (argc \u003c 2) usage(argv[0]); // CLI backwards compatibility const char *opt = argv[1]; if (opt[0] == '-' \u0026\u0026 opt[1] == '-') opt += 2; int req; // 选择触发的指令 if (opt == \"enable\"sv) req = LAUNCH_MAGISKHIDE; else if (opt == \"disable\"sv) req = STOP_MAGISKHIDE; else if (opt == \"add\"sv) req = ADD_HIDELIST; else if (opt == \"rm\"sv) req = RM_HIDELIST; else if (opt == \"ls\"sv) req = LS_HIDELIST; else if (opt == \"status\"sv) req = HIDE_STATUS; else if (opt == \"exec\"sv \u0026\u0026 argc \u003e 2) { xunshare(CLONE_NEWNS); xmount(nullptr, \"/\", nullptr, MS_PRIVATE | MS_REC, nullptr); hide_unmount(); execvp(argv[2], argv + 2); exit(1); } #if 0 \u0026\u0026 !ENABLE_INJECT else if (opt == \"test\"sv) test_proc_monitor(); #endif else usage(argv[0]); // 同样需要和daemon进行交互 // Send request int fd = connect_daemon(); write_int(fd, MAGISKHIDE); write_int(fd, req); if (req == ADD_HIDELIST || req == RM_HIDELIST) { write_string(fd, argv[2]); write_string(fd, argv[3] ? argv[3] : \"\"); } // Get response int code = read_int(fd); switch (code) { case DAEMON_SUCCESS: break; case HIDE_NOT_ENABLED: fprintf(stderr, \"MagiskHide is not enabled\\n\"); goto return_code; case HIDE_IS_ENABLED: fprintf(stderr, \"MagiskHide is enabled\\n\"); goto return_code; case HIDE_ITEM_EXIST: fprintf(stderr, \"Target already exists in hide list\\n\"); goto return_code; case HIDE_ITEM_NOT_EXIST: fprintf(stderr, \"Target does not exist in hide list\\n\"); goto return_code; case HIDE_NO_NS: fprintf(stderr, \"Your kernel doesn't support mount namespace\\n\"); goto return_code; case HIDE_INVALID_PKG: fprintf(stderr, \"Invalid package / process name\\n\"); goto return_code; case ROOT_REQUIRED: fprintf(stderr, \"Root is required for this operation\\n\"); goto return_code; case DAEMON_ERROR: default: fprintf(stderr, \"Daemon error\\n\"); return DAEMON_ERROR; } if (req == LS_HIDELIST) { string res; for (;;) { read_string(fd, res); if (res.empty()) break; printf(\"%s\\n\", res.data()); } } return_code: return req == HIDE_STATUS ? (code == HIDE_IS_ENABLED ? 0 : 1) : code != DAEMON_SUCCESS; 而对于daemon进程来说，处理magiskhide传来的指令，具体的处理逻辑还是在magiskhide.cpp中 // native/jni/core/daemon.cpp static void request_handler(int client, int req_code, ucred cred) { switch (req_code) { case MAGISKHIDE: magiskhide_handler(client, \u0026cred); break; ...... // native/jni/magiskhide/magiskhide.cpp void magiskhide_handler(int client, ucred *cred) { int req = read_int(client); int res = DAEMON_ERROR; ...... switch (req) { // magiskhide启动 case LAUNCH_MAGISKHIDE: res = launch_magiskhide(true); break; // magiskhide关闭 case STOP_MAGISKHIDE: res = stop_magiskhide(); break; // 新增需要隐藏的app case ADD_HIDELIST: res = add_list(client); break; // 移除 case RM_HIDELIST: res = rm_list(client); break; case LS_HIDELIST: ls_list(client); return; case HIDE_STATUS: res = hide_enabled() ? HIDE_IS_ENABLED : HIDE_NOT_ENABLED; break; #if ENABLE_INJECT case REMOTE_CHECK_HIDE: res = check_uid_map(client); break; case REMOTE_DO_HIDE: kill(cred-\u003epid, SIGSTOP); write_int(client, 0); hide_daemon(cred-\u003epid); close(client); return; #endif } write_int(client, res); close(client); } ","date":"2023-06-18","objectID":"/posts/%E9%87%8D%E8%AF%BBmagisk%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%823/:0:2","tags":["源码分析"],"title":"重读Magisk内部实现细节3","uri":"/posts/%E9%87%8D%E8%AF%BBmagisk%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%823/"},{"categories":["Magisk"],"content":"二、Magisk Hide指令分析 1 LAUNCH_MAGISKHIDE // native/jni/magiskhide/hide_utils.cpp // 开启magiskhide int launch_magiskhide(bool late_props) { // 锁申请 mutex_guard lock(hide_state_lock); // 判断全局变量hide_state的值，如果已经启动直接返回 if (hide_state) return HIDE_IS_ENABLED; // 检测是否有访问namespace的权限 if (access(\"/proc/self/ns/mnt\", F_OK) != 0) return HIDE_NO_NS; // 复制procfp if (procfp == nullptr \u0026\u0026 (procfp = opendir(\"/proc\")) == nullptr) return DAEMON_ERROR; LOGI(\"* Enable MagiskHide\\n\"); // 初始化hide_set并杀死相关进程 // Initialize the hide list if (!init_list()) return DAEMON_ERROR; // 替换prop属性 hide_sensitive_props(); if (late_props) // 针对vendor.boot.verifiedbootstate进行替换 hide_late_sensitive_props(); #if !ENABLE_INJECT // Start monitoring // 创建监控线程monitor_thread if (new_daemon_thread(\u0026proc_monitor)) return DAEMON_ERROR; #endif // 更新当前magiskhide状态 hide_state = true; // 更新settings里的magiskhide配置 update_hide_config(); // 释放锁 // Unlock here or else we'll be stuck in deadlock lock.unlock(); // 更新uid_proc_map，需要隐藏的app的uid对应进程名 update_uid_map(); return DAEMON_SUCCESS; } 2 STOP_MAGISKHIDE // native/jni/magiskhide/hide_utils.cpp int stop_magiskhide() { mutex_guard g(hide_state_lock); if (hide_state) { LOGI(\"* Disable MagiskHide\\n\"); // 清理工作 uid_proc_map.clear(); hide_set.clear(); #if !ENABLE_INJECT // 向monitor_thread发送自定义信号SIGTERMTHRD pthread_kill(monitor_thread, SIGTERMTHRD); #endif } // 更新当前magiskhide状态 hide_state = false; // 更新settings里的magiskhide配置 update_hide_config(); return DAEMON_SUCCESS; } 3 ADD_HIDELIST // native/jni/magiskhide/hide_utils.cpp int add_list(int client) { string pkg = read_string(client); string proc = read_string(client); int ret = add_list(pkg.data(), proc.data()); if (ret == DAEMON_SUCCESS) // 更新uid_proc_map update_uid_map(); return ret; } static int add_list(const char *pkg, const char *proc) { if (proc[0] == '\\0') proc = pkg; if (!validate(pkg, proc)) return HIDE_INVALID_PKG; for (auto \u0026hide : hide_set) if (hide.first == pkg \u0026\u0026 hide.second == proc) return HIDE_ITEM_EXIST; // Add to database char sql[4096]; // 写入hidelist数据表 snprintf(sql, sizeof(sql), \"INSERT INTO hidelist (package_name, process) VALUES('%s', '%s')\", pkg, proc); char *err = db_exec(sql); db_err_cmd(err, return DAEMON_ERROR); { // Critical region mutex_guard lock(hide_state_lock); // 更新hide_set add_hide_set(pkg, proc); } return DAEMON_SUCCESS; } 可以看出，首先在Magisk Hide中有三个存储结构用来做Magisk Hide的管理工作 hide_set: 存储需要隐藏功能的包名-进程名 uid_proc_map: 根据hide_set集合来存储对应App的uid以及进程名映射 hidelist: 数据表，供展示时使用 其次，可以看到在Magisk Hide启动时会额外启动monitor_thread这个线程，而这个就是Magisk Hide隐藏功能的核心 ","date":"2023-06-18","objectID":"/posts/%E9%87%8D%E8%AF%BBmagisk%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%823/:0:3","tags":["源码分析"],"title":"重读Magisk内部实现细节3","uri":"/posts/%E9%87%8D%E8%AF%BBmagisk%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%823/"},{"categories":["Magisk"],"content":"三、Magisk Hide原理 跟进monitor_thread 1 信号处理 // native/jni/magiskhide/proc_monitor.cpp // 设置该线程为monitor_thread，并于后续清理 monitor_thread = pthread_self(); // Backup original mask // 获取当前线程的信号掩码保存在orin_mask sigset_t orig_mask; pthread_sigmask(SIG_SETMASK, nullptr, \u0026orig_mask); // 清空信号集并初始化 sigset_t unblock_set; sigemptyset(\u0026unblock_set); sigaddset(\u0026unblock_set, SIGTERMTHRD); sigaddset(\u0026unblock_set, SIGIO); sigaddset(\u0026unblock_set, SIGALRM); // 设置信号处理函数集合 struct sigaction act{}; sigfillset(\u0026act.sa_mask); act.sa_handler = SIG_IGN; sigaction(SIGTERMTHRD, \u0026act, nullptr); sigaction(SIGIO, \u0026act, nullptr); sigaction(SIGALRM, \u0026act, nullptr); // 防止信号积压处理 // Temporary unblock to clear pending signals pthread_sigmask(SIG_UNBLOCK, \u0026unblock_set, nullptr); pthread_sigmask(SIG_SETMASK, \u0026orig_mask, nullptr); // 使用term_thread来处理SIGTERMTHRD信号 act.sa_handler = term_thread; sigaction(SIGTERMTHRD, \u0026act, nullptr); // 使用inotify_event处理SIGIO信号 act.sa_handler = inotify_event; sigaction(SIGIO, \u0026act, nullptr); // 使用check_zygote处理SIGALRM信号 act.sa_handler = [](int){ check_zygote(); }; sigaction(SIGALRM, \u0026act, nullptr); setup_inotify(); static void setup_inotify() { // 创建inotify实例时指定了IN_CLOEXEC标志位，表示将inotify实例设置为 close-on-exec 模式。 // 在close-on-exec模式下，当进程调用exec函数时，inotify实例会自动关闭 inotify_fd = xinotify_init1(IN_CLOEXEC); if (inotify_fd \u003c 0) return; // Setup inotify asynchronous I/O // 设置inotify文件描述符的异步通知和所有权 fcntl(inotify_fd, F_SETFL, O_ASYNC); struct f_owner_ex ex = { .type = F_OWNER_TID, .pid = gettid() }; fcntl(inotify_fd, F_SETOWN_EX, \u0026ex); // 监控/data/system的写入并关闭事件 // Monitor packages.xml inotify_add_watch(inotify_fd, \"/data/system\", IN_CLOSE_WRITE); // 监控app_process的被访问的事件，也就是监控App // Monitor app_process if (access(APP_PROC \"32\", F_OK) == 0) { inotify_add_watch(inotify_fd, APP_PROC \"32\", IN_ACCESS); if (access(APP_PROC \"64\", F_OK) == 0) inotify_add_watch(inotify_fd, APP_PROC \"64\", IN_ACCESS); } else { inotify_add_watch(inotify_fd, APP_PROC, IN_ACCESS); } } 这个部分主要做的事是 设置信号处理函数，信号分别是SIGTERMTHRD、SIGIO、SIGALRM 启动inotify，fd写入inotify_fd，监控/system/bin/app_process的access事件，重点在于packages.xml文件的写入 2 ptrace Zygote check_zygote(); if (!is_zygote_done()) { // 如果获取到zygote，则每250ms发送SIGALRM信号触发check_zygote // Periodic scan every 250ms timeval val { .tv_sec = 0, .tv_usec = 250000 }; itimerval interval { .it_interval = val, .it_value = val }; setitimer(ITIMER_REAL, \u0026interval, nullptr); } static void check_zygote() { crawl_procfs([](int pid) -\u003e bool { char buf[512]; snprintf(buf, sizeof(buf), \"/proc/%d/cmdline\", pid); if (FILE *f = fopen(buf, \"re\")) { fgets(buf, sizeof(buf), f); if (strncmp(buf, \"zygote\", 6) == 0 \u0026\u0026 parse_ppid(pid) == 1) new_zygote(pid); fclose(f); } return true; }); if (is_zygote_done()) { // Stop periodic scanning timeval val { .tv_sec = 0, .tv_usec = 0 }; itimerval interval { .it_interval = val, .it_value = val }; setitimer(ITIMER_REAL, \u0026interval, nullptr); } } static DIR *procfp; // procfp在之前已经被赋值成/proc目录 void crawl_procfs(const function\u003cbool(int)\u003e \u0026fn) { // 指针重置到目录起始位置 rewinddir(procfp); crawl_procfs(procfp, fn); } // 遍历proc目录，获取zygote的pid void crawl_procfs(DIR *dir, const function\u003cbool(int)\u003e \u0026fn) { struct dirent *dp; int pid; while ((dp = readdir(dir))) { pid = parse_int(dp-\u003ed_name); if (pid \u003e 0 \u0026\u0026 !fn(pid)) break; } } static void new_zygote(int pid) { struct stat st; // 读取zygote挂载的namespace信息 if (read_ns(pid, \u0026st)) return; // 更新或者存储st到zygote_map auto it = zygote_map.find(pid); if (it != zygote_map.end()) { // Update namespace info it-\u003esecond = st; return; } LOGD(\"proc_monitor: ptrace zygote PID=[%d]\\n\", pid); zygote_map[pid] = st; // ptrace attach到zygote进程 xptrace(PTRACE_ATTACH, pid); // 等待zygote进程状态变化 waitpid(pid, nullptr, __WALL | __WNOTHREAD); 监控zygote fork/vfork/exit事件 xptrace(PTRACE_SETOPTIONS, pid, nullptr, PTRACE_O_TRACEFORK | PTRACE_O_TRACEVFORK | PTRACE_O_TRACEEXIT); // 恢复zygote进程执行 xptrace(PTRACE_CONT, pid); } 这一部分的作用是轮询判断zygote进程是否启动以及ptrace attach到zygote以便于监控到zygote的fork操作（引导启动App进程） 3 子进程信号处理 for (int status;;) { // 解除信号阻塞，获取信号 pthread_sigmask(SI","date":"2023-06-18","objectID":"/posts/%E9%87%8D%E8%AF%BBmagisk%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%823/:0:4","tags":["源码分析"],"title":"重读Magisk内部实现细节3","uri":"/posts/%E9%87%8D%E8%AF%BBmagisk%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%823/"},{"categories":["Magisk生态"],"content":"一、市面现存的检测方式 1 Magisk Detector 来源于Magisk Detector（现已停止维护），我们可以从官方的细节文档看出它之前的设计思路 ，目前从最新的代码上看，仅仅存在三种检测方式 JNINativeMethod methods[] = { {\"haveSu\", \"()I\", haveSu}, {\"haveMagiskHide\", \"()I\", haveMagiskHide}, {\"haveMagicMount\", \"()I\", haveMagicMount}, }; 1.1 su文件检测 检测方式 static int scan_path() { char *path = getenv(\"PATH\"); char *p = strtok(path, \":\"); char supath[PATH_MAX]; do { sprintf(supath, \"%s/su\", p); if (access(supath, F_OK) == 0) { LOGW(\"Found su at %s\", supath); return 1; } } while ((p = strtok(NULL, \":\")) != NULL); return 0; } 代码比较少，很容易理解，通过获取系统环境变量path的值来确定当前有哪些可执行文件的目录，再依次遍历这些目录检测是否存在su文件，系统环境变量path内的路径通常是 selene:/ $ echo $PATH /product/bin:/apex/com.android.runtime/bin:/apex/com.android.art/bin:/system_ext/bin:/system/bin:/system/xbin:/odm/bin:/vendor/bin:/vendor/xbin selene:/ $ 思路 之所以要检测这些可执行文件的目录是否存在su文件是因为正常情况下，root过的手机都会依照传统方式通过执行su命令来提权切换到root用户下，那这就依靠在这些可执行文件的目录下放置su文件。对于Magisk来说，同样也是在每次启动后去动态修改bin目录，先是将magisk、magiskinit放入自身文件下的bin目录，再将例如su、magiskhide等做magisk的软链，最后通过bind mount同步到真实的bin目录下达到修改bin的效果 // native/jni/core/module.cpp static void inject_magisk_bins(root_node *system) { auto bin = system-\u003echild\u003cinter_node\u003e(\"bin\"); if (!bin) { bin = new inter_node(\"bin\", \"\"); system-\u003einsert(bin); } // Insert binaries bin-\u003einsert(new magisk_node(\"magisk\")); bin-\u003einsert(new magisk_node(\"magiskinit\")); // Also delete all applets to make sure no modules can override it for (int i = 0; applet_names[i]; ++i) delete bin-\u003eextract(applet_names[i]); for (int i = 0; init_applet[i]; ++i) delete bin-\u003eextract(init_applet[i]); } class magisk_node : public node_entry { public: explicit magisk_node(const char *name) : node_entry(name, DT_REG, this) {} void mount() override { const string \u0026dir_name = parent()-\u003enode_path(); if (name() == \"magisk\") { for (int i = 0; applet_names[i]; ++i) { string dest = dir_name + \"/\" + applet_names[i]; VLOGD(\"create\", \"./magisk\", dest.data()); xsymlink(\"./magisk\", dest.data()); } } else { for (int i = 0; init_applet[i]; ++i) { string dest = dir_name + \"/\" + init_applet[i]; VLOGD(\"create\", \"./magiskinit\", dest.data()); xsymlink(\"./magiskinit\", dest.data()); } } create_and_mount(MAGISKTMP + \"/\" + name()); } }; 所以，可以在/system/bin目录下看到magisk所做的变动，通过这个方面来检测magisk selene:/ $ ls -al /system/bin |grep magisk -rwxr-xr-x 1 root root 170224 2023-06-16 17:00 magisk lrwxrwxrwx 1 root root 8 2023-06-16 17:00 magiskhide -\u003e ./magisk -rwxr-xr-x 1 root root 3987848 2023-06-16 17:00 magiskinit lrwxrwxrwx 1 root root 12 2023-06-16 17:00 magiskpolicy -\u003e ./magiskinit lrwxrwxrwx 1 root root 8 2023-06-16 17:00 resetprop -\u003e ./magisk lrwxrwxrwx 1 root root 8 2023-06-16 17:00 su -\u003e ./magisk lrwxrwxrwx 1 root root 12 2023-06-16 17:00 supolicy -\u003e ./magiskinit 1.2 Magisk模块篡改系统文件检测 检测方式 static jint haveMagicMount(JNIEnv *env __unused, jclass clazz __unused) { dev_t data_dev = scan_mountinfo(); if (data_dev == 0) return -1; return scan_maps(data_dev); } static dev_t scan_mountinfo() { int major = 0; int minor = 0; char line[PATH_MAX]; char mountinfo[] = \"/proc/self/mountinfo\"; int fd = sys_open(mountinfo, O_RDONLY, 0); if (fd \u003c 0) { LOGE(\"cannot open %s\", mountinfo); return 0; } FILE *fp = fdopen(fd, \"r\"); if (fp == NULL) { LOGE(\"cannot open %s\", mountinfo); close(fd); return 0; } // 遍历mountinfo文件，判断存在/ /data的行时拿它的设备号 while (fgets(line, PATH_MAX - 1, fp) != NULL) { if (strstr(line, \"/ /data \") != NULL) { sscanf(line, \"%*d %*d %d:%d\", \u0026major, \u0026minor); } } fclose(fp); // 根据major和minor创建设备号 return makedev(major, minor); } static int scan_maps(dev_t data_dev) { int module = 0; char line[PATH_MAX]; char maps[] = \"/proc/self/maps\"; int fd = sys_open(maps, O_RDONLY, 0); if (fd \u003c 0) { LOGE(\"cannot open %s\", maps); return -1; } FILE *fp = fdopen(fd, \"r\"); if (fp == NULL) { LOGE(\"cannot open %s\", maps); close(fd); return -1; } while (fgets(line, PATH_MAX - 1, fp) != NULL) { // 在maps的内容里判断都否存在/data目录下的设备号 if (strchr(line, '/') == NULL) continue; if (strstr(line, \" /system/\") != NULL || strstr(line, \" /vendor/\") != NULL || strstr(line, \" /product/\") !=","date":"2023-06-17","objectID":"/posts/magisk%E6%A3%80%E6%B5%8B%E6%96%B9%E5%BC%8F/:0:1","tags":["Magisk","源码分析"],"title":"Magisk检测方式","uri":"/posts/magisk%E6%A3%80%E6%B5%8B%E6%96%B9%E5%BC%8F/"},{"categories":["Magisk"],"content":"基于Magisk v25.0 ","date":"2023-06-11","objectID":"/posts/zygisk%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/:0:0","tags":["源码分析","zygisk"],"title":"Zygisk源码阅读","uri":"/posts/zygisk%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/"},{"categories":["Magisk"],"content":"一、Zygisk注入 1. magic_mount挂载app_process magic_mount的原理是挂载tmpfs作为目录，并bind_mount原有的和修改后的文件，而zygisk的处理逻辑也在这个函数当中，整个过程是在magiskd这个系统守护进程中处理的 // native/jni/core/module.cpp void magic_mount() { // bind_mount的过程 ...... // Mount on top of modules to enable zygisk if (zygisk_enabled) { string zygisk_bin = MAGISKTMP + \"/\" ZYGISKBIN; // zygisk_bin对应的是/dev/xxxx/zygisk mkdir(zygisk_bin.data(), 0); mount_zygisk(32) mount_zygisk(64) } } // native/jni/core/module.cpp int app_process_32 = -1; int app_process_64 = -1; #define mount_zygisk(bit) \\ if (access(\"/system/bin/app_process\" #bit, F_OK) == 0) { \\ app_process_##bit = xopen(\"/system/bin/app_process\" #bit, O_RDONLY | O_CLOEXEC); \\ string zbin = zygisk_bin + \"/app_process\" #bit; \\ string dbin = zygisk_bin + \"/magisk\" #bit; \\ string mbin = MAGISKTMP + \"/magisk\" #bit; \\ int src = xopen(mbin.data(), O_RDONLY | O_CLOEXEC); \\ int out = xopen(zbin.data(), O_CREAT | O_WRONLY | O_CLOEXEC, 0); \\ xsendfile(out, src, nullptr, INT_MAX); \\ close(out); \\ out = xopen(dbin.data(), O_CREAT | O_WRONLY | O_CLOEXEC, 0); \\ lseek(src, 0, SEEK_SET); \\ xsendfile(out, src, nullptr, INT_MAX); \\ close(out); \\ close(src); \\ clone_attr(\"/system/bin/app_process\" #bit, zbin.data()); \\ clone_attr(\"/system/bin/app_process\" #bit, dbin.data()); \\ bind_mount(zbin.data(), \"/system/bin/app_process\" #bit); \\ } 从mount_zygisk的过程中可以看出做了三件事 打开原先的app_process(32|64)文件，fd保存到app_process_(32|64)中 把magisk自己的可执行文件magisk(32|64)(mbin)复制到zygisk目录下的app_process(32|64)(zbin)，此处用了sendfile直接在内核中复制文件 sendfile函数在两个文件描写叙述符之间直接传递数据(完全在内核中操作，传送)，从而避免了内核缓冲区数据和用户缓冲区数据之间的拷贝，操作效率非常高，被称之为零拷贝 把zygisk目录下app_process(实际上是magisk文件)通过bind_mount的方式挂载到到原先的/system/bin/app_process(32|64)上 那么这样一来，/system/bin下的app_process就变成了magisk文件，而原先的app_process的fd被magiskd持有。执行app_process的时候就是执行了magisk 2. app_process_main 首先magisk可执行文件的入口main在native/jni/core/applets.cpp里面，app_process实际上可以看作是它的一个applet（类似su、resetprop这些，不过被隐藏了，因为这是个内部功能） main启动会判断自己的文件名(argv0)，如果是app_process就会调用app_process_main，如下 // native\\jni\\core\\applets.cpp int main(int argc, char *argv[]) { enable_selinux(); cmdline_logging(); init_argv0(argc, argv); string_view base = basename(argv[0]); // app_process is actually not an applet if (str_starts(base, \"app_process\")) { return app_process_main(argc, argv); } umask(0); if (base == \"magisk\" || base == \"magisk32\" || base == \"magisk64\") { if (argc \u003e 1 \u0026\u0026 argv[1][0] != '-') { // Calling applet via magisk [applet] args --argc; ++argv; } else { return magisk_main(argc, argv); } } return call_applet(argc, argv); } // native/jni/zygisk/main.cpp // Entrypoint for app_process overlay int app_process_main(int argc, char *argv[]) { android_logging(); char buf[256]; bool zygote = false; if (auto fp = open_file(\"/proc/self/attr/current\", \"r\")) { fscanf(fp.get(), \"%s\", buf); zygote = (buf == \"u:r:zygote:s0\"sv); } if (!zygote) { // ... } if (int socket = connect_daemon(); socket \u003e= 0) { do { write_int(socket, ZYGISK_REQUEST); write_int(socket, ZYGISK_SETUP); if (read_int(socket) != 0) break; int app_proc_fd = recv_fd(socket); if (app_proc_fd \u003c 0) break; string tmp = read_string(socket); #if defined(__LP64__) string lib = tmp + \"/\" ZYGISKBIN \"/zygisk.app_process64.1.so\"; #else string lib = tmp + \"/\" ZYGISKBIN \"/zygisk.app_process32.1.so\"; #endif if (char *ld = getenv(\"LD_PRELOAD\")) { char env[256]; sprintf(env, \"%s:%s\", ld, lib.data()); setenv(\"LD_PRELOAD\", env, 1); } else { setenv(\"LD_PRELOAD\", lib.data(), 1); } setenv(INJECT_ENV_1, \"1\", 1); setenv(\"MAGISKTMP\", tmp.data(), 1); close(socket); snprintf(buf, sizeof(buf), \"/proc/self/fd/%d\", app_proc_fd); fcntl(app_proc_fd, F_SETFD, FD_CLOEXEC); execve(buf, argv, environ); } while (false); close(socket); } // If encountering any errors, unmount and execute the original app_process xreadlink(\"/proc/self/exe\", buf, sizeof(buf)); xumount2(\"/proc/self/exe\", MNT_DETACH); execve(buf, argv, environ); return 1; } 逻辑中会区分是否是zygote的情况，这里我们只关注zygote 首先连接到magiskd，然后发送ZYGISK_SETUP，会得到一个fd和一个字符串，观察对应的处理 // native/jni/zygisk/entry.cpp void zygisk_handler(","date":"2023-06-11","objectID":"/posts/zygisk%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/:0:1","tags":["源码分析","zygisk"],"title":"Zygisk源码阅读","uri":"/posts/zygisk%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/"},{"categories":["Magisk"],"content":"二、Zygisk加载 // native/jni/zygisk/entry.cpp __attribute__((constructor)) static void zygisk_init() { if (getenv(INJECT_ENV_2)) { // Return function pointer to first stage char buf[128]; snprintf(buf, sizeof(buf), \"%p\", \u0026second_stage_entry); setenv(SECOND_STAGE_PTR, buf, 1); } else if (getenv(INJECT_ENV_1)) { first_stage_entry(); } } 这里根据系统变量决定不同阶段处理方式 2.1 一阶段 正常加载时会加载第一阶段，这是在写入LD_PRELOAD时完成环境变量设置 static void first_stage_entry() { android_logging(); ZLOGD(\"inject 1st stage\\n\"); char *ld = getenv(\"LD_PRELOAD\"); char tmp[128]; strlcpy(tmp, getenv(\"MAGISKTMP\"), sizeof(tmp)); char *path; if (char *c = strrchr(ld, ':')) { *c = '\\0'; setenv(\"LD_PRELOAD\", ld, 1); // Restore original LD_PRELOAD path = strdup(c + 1); } else { unsetenv(\"LD_PRELOAD\"); path = strdup(ld); } unsetenv(INJECT_ENV_1); unsetenv(\"MAGISKTMP\"); sanitize_environ(); char *num = strrchr(path, '.') - 1; // Update path to 2nd stage lib *num = '2'; // Load second stage setenv(INJECT_ENV_2, \"1\", 1); void *handle = dlopen(path, RTLD_LAZY); remap_all(path); // Revert path to 1st stage lib *num = '1'; // Run second stage entry char *env = getenv(SECOND_STAGE_PTR); decltype(\u0026second_stage_entry) second_stage; sscanf(env, \"%p\", \u0026second_stage); second_stage(handle, tmp, path); } 一阶段的作用，环境清理（重置env）、获取LD_PRELOAD路径并dlopen、开启二阶段，这种方式和riru很类似，native_bridge加载的libriruloader.so只是一个loader的作用，负责load libriru.so后被处理 dlopen的path对应的是zygisk.app_process.[32|64].2.so，加载完成后调用remap_all void remap_all(const char *name) { vector\u003cmap_info\u003e maps = find_maps(name); for (map_info \u0026info : maps) { // 遍历 maps 中指定文件名的映射信息 void *addr = reinterpret_cast\u003cvoid *\u003e(info.start); size_t size = info.end - info.start; // 映射和目标同样大小的可写内存 void *copy = xmmap(nullptr, size, PROT_WRITE, MAP_ANONYMOUS | MAP_PRIVATE, -1, 0); if ((info.perms \u0026 PROT_READ) == 0) { // 如果目标不可读，让其可读 mprotect(addr, size, PROT_READ); } // 复制目标的内存到新的映射 memcpy(copy, addr, size); // 用新的匿名映射覆盖到原先目标的位置 mremap(copy, size, size, MREMAP_MAYMOVE | MREMAP_FIXED, addr); // 恢复权限使其和目标一致 mprotect(addr, size, info.perms); } } maps文件处理，把path对应的映射全部重新处理成匿名，目的应该是为了隐藏 2.2 二阶段 static void second_stage_entry(void *handle, const char *tmp, char *path) { self_handle = handle; MAGISKTMP = tmp; unsetenv(INJECT_ENV_2); unsetenv(SECOND_STAGE_PTR); zygisk_logging(); ZLOGD(\"inject 2nd stage\\n\"); hook_functions(); // First stage will be unloaded before the first fork first_stage_path = path; } 核心函数hook_functions // native\\jni\\zygisk\\hook.cpp #define XHOOK_REGISTER_SYM(PATH_REGEX, SYM, NAME) \\ hook_register(PATH_REGEX, SYM, (void*) new_##NAME, (void **) \u0026old_##NAME) #define XHOOK_REGISTER(PATH_REGEX, NAME) \\ XHOOK_REGISTER_SYM(PATH_REGEX, #NAME, NAME) #define ANDROID_RUNTIME \".*/libandroid_runtime.so$\" #define APP_PROCESS \"^/system/bin/app_process.*\" void hook_functions() { #if MAGISK_DEBUG // xhook_enable_debug(1); xhook_enable_sigsegv_protection(0); #endif default_new(xhook_list); default_new(jni_hook_list); default_new(jni_method_map); XHOOK_REGISTER(ANDROID_RUNTIME, fork); XHOOK_REGISTER(ANDROID_RUNTIME, unshare); XHOOK_REGISTER(ANDROID_RUNTIME, jniRegisterNativeMethods); XHOOK_REGISTER(ANDROID_RUNTIME, selinux_android_setcontext); XHOOK_REGISTER_SYM(ANDROID_RUNTIME, \"__android_log_close\", android_log_close); hook_refresh(); // Remove unhooked methods xhook_list-\u003eerase( std::remove_if(xhook_list-\u003ebegin(), xhook_list-\u003eend(), [](auto \u0026t) { return *std::get\u003c2\u003e(t) == nullptr;}), xhook_list-\u003eend()); if (old_jniRegisterNativeMethods == nullptr) { ZLOGD(\"jniRegisterNativeMethods not hooked, using fallback\\n\"); // android::AndroidRuntime::setArgv0(const char*, bool) XHOOK_REGISTER_SYM(APP_PROCESS, \"_ZN7android14AndroidRuntime8setArgv0EPKcb\", setArgv0); hook_refresh(); // We still need old_jniRegisterNativeMethods as other code uses it // android::AndroidRuntime::registerNativeMethods(_JNIEnv*, const char*, const JNINativeMethod*, int) constexpr char sig[] = \"_ZN7android14AndroidRuntime21registerNativeMethodsEP7_JNIEnvPKcPK15JNINativeMethodi\"; *(void **) \u0026old_jniRegisterNativeMethods = ","date":"2023-06-11","objectID":"/posts/zygisk%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/:0:2","tags":["源码分析","zygisk"],"title":"Zygisk源码阅读","uri":"/posts/zygisk%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/"},{"categories":["Magisk"],"content":"前言 承接上文，经过Magisk修补后的boot.img在启动引导过程中为了实现Root的功能很关键的一步在于patch了init.rc和sepolicy文件，在Magisk正式把init的执行权交由二阶段的原生init之后，便引导了Magisk deamon的启动 ","date":"2023-06-11","objectID":"/posts/%E9%87%8D%E8%AF%BBmagisk%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%822/:0:1","tags":["源码分析"],"title":"重读Magisk内部实现细节2","uri":"/posts/%E9%87%8D%E8%AF%BBmagisk%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%822/"},{"categories":["Magisk"],"content":"一、Magisk是如何工作的？ 1 init.rc 首先了解下init.rc，它是一个配置文件，内部由Android初始化语言（Android Init Language）编写的脚本，主要包含五种类型语句：Action、Command、Service、Option 和 Import，关键的两种类型是Action和Service Action 以 “on” 关键字开头的action list //触发阶段 on early-init # Disable sysrq from keyboard write /proc/1/oom_score_adj -1000 # Set the security context of /adb_keys if present. restorecon /adb_keys ... ... # cgroup for system_server and surfaceflinger mkdir /dev/memcg/system 0550 system system start ueventd exec_start apexd-bootstrap Action简单理解是定义当触发XX阶段时应该执行的动作 Service service ueventd /system/bin/ueventd class core critical seclabel u:r:ueventd:s0 shutdown critical Service定义了进程，包括名称、权限、执行用户等等，一般都是由init进程通过fork产生子进程来启动 从源码上来看看init.rc是如何被解析并执行其中的类型语句的（以Android11的源码为例） // system/core/init/init.cpp static void LoadBootScripts(ActionManager\u0026 action_manager, ServiceList\u0026 service_list) { // 建立parser对象，传入的是ActionManager和ServiceList，对应init.rc的action和service Parser parser = CreateParser(action_manager, service_list); // 优先从属性中获取rc文件的path，正常情况下都是为空 std::string bootscript = GetProperty(\"ro.boot.init_rc\", \"\"); // 也就是在android11中init.rc都是存在/system/etc/init/hw/init.rc这个路径下 if (bootscript.empty()) { parser.ParseConfig(\"/system/etc/init/hw/init.rc\"); if (!parser.ParseConfig(\"/system/etc/init\")) { late_import_paths.emplace_back(\"/system/etc/init\"); } // late_import is available only in Q and earlier release. As we don't // have system_ext in those versions, skip late_import for system_ext. parser.ParseConfig(\"/system_ext/etc/init\"); if (!parser.ParseConfig(\"/vendor/etc/init\")) { late_import_paths.emplace_back(\"/vendor/etc/init\"); } if (!parser.ParseConfig(\"/odm/etc/init\")) { late_import_paths.emplace_back(\"/odm/etc/init\"); } if (!parser.ParseConfig(\"/product/etc/init\")) { late_import_paths.emplace_back(\"/product/etc/init\"); } } else { parser.ParseConfig(bootscript); } } // system/core/init/parser.cpp bool Parser::ParseConfig(const std::string\u0026 path) { if (is_dir(path.c_str())) { return ParseConfigDir(path); } // 只从文件角度来看看 auto result = ParseConfigFile(path); if (!result.ok()) { LOG(INFO) \u003c\u003c result.error(); } return result.ok(); } Result\u003cvoid\u003e Parser::ParseConfigFile(const std::string\u0026 path) { LOG(INFO) \u003c\u003c \"Parsing file \" \u003c\u003c path \u003c\u003c \"...\"; android::base::Timer t; // 读取文件内容 auto config_contents = ReadFile(path); if (!config_contents.ok()) { return Error() \u003c\u003c \"Unable to read config file '\" \u003c\u003c path \u003c\u003c \"': \" \u003c\u003c config_contents.error(); } // 将文件内容解析写入Parser类 ParseData(path, \u0026config_contents.value()); LOG(VERBOSE) \u003c\u003c \"(Parsing \" \u003c\u003c path \u003c\u003c \" took \" \u003c\u003c t \u003c\u003c \".)\"; return {}; } 以上这些步骤主要是init进程搜索init.rc并逐行解析init.rc文件，将文件中的action和service和传入的ActionManager和ServiceList关联起来等待后续触发 // system/core/init/init.cpp ActionManager\u0026 am = ActionManager::GetInstance(); ServiceList\u0026 sm = ServiceList::GetInstance(); // 完成init.rc解析与绑定 LoadBootScripts(am, sm); // Turning this on and letting the INFO logging be discarded adds 0.2s to // Nexus 9 boot time, so it's disabled by default. if (false) DumpState(); // Make the GSI status available before scripts start running. auto is_running = android::gsi::IsGsiRunning() ? \"1\" : \"0\"; SetProperty(gsi::kGsiBootedProp, is_running); auto is_installed = android::gsi::IsGsiInstalled() ? \"1\" : \"0\"; SetProperty(gsi::kGsiInstalledProp, is_installed); if (android::gsi::IsGsiRunning()) { std::string dsu_slot; if (android::gsi::GetActiveDsu(\u0026dsu_slot)) { SetProperty(gsi::kDsuSlotProp, dsu_slot); } } // 挂载触发时机 am.QueueBuiltinAction(SetupCgroupsAction, \"SetupCgroups\"); am.QueueBuiltinAction(SetKptrRestrictAction, \"SetKptrRestrict\"); am.QueueBuiltinAction(TestPerfEventSelinuxAction, \"TestPerfEventSelinux\"); am.QueueBuiltinAction(ConnectEarlyStageSnapuserdAction, \"ConnectEarlyStageSnapuserd\"); am.QueueEventTrigger(\"early-init\"); ...... // Trigger all the boot actions to get us started. am.QueueEventTrigger(\"init\"); while (true) { ...... // 轮询监听，触发指令 if (!(prop_waiter_state.MightBeWaiting() || Service::is_exec_service_running())) { am.ExecuteOneCommand(); // If there's more work to do, wake up a","date":"2023-06-11","objectID":"/posts/%E9%87%8D%E8%AF%BBmagisk%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%822/:0:2","tags":["源码分析"],"title":"重读Magisk内部实现细节2","uri":"/posts/%E9%87%8D%E8%AF%BBmagisk%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%822/"},{"categories":["Magisk"],"content":"前言 相信Magisk对于移动安全从业者来说都不陌生了，我虽然也是一个版本接着一个版本的使用，但是始终没有去摸透Magisk的生态，希望借助之后想写的Magisk系列的文章来深度学习下Magisk，也正如Magisk在其主页所说的那样 Magisk is a suite of open source software for customizing Android, supporting devices higher than Android 6.0. Some highlight features: MagiskSU: Provide root access for applications Magisk Modules: Modify read-only partitions by installing modules MagiskBoot: The most complete tool for unpacking and repacking Android boot images Zygisk: Run code in every Android applications’ processes Magisk作为一套工具包，它的实现原理（包括它的su实现、boot patch、module机制等等）都是很值得去阅读理解的 ","date":"2023-06-09","objectID":"/posts/%E9%87%8D%E8%AF%BBmagisk%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%82/:0:1","tags":["源码分析"],"title":"重读Magisk内部实现细节","uri":"/posts/%E9%87%8D%E8%AF%BBmagisk%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%82/"},{"categories":["Magisk"],"content":"一、预备知识 boot.img的组成 android启动流程 android secure体系 linux存储 …… ","date":"2023-06-09","objectID":"/posts/%E9%87%8D%E8%AF%BBmagisk%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%82/:0:2","tags":["源码分析"],"title":"重读Magisk内部实现细节","uri":"/posts/%E9%87%8D%E8%AF%BBmagisk%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%82/"},{"categories":["Magisk"],"content":"二、什么是Root？ Android平台的基础是Linux内核，每个应用被严格控制运行在自己的沙盒中，不能越过边界，但是拥有Root权限就意味着你可以绕过内核的权限校验去任意执行你想要的功能。 ","date":"2023-06-09","objectID":"/posts/%E9%87%8D%E8%AF%BBmagisk%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%82/:0:3","tags":["源码分析"],"title":"重读Magisk内部实现细节","uri":"/posts/%E9%87%8D%E8%AF%BBmagisk%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%82/"},{"categories":["Magisk"],"content":"三、Android是如何限制Root的？ 在Android4.3之前的版本中，android会给每一个应用分配一个独一无二的ID（也就是user-ID，也称为UID），所以每个应用都有自己的权限边界，这个时候想要拥有Root权限的话，可以通过set-user-ID-root的机制执行su二进制文件来进行提权或者通过setgid/setuid来让自己拥有更多的权限。 但是自从Android4.3推出Security Enhancements in Android 4.3之后，堵住了setgid/setuid入口，引入了全新的安全体系（基于强制访问控制(MAC)的SELinux），构成了SEAndroid，进一步定义Android应用沙盒的边界，运行在单独的进程中，所以每个应用都有自己的权限边界，这样即使是进程具有root的能力，SELinux依然可以通过创建安全策略(sepolicy)来限制root进程的能力范围来增强Android的安全性。而在Android4.4之后推出的Security Enhancements in Android 4.4，进一步要求Android打开了SELinux的Enforcing模式。 上面这种改变也是因为过去的Android安全机制是基于DAC（自主访问控制）来实现的，其原理就是：进程理论上所拥有的权限与执行它的用户的权限相同，DAC使用了ACL（Access Control List，访问控制列表）来给非管理者用户提供不同的权限，而root用户对文件系统有完全自由的控制权，因此，想办法把自己的权限提升到root用户就可以完成任何事情。而正是因为这种宽松的管理方式，促使MAC（强制访问控制）的诞生，MAC核心思想：即任何进程想在SELinux系统中干任何事情，都必须先在安全策略配置文件中赋予权限，MAC不再像DAC一样简单的把进程分为root/others等，而是每个进程（Subject，主体）和文件（Object，客体）都配置了一个类型（Type），当一个进程去操控（读写等）一个文件时，系统会检测该进程类型是否有对该文件类型的操作权限 例如 (base) ✘ 大慈大悲观世音菩萨  ~/Projects/Android_boot_image_editor   master  as selene:/ $ ps -efZ|grep miui u:r:miuibooster:s0 root 943 1 0 17:43:34 ? 00:00:00 miuibooster u:r:platform_app:s0:c512,c768 u0_a122 1597 611 0 17:43:43 ? 00:00:01 com.miui.miwallpaper u:r:platform_app:s0:c512,c768 u0_a102 1950 610 0 17:43:44 ? 00:00:06 com.miui.home u:r:untrusted_app:s0:c234,c256,c512,c768 u0_a234 2212 610 0 17:43:45 ? 00:00:00 com.miui.weather2 u:r:platform_app:s0:c512,c768 u0_a163 2572 611 0 17:43:49 ? 00:00:00 com.miui.voiceassist u:r:system_app:s0 system 2616 610 0 17:43:49 ? 00:00:00 com.miui.contentcatcher u:r:system_app:s0 system 2667 610 0 17:43:49 ? 00:00:02 com.miui.daemon u:r:system_app:s0 system 2794 610 0 17:43:49 ? 00:00:00 com.miui.face u:r:untrusted_app:s0:c512,c768 u0_a78 2902 610 0 17:43:50 ? 00:00:00 com.miui.personalassistant u:r:system_app:s0 system 2971 610 0 17:43:50 ? 00:00:00 com.miui.notification:remote 可以看到，像miuibooster、platform_app这样即表示进程归属的type，而具体的type的权限可以从官方的te文件中查找 因此，在Android4.4之后，获取Root面临的困难是先DAC、后MAC的访问权限控制，市面上通用的做法是修改sepolicy获得一个不受限制的SELinux context，当拥有这个context之后，就可以修改init.rc启动类似su daemon的服务，这样保障了系统运行时后台随时都存在一个拥有root权限的服务，剩下需要做的就只是考虑该如何和这个daemon进行通信 ","date":"2023-06-09","objectID":"/posts/%E9%87%8D%E8%AF%BBmagisk%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%82/:0:4","tags":["源码分析"],"title":"重读Magisk内部实现细节","uri":"/posts/%E9%87%8D%E8%AF%BBmagisk%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%82/"},{"categories":["Magisk"],"content":"四、Magisk是如何工作的？ 有了上面对于android权限访问控制体系以及现阶段Root实现方式的了解，我们大概能猜到Magisk是如何实现Root的了？那么Magisk它具体的实现包括 如何修改sepolicy、init.rc？ 如何做到systemless的？ 如何适配多种版本、机型？ 是否具备扩展功能？ …… 是如何实现的呢，接下来通过源码来分析下 下面正式开始分析Magisk的内部工作原理（大家都知道Magisk在v24.1之后推出了Zygisk的模式，为了避免新增部分影响我们对于原始流程的分析，因此我选择先忽略掉这部分，以前一个版本v23.0的源码来作为样本阅读） 1 patch boot Magisk Manager做的第一步就是对boot的修补，所以第一步就从Magisk Manager的修补boot页面开始追下来 // com/topjohnwu/magisk/ui/install/InstallFragment.kt // 对应layout class InstallFragment : BaseUIFragment\u003cInstallViewModel, FragmentInstallMd2Binding\u003e() { override val layoutRes = R.layout.fragment_install_md2 override val viewModel by viewModel\u003cInstallViewModel\u003e() ...... } // layout/fragment_install_md2.xml // layout中的开始按钮，对应的方法是InstallViewModel中的install方法 \u003cButton style=\"@style/WidgetFoundation.Button.Text\" gone=\"@{viewModel.step != 1}\" isEnabled=\"@{viewModel.method == @id/method_patch ? viewModel.data != null : viewModel.method != -1}\" android:layout_width=\"wrap_content\" android:layout_height=\"wrap_content\" android:onClick=\"@{() -\u003e viewModel.install()}\" android:text=\"@string/install_start\" app:icon=\"@drawable/ic_forth_md2\" app:iconGravity=\"textEnd\" /\u003e // com/topjohnwu/magisk/ui/install/InstallViewModel.kt // 引导出FlashFragment fun install() { when (method) { R.id.method_patch -\u003e FlashFragment.patch(data!!).navigate() R.id.method_direct -\u003e FlashFragment.flash(false).navigate() R.id.method_inactive_slot -\u003e FlashFragment.flash(true).navigate() else -\u003e error(\"Unknown value\") } state = State.LOADING } // com/topjohnwu/magisk/ui/flash/FlashFragment.kt // 类似onCreate方法，触发startFlashing override fun onViewCreated(view: View, savedInstanceState: Bundle?) { super.onViewCreated(view, savedInstanceState) defaultOrientation = activity.requestedOrientation activity.requestedOrientation = ActivityInfo.SCREEN_ORIENTATION_NOSENSOR viewModel.startFlashing() } // com/topjohnwu/magisk/ui/flash/FlashViewModel.kt Const.Value.PATCH_FILE -\u003e { uri ?: return@launch showReboot = false MagiskInstaller.Patch(uri, outItems, logItems).exec() } // com/topjohnwu/magisk/core/tasks/MagiskInstaller.kt // patchFile也就是传入的原生boot.img protected fun doPatchFile(patchFile: Uri) = extractFiles() \u0026\u0026 handleFile(patchFile) 进入到关键类：MagiskInstaller private fun extractFiles(): Boolean { ...... // 创建/data/data/package_name/install目录 installDir = File(context.filesDir.parent, \"install\") installDir.deleteRecursively() installDir.mkdirs() try { // Extract binaries // 从stub或者full中获取so文件 if (isRunningAsStub) { val zf = ZipFile(DynAPK.current(context)) zf.entries().asSequence().filter { !it.isDirectory \u0026\u0026 it.name.startsWith(\"lib/${Const.CPU_ABI_32}/\") }.forEach { val n = it.name.substring(it.name.lastIndexOf('/') + 1) val name = n.substring(3, n.length - 3) val dest = File(installDir, name) zf.getInputStream(it).writeTo(dest) } } else { // 获取lib库中的so文件 val libs = Const.NATIVE_LIB_DIR.listFiles { _, name -\u003e name.startsWith(\"lib\") \u0026\u0026 name.endsWith(\".so\") } ?: emptyArray() for (lib in libs) { // 重命名so文件并做软链，例如libmagiskboot.so-\u003emagiskboot // 并软链到/data/data/package_name/install/magiskboot val name = lib.name.substring(3, lib.name.length - 3) Os.symlink(lib.path, \"$installDir/$name\") } } // Extract scripts // 从asset目录中抽出三个shell脚本 for (script in listOf(\"util_functions.sh\", \"boot_patch.sh\", \"addon.d.sh\")) { val dest = File(installDir, script) context.assets.open(script).writeTo(dest) } // Extract chromeos tools // 同理 File(installDir, \"chromeos\").mkdir() for (file in listOf(\"futility\", \"kernel_data_key.vbprivk\", \"kernel.keyblock\")) { val name = \"chromeos/$file\" val dest = File(installDir, name) context.assets.open(name).writeTo(dest) } } catch (e: Exception) { console.add(\"! Unable to extract files\") Timber.e(e) return false } ...... } extractFiles这一步做的功能就是准备资源，把so文件变成可执行文件以及准备好shell脚本，根据Apk对应下的目录可看到文件如下： (base) 大慈大悲观世音菩萨  ~/Downloads/Magisk-v23.0 (1)  ll assets total 88 -rw-rw-rw-@ 1 tcc0lin staff 3.4K 1 1 1981 addon.d.sh -rw-rw-rw-@ 1 tcc0lin staff 5.3K 1 1 1981 boot_patch.sh drwxr-xr-x@ 5 tcc0lin staff 160B 5 31 09:08 chromeo","date":"2023-06-09","objectID":"/posts/%E9%87%8D%E8%AF%BBmagisk%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%82/:0:5","tags":["源码分析"],"title":"重读Magisk内部实现细节","uri":"/posts/%E9%87%8D%E8%AF%BBmagisk%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%82/"},{"categories":["Magisk"],"content":"五、参考 感谢这些文章带来的启发 https://android.stackexchange.com/questions/213167/how-does-magisk-work https://bbs.kanxue.com/thread-275939.htm#msg_header_h2_3 ","date":"2023-06-09","objectID":"/posts/%E9%87%8D%E8%AF%BBmagisk%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%82/:0:6","tags":["源码分析"],"title":"重读Magisk内部实现细节","uri":"/posts/%E9%87%8D%E8%AF%BBmagisk%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%82/"},{"categories":["算法研究"],"content":"DES是一种对称密钥的块加密算法。”对称密钥”，是因为加密、解密用的密钥是一样的（这不同于RSA等非对称密钥体系）。“块加密”，是因为这种算法把明文划分为很多个等长的块(block)，对每个块进行加密，最后以某种手段拼在一起。“块加密”亦称“分组加密”。 1973年，NSA向社会征集满足安全要求的加密算法。1973-1974年，IBM研发了DES加密算法。1974年，NSA开始了第二次征集，此后DES在1976年成为美国联邦标准。 ","date":"2023-05-09","objectID":"/posts/%E4%BB%8Efips-46-3%E4%B8%AD%E7%90%86%E8%A7%A3des%E7%AE%97%E6%B3%95/:0:0","tags":["加密算法","源码分析"],"title":"从FIPS 46-3中理解DES算法","uri":"/posts/%E4%BB%8Efips-46-3%E4%B8%AD%E7%90%86%E8%A7%A3des%E7%AE%97%E6%B3%95/"},{"categories":["算法研究"],"content":"一、DES概述 DES的功能是：给定一个64位的明文和一个64位的密钥，输出一个64位的密文。这个密文可以用相同的密钥解密。所谓“64位的密钥”，其实里面只有54位在起作用。剩余的位可以直接丢弃，或者当作奇偶校验位。 虽然DES一次只能加密8个字节，但我们只需要把明文划分成每8个字节一组的块，就可以实现任意长度明文的加密。如果明文长度不是8个字节的倍数，还得进行填充。现在流行的填充方式是PKCS7/PKCS5，都是很简单的思路，用于把任意长度的文本填充成8字节的倍数长，也能方便地恢复原文，这里不再赘述。此外，独立地对每个块加密，最后直接拼起来是不行的（这种方式称为“电子密码本”，ECB模式。它会导致明文中重复的块，加密结果也重复，这对于图片之类的数据来说几乎是致命的）。因为不涵盖在算法流程中，因此对有关DES输入输出的处理后续再讲。 DES有一个非常不平凡的性质——加密与解密算法几乎一模一样。这大大简化了软件和硬件的设计。和加密算法的区别是，给它加上一行（倒转子密钥的顺序），就是一个解密算法了。 在这篇文章中，我们只关注一个核心任务——如何把64位的明文，用64位的密钥，加密成64位的密文，并执行解密。 ","date":"2023-05-09","objectID":"/posts/%E4%BB%8Efips-46-3%E4%B8%AD%E7%90%86%E8%A7%A3des%E7%AE%97%E6%B3%95/:0:1","tags":["加密算法","源码分析"],"title":"从FIPS 46-3中理解DES算法","uri":"/posts/%E4%BB%8Efips-46-3%E4%B8%AD%E7%90%86%E8%A7%A3des%E7%AE%97%E6%B3%95/"},{"categories":["算法研究"],"content":"二、DES算法框架 DES算法是在Feistel Network（费斯妥网络）的基础上执行的。以下是DES算法的流程图： 可以看到，整个算法可以看成是两个部分 密钥调度计算（右边基于给定密钥生成子密钥的过程） 所谓密钥调度，就是从一把64位的主密钥，得到16把48位的子密钥，然后把这些子密钥参与到后续16轮迭代加密中。那么，如何从一把主密钥得到16把子密钥呢？ 首先是从64位的主密钥中通过选择置换1选取特定的56位，其余的位就作为检验位，不参与后续计算。于是我们现在手上有了一个56位的密钥 接着把它分成左、右两个半密钥C0、D0，它们都是28位的密钥 然后对C0和D0进行16轮的迭代，每轮迭代都包括以下步骤： 左、右两个半密钥Cn、Dn都左旋（也就是循环左移。整个数组往左移，左边弹出去了的东西补到最右边去）一定位数得到Cn+1、Dn+1，这个左移的位数也是指定的。有些轮次是1位，有些轮次是2位 把左、右半密钥拼起来成为Kn+1，再通过选择置换2得到Kn，就得到了这一轮生成的子密钥。这个置换是从56位的数组里面选取指定的48位。所以现在每一轮都可以生成一个48位的子密钥。（注意，步骤3并不改变左右半密钥）。 最后，经过16轮迭代之后，就生成了16个48位的子密钥，这些子密钥被用于加密和解密数据 解密过程中，除了子密钥输出的顺序相反外，密钥调度的过程与加密完全相同 迭代加密（左边的16轮迭代加密的过程） 迭代加密就是由具体数据参与的主流程的加密逻辑，具体逻辑是 输入的明文（64bit）做一个置换（IP置换）。仍然得到64bit的数组（位数不等会导致信息丢失） 同样基于Feistel Network的概念将数据拆分成左右两个半数据，各32bit 每轮迭代都是接收一组L、R，返回L’、R’，作为下一轮迭代的 L, R . 迭代过程如下： L' = R R' = L⊕F(R,subkey) 关键在于F函数，也称为轮（Round）函数，是整个算法的核心，用于以子密钥加密32bit的信息 步骤3执行16轮，每轮分别更新L、R值 将最终得到的L、R值进行合并，再做一次置换（FP置换），即可得到密文 以上就是DES算法的大致过程，文中也提到，加解密的唯一区别就在于子密钥的顺序不同 1 密钥调度计算 详细来看看DES如何通过给定的主密钥而生成16把子密钥的，图示如下： 首先，采用“选择置换1 (PC-1)”，从64位key里面选出56位。这一步属于encode，对信息安全没有帮助。PC-1方法如下： const int pc_1[56] = { 57 ,49 ,41 ,33 ,25 ,17 ,9 , 1 ,58 ,50 ,42 ,34 ,26 ,18 , 10 ,2 ,59 ,51 ,43 ,35 ,27 , 19 ,11 ,3 ,60 ,52 ,44 ,36 , 63 ,55 ,47 ,39 ,31 ,23 ,15 , 7 ,62 ,54 ,46 ,38 ,30 ,22 , 14 ,6 ,61 ,53 ,45 ,37 ,29 , 21 ,13 ,5 ,28 ,20 ,12 ,4 }; string key_56 = \"\"; for (int i = 0; i \u003c 56; i++) key_56 += key_64[pc_1[i] - 1]; 经过PC-1之后，我们有了左、右两个半密钥，长度都是28位。接下来，我们每一轮把左、右半密钥左旋几位，再调用PC-2方法来造子密钥。框架如下： int num_leftShift[16] = { 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1 }; L_key[0] = shift_bit(key_firstHalf, num_leftShift[0]); R_key[0] = shift_bit(key_secondHalf, num_leftShift[0]); for (int i = 1; i \u003c 16; i++) { L_key[i] = shift_bit(L_key[i - 1], num_leftShift[i]); R_key[i] = shift_bit(R_key[i - 1], num_leftShift[i]); } for (int i = 0; i \u003c 16; i++) { keys_56[i] = L_key[i] + R_key[i]; // making 56 bits keys } 其中， shift_bit是循环左移，实现如下： string shift_bit(string s, int n) { string k = \"\"; for (int i = n; i \u003c s.size(); i++) k += s[i]; for (int i = 0; i \u003c n; i++) k += s[i]; return k; } PC-2又是一个简单置换，用于从左右半密钥拼起来的56位密钥中，选取48位作为一个子密钥。实现如下： const int pc_2[48] = { 14 ,17 ,11 ,24 ,1 ,5 , 3 ,28 ,15 ,6 ,21 ,10 , 23 ,19 ,12 ,4 ,26 ,8 , 16 ,7 ,27 ,20 ,13 ,2 , 41 ,52 ,31 ,37 ,47 ,55 , 30 ,40 ,51 ,45 ,33 ,48 , 44 ,49 ,39 ,56 ,34 ,53 , 46 ,42 ,50 ,36 ,29 ,32 }; for (int i = 0; i \u003c 16; i++) { key_48[i] = \"\"; for (int j = 0; j \u003c 48; j++) key_48[i] += keys_56[i][pc_2[j] - 1]; // making 48 bits keys } 这样，我们就实现了密钥调度算法。基于主密钥而得到的16个48位的子密钥。不难看出，整个密钥调度的过程都是对主密钥的encode。生成这么多子密钥的目的，是使得加密迭代变得更加复杂、难以分析 2 迭代加密 加密迭代的过程已经描述过。先把信息进行一次初始置换(IP置换)；再进行16轮迭代；最后再给(R+L)这个数组来一次最终置换(FP置换)，即可输出作为密文 const int IP_t[64] = { 58 ,50 ,42 ,34 ,26 ,18 ,10 ,2 , 60 ,52 ,44 ,36 ,28 ,20 ,12 ,4 , 62 ,54 ,46 ,38 ,30 ,22 ,14 ,6 , 64 ,56 ,48 ,40 ,32 ,24 ,16 ,8 , 57 ,49 ,41 ,33 ,25 ,17 ,9 ,1 , 59 ,51 ,43 ,35 ,27 ,19 ,11 ,3 , 61 ,53 ,45 ,37 ,29 ,21 ,13 ,5 , 63 ,55 ,47 ,39 ,31 ,23 ,15 ,7 }; string IP = \"\"; // permuted key for (int i = 0; i \u003c 64; i++) IP += plain_txt_64[IP_t[i] - 1]; DES的安全性在很大程度上取决于F函数，也就是轮函数。那么Feistel函数是干了什么事呢？来看下面一张流程图： 一个32-bit的块，经过一个扩张(Expand函数)，变成48位，然后与子密钥异或。得到的48-bit的结果分为8组，每一组是6-bit的数据，丢进对应的S盒，输出4-bit的信息。把这些输出收集起来，一共是4*8=32位，做一次置换(P置换)，得到32-bit的结果。这与输进来的32-bit信息是等长度的。 Expand算法是指定的 const int E_t[48] = { 32 ,1 ,2 ,3 ,4 ,5 , // expantion table 4 ,5 ,6 ,7 ,8 ,9 , 8 ,9 ,10 ,11 ,12 ,13 , 12 ,13 ,14 ,15 ,16 ,17 , 16 ,17 ,18 ,19 ,20 ,21 , 20 ,21 ,22 ,23 ,24 ,25 , 24 ,25 ,26 ,27 ,28 ,29 , 28 ,29 ,30 ,31 ,32 ,1 }; R_48[0] = \"\"; for (int j = 0; j \u003c 48; j++) R_48[0] += R[E_t[j] - 1]; string xor_add(string s1, string s2) { string result = \"\"; for (int j = 0; j \u003c s1.size(); j++) { if (s1[j] != s2[j]) result += '1'; else result += '0'; } return result; } R_xor_K[0] = xor_add(R_48[0], key_48[0]); 分成8组分别进入S盒处理 for (int j = 0; j \u003c48; j += 6) // dividing each value of R_xor_K to 8 string contaning 6 char each for (int k = j; k \u003c j + 6; k++) s[0][j / 6] += R_xor_K[0][k]; s_1[0] = \"\"; for (int j = 0; j \u003c 8; j++) s_1[0] += get_element_from_box(s[0][j], ","date":"2023-05-09","objectID":"/posts/%E4%BB%8Efips-46-3%E4%B8%AD%E7%90%86%E8%A7%A3des%E7%AE%97%E6%B3%95/:0:2","tags":["加密算法","源码分析"],"title":"从FIPS 46-3中理解DES算法","uri":"/posts/%E4%BB%8Efips-46-3%E4%B8%AD%E7%90%86%E8%A7%A3des%E7%AE%97%E6%B3%95/"},{"categories":["算法研究"],"content":"三、理解 DES也算是第一代的公认的对称加密的标准算法，核心在于F函数的概念与实现。当然DES算法主体流程还是依赖于固定64位的输入输出，而到了实际使用上还存在有不同的工作方式以及安全性问题，这些问题还等到后续继续补充 ","date":"2023-05-09","objectID":"/posts/%E4%BB%8Efips-46-3%E4%B8%AD%E7%90%86%E8%A7%A3des%E7%AE%97%E6%B3%95/:0:3","tags":["加密算法","源码分析"],"title":"从FIPS 46-3中理解DES算法","uri":"/posts/%E4%BB%8Efips-46-3%E4%B8%AD%E7%90%86%E8%A7%A3des%E7%AE%97%E6%B3%95/"},{"categories":["算法研究"],"content":"一、前置知识点 MD5算法的输入是任意长度的信息，而输出是固定的长度为128位的信息，也就是固定大小为16字节的数组（byte=8bit） ","date":"2023-05-09","objectID":"/posts/%E4%BB%8Erfc1321%E4%B8%AD%E7%90%86%E8%A7%A3md5%E7%AE%97%E6%B3%95/:0:1","tags":["摘要算法","源码分析"],"title":"从RFC1321中理解MD5算法","uri":"/posts/%E4%BB%8Erfc1321%E4%B8%AD%E7%90%86%E8%A7%A3md5%E7%AE%97%E6%B3%95/"},{"categories":["算法研究"],"content":"二、算法流程 根据上面所说，MD5算法的输入是任意长度的信息，长度可以是0，也可以不是8的倍数，针对任意长度的输入，就需要通过下面的五个步骤来计算出它的MD5值 1 补位 输入可以是不定长的信息，但是实际上转化到算法逻辑中时又需要根据定长的信息来计算，因此，首先需要做的就是补位操作，方法如下： 将二进制数据对512进行取模，如果有余数不等于448，则将余数补足到448的长度，补足的规则是先补1，后面全补0，相当于N*512+448的长度，N为一个非负整数（也包括0） 例如 # 以长度20解释 1001001001 #长度为10 10010010011000000000 #先补1后补0 2 记录信息长度 上一步将最后的余数补充到448，距离512还相差64，这64位二进制就是用来记录信息的长度的，当然，如果信息长度超过64位，则取低64位。经过以上这两步的处理，整个输入信息的长度已经被扩充成N*512+448+64=(N+1)*512，即长度恰好是512的整数倍。这样做的原因是为满足后面处理中对信息长度的要求 3 初始化变量 这一步引入MD5算法中第一个关键点—初始常量（可以叫幻数、魔数或者IV），这些参数以小端字节序来表示，会参与到后续的计算，也会直接影响最终的计算结果。 word A: 01 23 45 67 word B: 89 ab cd ef word C: fe dc ba 98 word D: 76 54 32 10 每一个变量给出的数值是高字节存于内存低地址，低字节存于内存高地址，即小端字节序。在程序中变量A、B、C、D的值分别为0x67452301，0xEFCDAB89，0x98BADCFE，0x10325476 4 处理分组数据 在前两步我们将数据处理成了N*512的分组形式，下面再对每个分组进行二次分组成16份，也就是16*32=512，每个子分组是32bit的数据 每个分组的计算流程都是一样的，简单来说如下：默认初始变量有a、b、c、d四个变量，首先以第三步的四个变量分别对其赋值，也就是 A = a B = b C = c D = d 之后开始四轮的循环计算，每轮有16次操作，分别对应一个非线性函数以及子分组、常量，每次操作都会计算出a、b、c、d其中一个变量的新值作替换，这样经过四轮计算之后，a、b、c、d的值也就更新了一遍，后续的其他分组也是如此操作 下面具体讲下其中的逻辑： 首先是MD5算法中第二个关键点—非线性函数，分别是 F(X,Y,Z) = XY v not(X) Z G(X,Y,Z) = XZ v Y not(Z) H(X,Y,Z) = X xor Y xor Z I(X,Y,Z) = Y xor (X v not(Z)) // c++实现 F, G, H and I are basic MD5 functions. inline MD5::uint4 MD5::F(uint4 x, uint4 y, uint4 z) { return (x \u0026 y) | (~x \u0026 z); } inline MD5::uint4 MD5::G(uint4 x, uint4 y, uint4 z) { return (x \u0026 z) | (y \u0026 ~z); } inline MD5::uint4 MD5::H(uint4 x, uint4 y, uint4 z) { return x ^ y ^ z; } inline MD5::uint4 MD5::I(uint4 x, uint4 y, uint4 z) { return y ^ (x | ~z); } 每轮中都会使用其中一个函数来进行计算，因此函数的逻辑也直接决定最终的结果，具体使用到的地方如下 // rotate_left rotates x left n bits. inline MD5::uint4 MD5::rotate_left(uint4 x, int n) { return (x \u003c\u003c n) | (x \u003e\u003e (32 - n)); } // FF, GG, HH, and II transformations for rounds 1, 2, 3, and 4. // Rotation is separate from addition to prevent recomputation. inline void MD5::FF(uint4 \u0026a, uint4 b, uint4 c, uint4 d, uint4 x, uint4 s, uint4 ac) { a = rotate_left(a + F(b, c, d) + x + ac, s) + b; } inline void MD5::GG(uint4 \u0026a, uint4 b, uint4 c, uint4 d, uint4 x, uint4 s, uint4 ac) { a = rotate_left(a + G(b, c, d) + x + ac, s) + b; } inline void MD5::HH(uint4 \u0026a, uint4 b, uint4 c, uint4 d, uint4 x, uint4 s, uint4 ac) { a = rotate_left(a + H(b, c, d) + x + ac, s) + b; } inline void MD5::II(uint4 \u0026a, uint4 b, uint4 c, uint4 d, uint4 x, uint4 s, uint4 ac) { a = rotate_left(a + I(b, c, d) + x + ac, s) + b; } 四个函数格式相似，不同的只是引用到刚才所说的非线性函数 讲到主逻辑之前还需要提到MD5算法中第三个关键点—T常量表 它的计算方式也比较简单，之前说到计算会有4*16=64次，因此也就需要64个常量，公式如 4294967296*abs(sin(i)) 其中i是取值从1到64，而4294967296=2的32次方，最后计算可得出T常量表如 unsigned int T[64] = { 0xd76aa478, 0xe8c7b756, 0x242070db, 0xc1bdceee, 0xf57c0faf, 0x4787c62a, 0xa8304613, 0xfd469501, 0x698098d8, 0x8b44f7af, 0xffff5bb1, 0x895cd7be, 0x6b901122, 0xfd987193, 0xa679438e, 0x49b40821, 0xf61e2562, 0xc040b340, 0x265e5a51, 0xe9b6c7aa, 0xd62f105d, 0x02441453, 0xd8a1e681, 0xe7d3fbc8, 0x21e1cde6, 0xc33707d6, 0xf4d50d87, 0x455a14ed, 0xa9e3e905, 0xfcefa3f8, 0x676f02d9, 0x8d2a4c8a, 0xfffa3942, 0x8771f681, 0x6d9d6122, 0xfde5380c, 0xa4beea44, 0x4bdecfa9, 0xf6bb4b60, 0xbebfbc70, 0x289b7ec6, 0xeaa127fa, 0xd4ef3085, 0x04881d05, 0xd9d4d039, 0xe6db99e5, 0x1fa27cf8, 0xc4ac5665, 0xf4292244, 0x432aff97, 0xab9423a7, 0xfc93a039, 0x655b59c3, 0x8f0ccc92, 0xffeff47d, 0x85845dd1, 0x6fa87e4f, 0xfe2ce6e0, 0xa3014314, 0x4e0811a1, 0xf7537e82, 0xbd3af235, 0x2ad7d2bb, 0xeb86d391 }; 还有第四个关键点—转换常量 unsigned int S1[4] = {7, 12, 17, 22}; unsigned int S2[4] = {5, 9, 14, 20}; unsigned int S3[4] = {4, 11, 16, 23}; unsigned int S4[4] = {6, 10, 15, 21}; 参与到非线性函数中循环左移的操作 主逻辑 /* Round 1 */ FF(a, b, c, d, x[0], S1[0], T[0]); /* 1 */ FF(d, a, b, c, x[1], S1[1], T[1]); /* 2 */ FF(c, d, a, b, x[2], S1[2], T[2]); /* 3 */ FF(b, c, d, a, x[3], S1[3], T[3]); /* 4 */ FF(a, b, c, d, x[4], S1[0], T[4]); /* 5 */ FF(d, a, b, c, x[5], S1[1], T[5]); /* 6 */ FF(c, d, a, b, x[6], S1[2], T[6]); /* 7 */ FF(b, c, d, a, x[7], S1[3], T[7]); /* 8 */ FF(a, b, c, d, x[8], S1[0], T[8]); /* 9 */ FF(d, a, b, c, x[9], S1[1], T[9]); /* 10 */ FF(c, d, a, b, x[10], S1[2], T[10]","date":"2023-05-09","objectID":"/posts/%E4%BB%8Erfc1321%E4%B8%AD%E7%90%86%E8%A7%A3md5%E7%AE%97%E6%B3%95/:0:2","tags":["摘要算法","源码分析"],"title":"从RFC1321中理解MD5算法","uri":"/posts/%E4%BB%8Erfc1321%E4%B8%AD%E7%90%86%E8%A7%A3md5%E7%AE%97%E6%B3%95/"},{"categories":["算法研究"],"content":"总结 综合上面所讲到的MD5算法原理，可以看出MD5还是比较简单易懂的，与最终结果相关的正如上面所讲到的有四个关键点，理解它们的含义以及作用在后续我们对MD5算法进行魔改的时候是很有帮助的 ","date":"2023-05-09","objectID":"/posts/%E4%BB%8Erfc1321%E4%B8%AD%E7%90%86%E8%A7%A3md5%E7%AE%97%E6%B3%95/:0:3","tags":["摘要算法","源码分析"],"title":"从RFC1321中理解MD5算法","uri":"/posts/%E4%BB%8Erfc1321%E4%B8%AD%E7%90%86%E8%A7%A3md5%E7%AE%97%E6%B3%95/"},{"categories":["算法研究"],"content":"一、RC5算法概述 作为同样是由Rivest推出的算法，RC5算法与RC4算法是完全不同的，一个明显的特征是RC5采用的是基于Feistel对称结构的分组加密算法 和许多加密方法不同，RC5支持可变的块大小(32、64或128比特)，密钥长度（0至2040位）和加密轮数（0～255）。最初建议选择的参数是64位的块大小，128位的密钥和12轮加密 RC5的一个关键特征是使用基于数据的置换。RC5的其中一个目标是促进对于这类作为原始密码的操作的研究和评估。RC5也包括一些的取模加法和逻辑异或(XOR)运算。加密结构是基于Feistel来完成的，虽然结构简单，但密钥的生成算法更复杂。密钥扩展使用了e和黄金比例代入一个单向函数，将所得值作为“袖子里是空的”数字（即无任何来源依据的魔法数字）。算法的诱人的简洁性和基于数据的置换的特性，让RC5吸引了众多密码研究人员将其作为研究对象。 RC5通常被记为RC5-w/r/b，w=字的大小（以bit为单位），r=加密轮数，b=密钥的字节数。这样，RC5-32/16/16表示为RC5的块长为64位（注：RC5使用两个字块）、16轮加密和16字节密钥。Ron Rivest推荐的最低安全版本为RC5-32/16/16 ","date":"2023-05-09","objectID":"/posts/%E4%BB%8Erfc2040%E4%B8%AD%E7%90%86%E8%A7%A3rc5%E7%AE%97%E6%B3%95/:0:1","tags":["摘要算法","源码分析"],"title":"从RFC2040中理解RC5算法","uri":"/posts/%E4%BB%8Erfc2040%E4%B8%AD%E7%90%86%E8%A7%A3rc5%E7%AE%97%E6%B3%95/"},{"categories":["算法研究"],"content":"二、RC5算法框架 为了便于理解RC5算法，假设输入明文块的长度为64位，其他块长的操作原理是一样的 在一次性初始操作中，输入明文块分成两个32位块A和B，前两个子密钥（稍后会介绍如何生成）S[0]和S[1]分别加进A和B，分别产生C和D，表示一次性操作结束 接着进行各轮计算，每轮完成以下操作： 位异或运算 循环左移 对C和D增加下一个子密钥，先是加法运算，然后将结果用2^32求模 1 初始化操作 第一步的初始化计算可以看成是RC4融合了DES的做法，融合了RC4的密钥计算和DES的Feistel的一个对称结构运用 首先会将明文分为两个等长的A和B，接着是第一个子密钥S[0]与A相加，第二个子密钥S[1]与B相加 2 子密钥的计算 子密钥的计算可以分成生成和混合两步，预计要产生2r+2个子密钥，每个密钥长度为w位 生成 这一步使用两个常量P和Q。生成的子密钥数组称为S，第一个子密钥为S[0]用P值初始化。每个后续子密钥（S[1]，S[2]，…）根据前面的子密钥和常量Q求出，用2^32求模，这个过程要进行2(r+1)-1次，其中r位轮数 // Set magic constants rc5_p = 0xb7e15163; rc5_q = 0x9e3779b9; // Cleaning user key for(int i=0; i\u003cRC5_B; i++) rc5_key[i]=0; for(rc5_s[0]=rc5_p,i=1; i\u003cRC5_T; i++) rc5_s[i] = rc5_s[i-1]+rc5_q; for(i=RC5_B-1, l[RC5_C-1]=0; i!=-1; i--) l[i/u] = (l[i/u]\u003c\u003c8)+key[i]; 混合 // 3*t \u003e 3*c for(a=b=i=j=k=0; k\u003c3*RC5_T; k++, i=(i+1)%RC5_T, j=(j+1)%RC5_C) { a = rc5_s[i] = RC5_ROTL(rc5_s[i]+(a+b),3); b = l[j] = RC5_ROTL(l[j]+(a+b),(a+b)); } 混合之后得到了新的长度为(2 * r) + 2的密钥组，需要注意的是，代码中提到了P和Q两个变量，其实是根据以下的公式而得来的 Pw = Odd((e-2)*2^32) Qw = Odd((Φ-2)*2^32) e表示自然对数的底 Φ表示黄金分割比率 Odd(x)表示最接近x的奇整数 3 轮计算 RC5_TWORD i; RC5_TWORD a=pt[0]+rc5_s[0]; RC5_TWORD b=pt[1]+rc5_s[1]; for(i=1; i\u003c=RC5_R; i++) { a = RC5_ROTL(a^b, b)+rc5_s[2*i]; b = RC5_ROTL(b^a, a)+rc5_s[2*i+1]; } ct[0] = a; ct[1] = b; ","date":"2023-05-09","objectID":"/posts/%E4%BB%8Erfc2040%E4%B8%AD%E7%90%86%E8%A7%A3rc5%E7%AE%97%E6%B3%95/:0:2","tags":["摘要算法","源码分析"],"title":"从RFC2040中理解RC5算法","uri":"/posts/%E4%BB%8Erfc2040%E4%B8%AD%E7%90%86%E8%A7%A3rc5%E7%AE%97%E6%B3%95/"},{"categories":["算法研究"],"content":"三、理解 ","date":"2023-05-09","objectID":"/posts/%E4%BB%8Erfc2040%E4%B8%AD%E7%90%86%E8%A7%A3rc5%E7%AE%97%E6%B3%95/:0:3","tags":["摘要算法","源码分析"],"title":"从RFC2040中理解RC5算法","uri":"/posts/%E4%BB%8Erfc2040%E4%B8%AD%E7%90%86%E8%A7%A3rc5%E7%AE%97%E6%B3%95/"},{"categories":["算法研究"],"content":"一、前置知识点 总体上来说，SHA1算法和MD5算法很类似（因为它们都属于是针对于信息摘要的哈希算法），大体的算法流程也是基本相同，可以回忆下MD5算法的五个步骤，可以说SHA1是升级版本的MD5。不同点从直观上看，SHA1返回的信息长度是160位（20个字节），而MD5则是128位（16个字节），因此相较于MD5算法来说会更加安全一些（不过也仅仅是一些而已） ","date":"2023-05-09","objectID":"/posts/%E4%BB%8Erfc3174%E4%B8%AD%E7%90%86%E8%A7%A3sha1%E7%AE%97%E6%B3%95/:0:1","tags":["摘要算法","源码分析"],"title":"从RFC3174中理解SHA1算法","uri":"/posts/%E4%BB%8Erfc3174%E4%B8%AD%E7%90%86%E8%A7%A3sha1%E7%AE%97%E6%B3%95/"},{"categories":["算法研究"],"content":"二、算法流程 算法流程就不多做介绍，和MD5算法类似，同样需要通过五个步骤来完成 1 补位 基本一样，不做额外说明 2 记录信息长度 同上 3 初始化变量 这一步开始有不同了，SHA1算法也同样有初始变量，与MD5不同的是，MD5最终是依靠初始变量组合起来的16个字节的结果，而SHA1结果为20个字节，因此也在初始变量中多了4个字节，定义如下 uint32_t H0 = 0x67452301; // 0x01, 0x23, 0x45, 0x67 uint32_t H1 = 0xEFCDAB89; // 0x89, 0xAB, 0xCD, 0xEF uint32_t H2 = 0x98BADCFE; // 0xFE, 0xDC, 0xBA, 0x98 uint32_t H3 = 0x10325476; // 0x76, 0x54, 0x32, 0x10 uint32_t H4 = 0xC3D2E1F0; // 0xF0, 0xE1, 0xD2, 0xC3 初始化变量的个数和结果有直接关系，因为结果是由初始化变量组合在一起的 4 处理分组数据 这一步大体结构一样，但是处理的方式有点不同 分组方式不说了，同样是将数据处理成了N*512的分组形式，下面再对每个分组进行二次分组成16份，也就是16*32=512，每个子分组是32bit的数据，着重讲讲和MD5算法的不同点 相比于MD5的四轮计算，SHA1也会涉及到四轮计算，每轮则增加到20次，一共是80次非线性函数计算，对于每轮使用的数据和MD5也是有区别的，MD5处理每次分组的数据就是把数据分成16组，每轮使用的都是这16组数据，而SHA1则不一样，只有前16组使用的是拆分的数据，从16-80则根据公式得到新的数据 /* a. Divide M(i) into 16 words W(0), W(1), ..., W(15), where W(0) is the left - most word. */ for (t = 0; t \u003c= 15; t++) { W[t] = M[t]; } /* b. For t = 16 to 79 let W(t) = S^1(W(t-3) XOR W(t-8) XOR W(t-14) XOR W(t-16)). */ for (t = 16; t \u003c= 79; t++) { W[t] = MoveLeft(W[t - 3] ^ W[t - 8] ^ W[t - 14] ^ W[t - 16], 1); } 首先先看看四个非线性函数参考（二、四轮其实是一样的） /* f(X, Y, Z) */ /* [0, 19] */ static uint32_t Ch(uint32_t X, uint32_t Y, uint32_t Z) { return (X \u0026 Y) ^ ((~X) \u0026 Z); } /* [20, 39] */ /* [60, 79] */ static uint32_t Parity(uint32_t X, uint32_t Y, uint32_t Z) { return X ^ Y ^ Z; } /* [40, 59] */ static uint32_t Maj(uint32_t X, uint32_t Y, uint32_t Z) { return (X \u0026 Y) ^ (X \u0026 Z) ^ (Y \u0026 Z); } 接着是每次计算所会涉及到的常量K，还记得在MD5中有个常量表T表，T表是根据公式计算得来的64个常量，而K就是直接给好的 K(t) = 5A827999 ( 0 \u003c= t \u003c= 19) K(t) = 6ED9EBA1 (20 \u003c= t \u003c= 39) K(t) = 8F1BBCDC (40 \u003c= t \u003c= 59) K(t) = CA62C1D6 (60 \u003c= t \u003c= 79) 文档也给的很干脆，每轮一个固定常量 下面该讲到具体的处理了，MD5算法每次计算改变的只是一个变量的值，但是SHA1每次计算则会改变五个变量的值 uint32_t temp = MoveLeft(A, 5) + Ch(B, C, D) + E + W[t] + K[0]; E = D; D = C; C = MoveLeft(B, 30); B = A; A = temp; 最终只需要将得到的a、b、c、d重新赋值再作为初始变量传递给下一分组计算即可 5 输出结果 在经过分组计算后能够得到A、B、C、D、E，从低位字节A开始，高位字节E结束 ","date":"2023-05-09","objectID":"/posts/%E4%BB%8Erfc3174%E4%B8%AD%E7%90%86%E8%A7%A3sha1%E7%AE%97%E6%B3%95/:0:2","tags":["摘要算法","源码分析"],"title":"从RFC3174中理解SHA1算法","uri":"/posts/%E4%BB%8Erfc3174%E4%B8%AD%E7%90%86%E8%A7%A3sha1%E7%AE%97%E6%B3%95/"},{"categories":["算法研究"],"content":"总结 文中每个步骤都在对比MD5和SHA1的异同，可以看出，虽然结果上SHA1只是多了4个字节，但是在细节上还是有很大的提升，算法整体上更复杂了，变化也更多了，下面总体归纳下两个算法的异同 算法 MD5 SHA1 分组数据处理 使用同一套16组数据 基于16组数据的基础上变化得到额外64组数据 初始化常量 4个 5个 非线性函数 4个 4个 常量表 T常量表分配给64次计算，各不相同 K表分配给80次计算，每20次使用同一个常量 常量变化 每次计算重新给一个常量赋值 每次计算所有常量全部发生变化 ","date":"2023-05-09","objectID":"/posts/%E4%BB%8Erfc3174%E4%B8%AD%E7%90%86%E8%A7%A3sha1%E7%AE%97%E6%B3%95/:0:3","tags":["摘要算法","源码分析"],"title":"从RFC3174中理解SHA1算法","uri":"/posts/%E4%BB%8Erfc3174%E4%B8%AD%E7%90%86%E8%A7%A3sha1%E7%AE%97%E6%B3%95/"},{"categories":["算法研究"],"content":"一、前置知识点 Base64算法是一种编码算法，它是采用常见的64个字符来表示做数据映射的表，分别是A-Z、a-z、+、/。 64对应的二进制是0b111111，也就是 2^6 = 64 换句话说，6个bit就能表示一个字符，而正常的字节对应的8bit，要把正常字符和编码后的字符串联起来的话那么就需要找出它们的最小公倍数，以最小公倍数所代表的长度来划分，那么8和6的公倍数是24，也就可以这么理解，3个正常字符实际上对应的是4个编码字符，举例说明下 lin的正常二进制编码 01101100|01101001|01101110 变成base64的编码 011011|000110|100101|101110 # 正常来说8bit组成一个字节，所以划分成base64的编码之后还需要在前面补两个0变成正常的8bit 变成十进制 27|6|37|46 获取映射表 bGlu 这样就得到了最终的编码，所以就可以理解正常字符中每三个字符会对应编码后的四个字符，如果按长度3来切分存在余数的话（例如1、2），就使用0来做填充，而填充的输出通常用=来表示，所以一般都能看到在base64编码后的字符存在=的情况，这样就表示字符长度非3的倍数（一般余数为1的话就是两个=） ","date":"2023-05-09","objectID":"/posts/%E4%BB%8Erfc4648%E4%B8%AD%E7%90%86%E8%A7%A3base64%E7%AE%97%E6%B3%95/:0:1","tags":["摘要算法","源码分析"],"title":"从RFC4648中理解Base64算法","uri":"/posts/%E4%BB%8Erfc4648%E4%B8%AD%E7%90%86%E8%A7%A3base64%E7%AE%97%E6%B3%95/"},{"categories":["算法研究"],"content":"二、算法流程 1 分组并获取映射 获取输入字符的长度，每3个字符为一组来进行处理 第一个字符的处理：获取字符的二进制前6位，并获取对应的映射 ret.push_back(base64_chars_[(bytes_to_encode[pos + 0] \u0026 0xfc) \u003e\u003e 2]); 第二个字符的处理：第一个字符还剩余两位，取出低位2个bit，同时左移四位并取出第二个字符的前4个bit ret.push_back(base64_chars_[((bytes_to_encode[pos + 0] \u0026 0x03) \u003c\u003c 4) + ((bytes_to_encode[pos + 1] \u0026 0xf0) \u003e\u003e 4)]); 第三个字符的处理：第二个字符的后4个bit还没取出，取出并取第三个字符的前2个bit ret.push_back(base64_chars_[((bytes_to_encode[pos + 1] \u0026 0x0f) \u003c\u003c 2) + ((bytes_to_encode[pos + 2] \u0026 0xc0) \u003e\u003e 6)]); 第四个字符的处理：直接取出剩余的低六位即可 ret.push_back(base64_chars_[ bytes_to_encode[pos + 2] \u0026 0x3f]); 3 尾端处理 剩余两个字符的情况 ret.push_back(base64_chars_[(bytes_to_encode[pos + 1] \u0026 0x0f) \u003c\u003c 2]); ret.push_back(trailing_char); 剩余一个字符的情况 ret.push_back(base64_chars_[(bytes_to_encode[pos + 0] \u0026 0x03) \u003c\u003c 4]); ret.push_back(trailing_char); ret.push_back(trailing_char); ","date":"2023-05-09","objectID":"/posts/%E4%BB%8Erfc4648%E4%B8%AD%E7%90%86%E8%A7%A3base64%E7%AE%97%E6%B3%95/:0:2","tags":["摘要算法","源码分析"],"title":"从RFC4648中理解Base64算法","uri":"/posts/%E4%BB%8Erfc4648%E4%B8%AD%E7%90%86%E8%A7%A3base64%E7%AE%97%E6%B3%95/"},{"categories":["算法研究"],"content":"三、解码算法流程 解码流程就可以当做编码流程的逆向过程，将每个编码根据映射表转化成索引-\u003e二进制，再组合起来即可 ","date":"2023-05-09","objectID":"/posts/%E4%BB%8Erfc4648%E4%B8%AD%E7%90%86%E8%A7%A3base64%E7%AE%97%E6%B3%95/:0:3","tags":["摘要算法","源码分析"],"title":"从RFC4648中理解Base64算法","uri":"/posts/%E4%BB%8Erfc4648%E4%B8%AD%E7%90%86%E8%A7%A3base64%E7%AE%97%E6%B3%95/"},{"categories":["算法研究"],"content":"总结 综合上面所讲到的MD5算法原理，可以看出Base64还是比较简单易懂的，与最终结果相关的正如上面所讲到的有一个关键点，理解它们的含义以及作用在后续我们对Base64算法进行魔改的时候是很有帮助的 ","date":"2023-05-09","objectID":"/posts/%E4%BB%8Erfc4648%E4%B8%AD%E7%90%86%E8%A7%A3base64%E7%AE%97%E6%B3%95/:0:4","tags":["摘要算法","源码分析"],"title":"从RFC4648中理解Base64算法","uri":"/posts/%E4%BB%8Erfc4648%E4%B8%AD%E7%90%86%E8%A7%A3base64%E7%AE%97%E6%B3%95/"},{"categories":["算法研究"],"content":"一、RC4概述 RC4是在1987年提出，和DES算法一样。是一种对称加密算法，也就是说使用的密钥为单钥（或称为私钥）。但不同于DES算法的是。RC4不是对明文进行分组处理，而是通过字节流的方式依次加密明文中的每个字节，同样的，解密的时候也是依次对密文中的每个字节进行解密。 RC4算法的一个特点是可变密钥，可变范围在1256字节，也就是8位2048位 ","date":"2023-05-09","objectID":"/posts/%E4%BB%8Erfc6229%E4%B8%AD%E7%90%86%E8%A7%A3rc4%E7%AE%97%E6%B3%95/:0:1","tags":["摘要算法","源码分析"],"title":"从RFC6229中理解RC4算法","uri":"/posts/%E4%BB%8Erfc6229%E4%B8%AD%E7%90%86%E8%A7%A3rc4%E7%AE%97%E6%B3%95/"},{"categories":["算法研究"],"content":"二、RC4算法框架 RC4算法简单、易于描述，主要使用一个S表来生成密钥流，分为密钥调度算法（KSA）和伪随机数生成算法（PRGA）两个步骤。其中KSA使用原始密钥生成S表，PRGA利用S表来产生密钥流序列。 上面已经说过了，原始密钥K是可变的，而加密单位的话以一个字节为准。 1 密钥调度算法（Key Scheduling Algorithm，KSA） 密钥调度算法的作用是，利用原始密钥K来生成S表 这里的密钥K的长度为1~256字节。S表类似于一个数组，其大小为256，表示为S[0]~S[255]，其中每个S表单元可以存放一个字节（8位） S表的生成分为初始化和置换两部分： 初始化 首先对S表的每个单元依照编号从0~255依次填充（二进制序列）。即S[0]=0；S[1]=1；……S[255]=255 接着建立一个临时数组T，称为T表，其大小与S表相同。使用原始密钥K对T表进行填充。如果K的长度等于256，则直接将K赋值给T表。如果K的长度小于256，则T表剩余的部分继续使用密钥K循环填充，直到填满为止。假设密钥K=123，T表长度为7，则T表=1231231 用代码来描述的话如下 unsigned char S[256]; //状态向量S表 unsigned char T[256]; //临时向量T表 vector\u003cchar\u003e K; int keylen; //密钥长度，keylen个字节，取值范围为1-256 for(int i = 0; i \u003c 256; i++)//对S表、T表的每个单元进行填充 { //填充S表 S[i] = i; //填充T表，使用密钥K循环填充，keylen为密钥K的长度 T[i] = K[i % keylen]; } 置换 置换过程就是根据一定的规则，对S表中的单元交换位置，交换的规则为： 初始化一个变量j=0，然后对于S表的第i个单元，计算得j=(j+S[i]+T[i])mod256，括号中的j为上一次计算得出的j值 每次计算出j后，交换S[i]和S[j]的值 以上的代码如下： int j=0; for(int i=0;i\u003c256;++i){ j=(j+S[i]+T[i])%256; //cout\u003c\u003c\"j=\"\u003c\u003cj\u003c\u003cendl; S[i]=S[i]+S[j]; S[j]=S[i]-S[j]; S[i]=S[i]-S[j]; } 经过置换后，S表中的内容也没有发生实质性的变化，只是各个字节被打乱了位置而已 2 伪随机数生成算法（Pseudo-Random Generation Algorithm，PRGA） 在经过KSA后，S表被建立了起来，之后的任务就是从S表中选取字节单元，输出密钥流序列 为了使生成的密钥流序列更加的随机，PRGA每生成一个字节的密钥流，就会打乱一次S表 生成密钥流、打乱S表的步骤如下： 初始化：首先初始化两个变量i=0，j=0 递增：然后每次在生成一字节的密钥流之前，i+=1（但不能超过256，需要mod256），j+=S[i]（但不能超过256，需要mod256） 交换打乱：交换S[i]和S[j]的值，用来打乱S表 输出：这时就可以输出一字节的密钥流，密钥流取自S表的第S[i]+S[j]的值取余256 重复上述步骤，即可生成多个字节的密钥流序列，代码如下： int i = 0,j = 0;//初始化i，j为0 while(true) { //i自增1 i = (i + 1) % 256; //j自增S[i] j = (j + S[i]) % 256; //交换，打乱S表 swap(S[i], S[j]); //使用变量t保存输出S表的第几个单元 t = (S[i] + S[j]) % 256; //输出一字节的密钥流序列k k = S[t]; } 通过以上方式，就可以得到一系列字节的流密钥序列。之后，使用一字节的流密钥序列与一字节的明文序列异或可以得到密文；同理，使用一字节的流密钥序列与一字节的密文序列异或可以得到明文 ","date":"2023-05-09","objectID":"/posts/%E4%BB%8Erfc6229%E4%B8%AD%E7%90%86%E8%A7%A3rc4%E7%AE%97%E6%B3%95/:0:2","tags":["摘要算法","源码分析"],"title":"从RFC6229中理解RC4算法","uri":"/posts/%E4%BB%8Erfc6229%E4%B8%AD%E7%90%86%E8%A7%A3rc4%E7%AE%97%E6%B3%95/"},{"categories":["算法研究"],"content":"一、前置知识点 SHA2-256算法是SHA第二代的算法，256指的是它的算法结果会产生256位数据，也就是32字节、64位长度的16进制字符。 ","date":"2023-05-09","objectID":"/posts/%E4%BB%8Erfc6234%E4%B8%AD%E7%90%86%E8%A7%A3sha2-256%E7%AE%97%E6%B3%95/:0:1","tags":["摘要算法","源码分析"],"title":"从RFC6234中理解SHA2-256算法","uri":"/posts/%E4%BB%8Erfc6234%E4%B8%AD%E7%90%86%E8%A7%A3sha2-256%E7%AE%97%E6%B3%95/"},{"categories":["算法研究"],"content":"二、算法流程 算法流程就不多做介绍，同其他哈希算法流程类似，都需要经历补位、填充长度以及分组，不同的是每轮循环所做的操作 1 补位 基本一样，不做额外说明 2 记录信息长度 同上 3 初始化变量 依旧是从常量的初始化开始，根据结果256位来看，需要8个常量组成，常量的计算方式是取自自然数中前面8个素数(2,3,5,7,11,13,17,19)的平方根的小数部分的前32位，举例看 \u003e\u003e\u003e 2**0.5-1 0.41421356237309515 0.41421356237309515=6*16^-1+a*16^-2+0\u002616^-3··· 于是, 质数2的平方根的小数部分取前32位就对应0x6a09e667，据此类推，初始化常量的值就是 m_state[0] = 0x6a09e667; m_state[1] = 0xbb67ae85; m_state[2] = 0x3c6ef372; m_state[3] = 0xa54ff53a; m_state[4] = 0x510e527f; m_state[5] = 0x9b05688c; m_state[6] = 0x1f83d9ab; m_state[7] = 0x5be0cd19; 4 处理分组数据 还是同样的套路，输入的数据被分成每512位一组，而512位的数据又被拆分成每32位一小组，一共是16个小组，SHA256的循环轮次和MD5是相同的，但是SHA256和SHA1一样，除了初始的16组是原始的以外，剩余的组都通过额外的公式来计算得来 根据文档 For t = 0 to 15 Wt = M(i)t For t = 16 to 63 Wt = SSIG1(W(t-2)) + W(t-7) + SSIG0(w(t-15)) + W(t-16) c++实现 for (uint8_t i = 0, j = 0; i \u003c 16; i++, j += 4) { // Split data in 32 bit blocks for the 16 first words m[i] = (m_data[j] \u003c\u003c 24) | (m_data[j + 1] \u003c\u003c 16) | (m_data[j + 2] \u003c\u003c 8) | (m_data[j + 3]); } for (uint8_t k = 16 ; k \u003c 64; k++) { // Remaining 48 blocks m[k] = SHA256::sig1(m[k - 2]) + m[k - 7] + SHA256::sig0(m[k - 15]) + m[k - 16]; } uint32_t SHA256::sig0(uint32_t x) { return SHA256::rotr(x, 7) ^ SHA256::rotr(x, 18) ^ (x \u003e\u003e 3); } uint32_t SHA256::sig1(uint32_t x) { return SHA256::rotr(x, 17) ^ SHA256::rotr(x, 19) ^ (x \u003e\u003e 10); } 针对64轮次每轮同样有常量，而SHA256的常量计算方式如下（取自自然数中前面64个素数的立方根的小数部分的前32位） unsigned int K[64] = { 0x428a2f98,0x71374491,0xb5c0fbcf,0xe9b5dba5, 0x3956c25b,0x59f111f1,0x923f82a4,0xab1c5ed5, 0xd807aa98,0x12835b01,0x243185be,0x550c7dc3, 0x72be5d74,0x80deb1fe,0x9bdc06a7,0xc19bf174, 0xe49b69c1,0xefbe4786,0x0fc19dc6,0x240ca1cc, 0x2de92c6f,0x4a7484aa,0x5cb0a9dc,0x76f988da, 0x983e5152,0xa831c66d,0xb00327c8,0xbf597fc7, 0xc6e00bf3,0xd5a79147,0x06ca6351,0x14292967, 0x27b70a85,0x2e1b2138,0x4d2c6dfc,0x53380d13, 0x650a7354,0x766a0abb,0x81c2c92e,0x92722c85, 0xa2bfe8a1,0xa81a664b,0xc24b8b70,0xc76c51a3, 0xd192e819,0xd6990624,0xf40e3585,0x106aa070, 0x19a4c116,0x1e376c08,0x2748774c,0x34b0bcb5, 0x391c0cb3,0x4ed8aa4a,0x5b9cca4f,0x682e6ff3, 0x748f82ee,0x78a5636f,0x84c87814,0x8cc70208, 0x90befffa,0xa4506ceb,0xbef9a3f7,0xc67178f2 }; 看下主处理流程 3. Perform the main hash computation: For t = 0 to 63 T1 = h + BSIG1(e) + CH(e,f,g) + Kt + Wt T2 = BSIG0(a) + MAJ(a,b,c) h = g g = f f = e e = d + T1 d = c c = b b = a a = T1 + T2 出现T1、T2两个中间变量，涉及到了4个函数 CH( x, y, z) = (x AND y) XOR ( (NOT x) AND z) MAJ( x, y, z) = (x AND y) XOR (x AND z) XOR (y AND z) BSIG0(x) = ROTR^2(x) XOR ROTR^13(x) XOR ROTR^22(x) BSIG1(x) = ROTR^6(x) XOR ROTR^11(x) XOR ROTR^25(x) c++来实现 maj = SHA256::majority(state[0], state[1], state[2]); xorA = SHA256::rotr(state[0], 2) ^ SHA256::rotr(state[0], 13) ^ SHA256::rotr(state[0], 22); ch = choose(state[4], state[5], state[6]); xorE = SHA256::rotr(state[4], 6) ^ SHA256::rotr(state[4], 11) ^ SHA256::rotr(state[4], 25); sum = m[i] + K[i] + state[7] + ch + xorE; newA = xorA + maj + sum; newE = state[3] + sum; state[7] = state[6]; state[6] = state[5]; state[5] = state[4]; state[4] = newE; state[3] = state[2]; state[2] = state[1]; state[1] = state[0]; state[0] = newA; 最终只需要将得到的8个变量重新赋值再作为初始变量传递给下一分组计算即可 5 输出结果 在经过分组计算后能够得到A、B、C、D、E、F、G、H，从低位字节A开始，高位字节E结束 ","date":"2023-05-09","objectID":"/posts/%E4%BB%8Erfc6234%E4%B8%AD%E7%90%86%E8%A7%A3sha2-256%E7%AE%97%E6%B3%95/:0:2","tags":["摘要算法","源码分析"],"title":"从RFC6234中理解SHA2-256算法","uri":"/posts/%E4%BB%8Erfc6234%E4%B8%AD%E7%90%86%E8%A7%A3sha2-256%E7%AE%97%E6%B3%95/"},{"categories":["算法研究"],"content":"总结 在了解了MD5、SHA1算法之后再来看SHA2-256算法的话，很明显能发现SHA2-256结合了前两个算法，包括MD5的每轮次的不同常量以及SHA1的数据分组方式以及每轮次计算方式，并且来降低了计算的轮次，引入更多的空间来替换计算时间效率的提升 ","date":"2023-05-09","objectID":"/posts/%E4%BB%8Erfc6234%E4%B8%AD%E7%90%86%E8%A7%A3sha2-256%E7%AE%97%E6%B3%95/:0:3","tags":["摘要算法","源码分析"],"title":"从RFC6234中理解SHA2-256算法","uri":"/posts/%E4%BB%8Erfc6234%E4%B8%AD%E7%90%86%E8%A7%A3sha2-256%E7%AE%97%E6%B3%95/"},{"categories":["算法研究"],"content":"一、CRC算法概述 循环冗余校验（Cyclic Redundancy Check， CRC）是一种根据网络数据包或计算机文件等数据产生简短固定位数校验码的一种信道编码技术，主要用来检测或校验数据传输或者保存后可能出现的错误。它是利用除法及余数的原理来作错误侦测的。 ––维基百科 在对信息的处理过程中，我们可以将要被处理的数据块M看成一个n阶的二进制多项式，其形式如下 $M=a_{n-1}x^{n-1}+a_{n-2}x^{n-2}+a_{n-3}x^{n-3}+……+a_1x^1+a_0$ CRC校验就是基于这种多项式进行的运算，以GF(2)(The integers modulo 2)多项式算术为数学基础，即(模-2)除法的余数运算（其实说白了就是异或Xor），使用的除数不同，CRC的类型也就不一样。CRC传输实际上就是在长度为 k 的数据后面添加供差错检测(Frame Check Sequence) 用的 r 位冗余码（Redundant code 没错CRC里面的R就是这个），使原数据构成 n = k + r 位并发送出去, 此方式又叫（n, k）码。可以证明存在一个最高次幂为n-k=r的多项式G(x), 根据G(x)可以生成k位信息的校验码，而 G(x) 叫做这个CRC码的生成多项式( Poly )。而根据 k 值的不同，就形成了不同的CRC码的生成多项式，以下为各种常用的多项表达式： $crc-4=x^4+x+1$ $crc-8=x8+x5+x^4+1$ $crc-32=x32+x26+x2+x22+x16+x12+x11+x10+x8+x7+x5+x4+x2+x1+1$ 这些多项表达式的值便是(模-2)除法的除数，这里选取CRC-32多项式（即为对应除数）格式，通过取余做操，获取CRC检验码 ","date":"2023-05-09","objectID":"/posts/%E7%90%86%E8%A7%A3crc32%E7%AE%97%E6%B3%95/:0:1","tags":["摘要算法","源码分析"],"title":"理解CRC32算法","uri":"/posts/%E7%90%86%E8%A7%A3crc32%E7%AE%97%E6%B3%95/"},{"categories":["算法研究"],"content":"二、CRC32算法框架 CRC32校验计算框架如下： 选择一个生成多项式G(x) 假设该生成多项式G(x)的二进制数有k位，在发送的数据帧B(x)(设为m位)后加k-1个0，得到新二进制串H(x)，H(x)位数应该为m+k-1。 H(x)“模2除法”除以G(x)，所得到的余数(记为F(x))就是原数据帧的CRC校验码，又称FCS(帧校验序列)。注意，F(x)的位数只能比G(x)少一位，0不能省略。 将F(x)附加到B(x)后面，组成新帧N(x),然后发送到接收端。 接收端将N(x)以“模2除法”除以G(x)，如果没有余数，则表明没有出错(因为在发送端发送数据帧之前就已附加了一个数,做了去余处理(也就已经能整除了),所以结果应该没有余数。如果有余数,则表明该帧在传输过程中出现了差错)。 1 多项式选择 如上面所示，常见CRC标准如下 通常多项式也会使用二进制来表示，计算方式是x的最高幂次对应二进制数的最高位，以下各位对应多项式的各幂次，有此幂次项对应1，无此幂次项对应0。可以看出：x的最高幂次为R，转换成对应的二进制数有R+1位 2 模2除法 CRC校验是基于多项式进行的运算，其加减法运算以2为模GF(2) ，加减时不进（借）位，实际上与逻辑异或（XOR）运算是一致, XOR是将参加运算的两个数据，按二进制位进行“异或”运算。 异或运算规则（^）规则如下： 0^0=0； 0^1=1； 1^0=1； 1^1=0； 即：参加运算的两个对象，如果两个相应位为“异”（值不同），则该位结果为1，否则为0。 3 计算示例 以$G(x)=x4+x3+1$为例，设原数据为10110011 $G(x)=x4+x3+1$, 二进制比特串为11001。（在X的n次方不为0处2的n次方的位=1) 因为校验码4位，所以10110011后面需加4个0，得到101100110000，用“模2除法” (即逻辑亦或^) 即可得出结果： 即CRC^101100110000得到101100110100，并发送到接收端 接收端收到101100110100后除以11001(以“模2除法”方式去除),余数为0则无差错 4 CRC的实现方式 一般来说CRC有多种实现方式，通常有直接生成法和查表法两种 直接生成法 适用于CRC次幂较小的格式，当CRC次幂逐渐增高时，因为其复杂的XOR逻辑运算会拖累系统运行速度，不再建议使用直接生成法，取而代之的是查表法——将数据块M 的一部分提前运算好，并将结果存入数组中，系统开始执行运算时，相当于省去了之前的操作，直接从类似中间的位置开始计算，所以会提高效率 生成CRC码表的方式如下： int make_crc32_table() { uint32_t c; int i = 0; int bit = 0; for(i = 0; i \u003c 256; i++) { c = (uint32_t)i; for(bit = 0; bit \u003c 8; bit++) { if(c\u00261) { c = (c \u003e\u003e 1)^(0xEDB88320); } else { c = c \u003e\u003e 1; } } uiCRC32_Table[i] = c; } } ","date":"2023-05-09","objectID":"/posts/%E7%90%86%E8%A7%A3crc32%E7%AE%97%E6%B3%95/:0:2","tags":["摘要算法","源码分析"],"title":"理解CRC32算法","uri":"/posts/%E7%90%86%E8%A7%A3crc32%E7%AE%97%E6%B3%95/"},{"categories":["算法研究"],"content":"三、思考 如上面所理解的那样，CRC算法关键在于码表，但是码表也分动态生成和静态表，若是动态生成表，则应留意生成多项式，若是静态表，则会在数据段留下整个表 ","date":"2023-05-09","objectID":"/posts/%E7%90%86%E8%A7%A3crc32%E7%AE%97%E6%B3%95/:0:3","tags":["摘要算法","源码分析"],"title":"理解CRC32算法","uri":"/posts/%E7%90%86%E8%A7%A3crc32%E7%AE%97%E6%B3%95/"},{"categories":["算法研究"],"content":" 写法 算法常量 编码表 算法流程 ","date":"2023-05-09","objectID":"/posts/%E6%8E%A2%E8%AE%A8%E5%85%B3%E4%BA%8Ebase64%E7%AE%97%E6%B3%95%E7%9A%84%E9%AD%94%E6%94%B9%E6%96%B9%E5%BC%8F/:0:0","tags":["摘要算法","魔改思路"],"title":"探讨关于Base64算法的魔改方式","uri":"/posts/%E6%8E%A2%E8%AE%A8%E5%85%B3%E4%BA%8Ebase64%E7%AE%97%E6%B3%95%E7%9A%84%E9%AD%94%E6%94%B9%E6%96%B9%E5%BC%8F/"},{"categories":["算法研究"],"content":" 写法 函数名 算法常量 CRC码表 多项式的二进制 算法流程 CRC码表生成方式 ","date":"2023-05-09","objectID":"/posts/%E6%8E%A2%E8%AE%A8%E5%85%B3%E4%BA%8Ecrc32%E7%AE%97%E6%B3%95%E7%9A%84%E9%AD%94%E6%94%B9%E6%96%B9%E5%BC%8F/:0:0","tags":["摘要算法","魔改思路"],"title":"探讨关于CRC32算法的魔改方式","uri":"/posts/%E6%8E%A2%E8%AE%A8%E5%85%B3%E4%BA%8Ecrc32%E7%AE%97%E6%B3%95%E7%9A%84%E9%AD%94%E6%94%B9%E6%96%B9%E5%BC%8F/"},{"categories":["算法研究"],"content":" 写法 函数名 常量初始化方式 算法常量 IV 转换变量 T常量表 算法流程 非线性函数 ","date":"2023-05-09","objectID":"/posts/%E6%8E%A2%E8%AE%A8%E5%85%B3%E4%BA%8Emd5%E7%AE%97%E6%B3%95%E7%9A%84%E9%AD%94%E6%94%B9%E6%96%B9%E5%BC%8F/:0:0","tags":["摘要算法","魔改思路"],"title":"探讨关于MD5算法的魔改方式","uri":"/posts/%E6%8E%A2%E8%AE%A8%E5%85%B3%E4%BA%8Emd5%E7%AE%97%E6%B3%95%E7%9A%84%E9%AD%94%E6%94%B9%E6%96%B9%E5%BC%8F/"},{"categories":["算法研究"],"content":" 写法 算法常量 S盒长度、值 算法流程 数据交换 流数据异或 ","date":"2023-05-09","objectID":"/posts/%E6%8E%A2%E8%AE%A8%E5%85%B3%E4%BA%8Erc4%E7%AE%97%E6%B3%95%E7%9A%84%E9%AD%94%E6%94%B9%E6%96%B9%E5%BC%8F/:0:0","tags":["摘要算法","魔改思路"],"title":"探讨关于RC4算法的魔改方式","uri":"/posts/%E6%8E%A2%E8%AE%A8%E5%85%B3%E4%BA%8Erc4%E7%AE%97%E6%B3%95%E7%9A%84%E9%AD%94%E6%94%B9%E6%96%B9%E5%BC%8F/"},{"categories":["算法研究"],"content":" 写法 函数名 常量初始化方式 算法常量 IV K常量表 算法流程 分组数据变化的步函数 非线性函数 每次计算时初始化变量赋值方式 ","date":"2023-05-09","objectID":"/posts/%E6%8E%A2%E8%AE%A8%E5%85%B3%E4%BA%8Esha1%E7%AE%97%E6%B3%95%E7%9A%84%E9%AD%94%E6%94%B9%E6%96%B9%E5%BC%8F/:0:0","tags":["摘要算法","魔改思路"],"title":"探讨关于SHA1算法的魔改方式","uri":"/posts/%E6%8E%A2%E8%AE%A8%E5%85%B3%E4%BA%8Esha1%E7%AE%97%E6%B3%95%E7%9A%84%E9%AD%94%E6%94%B9%E6%96%B9%E5%BC%8F/"},{"categories":["算法研究"],"content":" 写法 函数名 常量初始化方式 算法常量 IV K常量表 算法流程 分组数据变化的步函数 非线性函数 每次计算时初始化变量赋值方式 ","date":"2023-05-09","objectID":"/posts/%E6%8E%A2%E8%AE%A8%E5%85%B3%E4%BA%8Esha256%E7%AE%97%E6%B3%95%E7%9A%84%E9%AD%94%E6%94%B9%E6%96%B9%E5%BC%8F/:0:0","tags":["摘要算法","魔改思路"],"title":"探讨关于SHA256算法的魔改方式","uri":"/posts/%E6%8E%A2%E8%AE%A8%E5%85%B3%E4%BA%8Esha256%E7%AE%97%E6%B3%95%E7%9A%84%E9%AD%94%E6%94%B9%E6%96%B9%E5%BC%8F/"},{"categories":["ollvm混淆与反混淆"],"content":"goron使用的控制流平坦化是ollvm原生的 ","date":"2023-03-30","objectID":"/posts/ollvm%E6%B7%B7%E6%B7%86%E4%B8%8E%E5%8F%8D%E6%B7%B7%E6%B7%86-goron%E6%A1%86%E6%9E%B6%E6%8E%A7%E5%88%B6%E6%B5%81%E5%B9%B3%E5%9D%A6%E5%8C%96%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/:0:0","tags":["goron框架"],"title":"Ollvm混淆与反混淆: goron框架控制流平坦化的实现原理","uri":"/posts/ollvm%E6%B7%B7%E6%B7%86%E4%B8%8E%E5%8F%8D%E6%B7%B7%E6%B7%86-goron%E6%A1%86%E6%9E%B6%E6%8E%A7%E5%88%B6%E6%B5%81%E5%B9%B3%E5%9D%A6%E5%8C%96%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/"},{"categories":["ollvm混淆与反混淆"],"content":"一、控制流平坦化实现逻辑 1.1 生成SCRAMBLER // SCRAMBLER char scrambling_key[16]; llvm::cryptoutils-\u003eget_bytes(scrambling_key, 16); // END OF SCRAMBLER 1.2 调用Lower switch // Lower switch #if LLVM_VERSION_MAJOR * 10 + LLVM_VERSION_MINOR \u003e= 90 FunctionPass *lower = createLegacyLowerSwitchPass(); #else FunctionPass *lower = createLowerSwitchPass(); #endif lower-\u003erunOnFunction(*f); bool LowerSwitch::runOnFunction(Function \u0026F) { bool Changed = false; SmallPtrSet\u003cBasicBlock*, 8\u003e DeleteList; // 遍历function获取基本块 for (Function::iterator I = F.begin(), E = F.end(); I != E; ) { BasicBlock *Cur = \u0026*I++; // Advance over block so we don't traverse new blocks // If the block is a dead Default block that will be deleted later, don't // waste time processing it. if (DeleteList.count(Cur)) continue; // 如果块的末尾指令是switch指令，则需要处理 if (SwitchInst *SI = dyn_cast\u003cSwitchInst\u003e(Cur-\u003egetTerminator())) { Changed = true; processSwitchInst(SI, DeleteList); } } for (BasicBlock* BB: DeleteList) { DeleteDeadBlock(BB); } return Changed; } Lower switch的目的是去除原生函数的switch结构降级成if结构 1.3 保存所有块 // Save all original BB for (Function::iterator i = f-\u003ebegin(); i != f-\u003eend(); ++i) { BasicBlock *tmp = \u0026*i; origBB.push_back(tmp); BasicBlock *bb = \u0026*i; if (isa\u003cInvokeInst\u003e(bb-\u003egetTerminator())) { return false; } } 1.4 第一个基本块处理 // Remove first BB // 删除第一个块并做一些处理 origBB.erase(origBB.begin()); // Get a pointer on the first BB // 获取第一个块指针 Function::iterator tmp = f-\u003ebegin(); //++tmp; BasicBlock *insert = \u0026*tmp; // If main begin with an if BranchInst *br = NULL; if (isa\u003cBranchInst\u003e(insert-\u003egetTerminator())) { br = cast\u003cBranchInst\u003e(insert-\u003egetTerminator()); } // 如果块末尾是条件指令或者后继块有多个，都需要单独切割出来 if ((br != NULL \u0026\u0026 br-\u003eisConditional()) || insert-\u003egetTerminator()-\u003egetNumSuccessors() \u003e 1) { BasicBlock::iterator i = insert-\u003eend(); --i; if (insert-\u003esize() \u003e 1) { --i; } // 将条件跳转的语句切割出来，成为一个新的基本块，并插入到vector开头 BasicBlock *tmpBB = insert-\u003esplitBasicBlock(i, \"first\"); origBB.insert(origBB.begin(), tmpBB); } // Remove jump // 删除第一个基本块最后的末尾跳转 insert-\u003egetTerminator()-\u003eeraseFromParent(); 因为平坦化要求第一个基本块只能有一个后继基本块，如果第一个基本块末尾就是条件跳转（有两个或多个后继块）就无法进行后面的平坦化操作 1.5 创建switch变量并设置初始值 // Create switch variable and set as it switchVar = new AllocaInst(Type::getInt32Ty(f-\u003egetContext()), 0, \"switchVar\", insert); // 首先设置初始值 new StoreInst( ConstantInt::get(Type::getInt32Ty(f-\u003egetContext()), llvm::cryptoutils-\u003escramble32(0, scrambling_key)), switchVar, insert); 1.6 基本骨架设置 // Create main loop // 创建loopEntry、loopEntry两个基本块 loopEntry = BasicBlock::Create(f-\u003egetContext(), \"loopEntry\", f, insert); loopEnd = BasicBlock::Create(f-\u003egetContext(), \"loopEnd\", f, insert); // load switchVar 变量 load = new LoadInst(switchVar, \"switchVar\", loopEntry); // Move first BB on top insert-\u003emoveBefore(loopEntry); // 构建顺序insert-\u003eloopEntry BranchInst::Create(loopEntry, insert); // loopEnd jump to loopEntry // 构建顺序loopEnd-\u003eloopEntry BranchInst::Create(loopEntry, loopEnd); BasicBlock *swDefault = BasicBlock::Create(f-\u003egetContext(), \"switchDefault\", f, loopEnd); // 构建swDefault-\u003eloopEnd BranchInst::Create(loopEnd, swDefault); // Create switch instruction itself and set condition switchI = SwitchInst::Create(\u0026*f-\u003ebegin(), swDefault, 0, loopEntry); switchI-\u003esetCondition(load); // Remove branch jump from 1st BB and make a jump to the while f-\u003ebegin()-\u003egetTerminator()-\u003eeraseFromParent(); // 构建顺序第一个块到loopEntry BranchInst::Create(loopEntry, \u0026*f-\u003ebegin()); 整体顺序就是第一个块-\u003eloopEntry，swDefault-\u003eloopEnd，loopEnd-\u003eloopEntry 1.7 装入基本块 // Put all BB in the switch // 遍历每个块 for (vector\u003cBasicBlock *\u003e::iterator b = origBB.begin(); b != origBB.end(); ++b) { BasicBlock *i = *b; ConstantInt *numCase = NULL; // 块放在loopEnd前面 // Move the BB inside the switch (only visual, no code logic) i-\u003emoveBefore(loopEnd); // 设置随机值并加入到switch结构中 // Add case to switch numCase = cast\u003cConstantInt\u003e(ConstantInt::get( switchI-\u003egetCondition()-\u003egetType(), llvm::cryptoutils-\u003escramble32(switchI-\u003egetNumCases(), scrambling_key))); switchI-\u003eaddCase(numCase, i); } 这里只是单纯的将块和随机变量绑定，并没有指定块的跳转顺序，下面要开始调整基本块之间的关系了 1.8 计算switch","date":"2023-03-30","objectID":"/posts/ollvm%E6%B7%B7%E6%B7%86%E4%B8%8E%E5%8F%8D%E6%B7%B7%E6%B7%86-goron%E6%A1%86%E6%9E%B6%E6%8E%A7%E5%88%B6%E6%B5%81%E5%B9%B3%E5%9D%A6%E5%8C%96%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/:0:1","tags":["goron框架"],"title":"Ollvm混淆与反混淆: goron框架控制流平坦化的实现原理","uri":"/posts/ollvm%E6%B7%B7%E6%B7%86%E4%B8%8E%E5%8F%8D%E6%B7%B7%E6%B7%86-goron%E6%A1%86%E6%9E%B6%E6%8E%A7%E5%88%B6%E6%B5%81%E5%B9%B3%E5%9D%A6%E5%8C%96%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/"},{"categories":["ollvm混淆与反混淆"],"content":"二、总结 调用lower switch去除当前函数的switch结构 保存所有块并单独刨除第一个块 创建switch变量并设置初始值 设置基本骨架frist-\u003eloopEntry-\u003eswitch-\u003eloopEnd-\u003eloopEntry 装入基本块 重新计算switchVar 栈修复 ","date":"2023-03-30","objectID":"/posts/ollvm%E6%B7%B7%E6%B7%86%E4%B8%8E%E5%8F%8D%E6%B7%B7%E6%B7%86-goron%E6%A1%86%E6%9E%B6%E6%8E%A7%E5%88%B6%E6%B5%81%E5%B9%B3%E5%9D%A6%E5%8C%96%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/:0:2","tags":["goron框架"],"title":"Ollvm混淆与反混淆: goron框架控制流平坦化的实现原理","uri":"/posts/ollvm%E6%B7%B7%E6%B7%86%E4%B8%8E%E5%8F%8D%E6%B7%B7%E6%B7%86-goron%E6%A1%86%E6%9E%B6%E6%8E%A7%E5%88%B6%E6%B5%81%E5%B9%B3%E5%9D%A6%E5%8C%96%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/"},{"categories":["ollvm混淆与反混淆"],"content":"函数实现逻辑在llvm/lib/Transforms/Obfuscation/StringEncryption.cpp文件中，IndirectBranch，集成自类ModulePass，实现了runOnModule函数 Module（模块）： Module是LLVM的最高级别的组织单元，它代表一个编译单元或一个独立的代码模块 Module包含了全局变量、函数定义、类型定义等 一个Module可以包含多个Function Function（函数）： Function代表一个具体的函数，包含函数的定义和实现 Function定义了函数的参数类型、返回类型、函数名等信息 Function还包含了函数的基本块（Basic Block）和指令（Instruction） 在LLVM的编译过程中，首先创建一个Module，然后在Module中创建和添加Function，最后为每个Function添加基本块和指令 ","date":"2023-03-30","objectID":"/posts/ollvm%E6%B7%B7%E6%B7%86%E4%B8%8E%E5%8F%8D%E6%B7%B7%E6%B7%86-goron%E6%A1%86%E6%9E%B6%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8A%A0%E5%AF%86%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/:0:0","tags":["goron框架"],"title":"Ollvm混淆与反混淆: goron框架字符串加密的实现原理","uri":"/posts/ollvm%E6%B7%B7%E6%B7%86%E4%B8%8E%E5%8F%8D%E6%B7%B7%E6%B7%86-goron%E6%A1%86%E6%9E%B6%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8A%A0%E5%AF%86%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/"},{"categories":["ollvm混淆与反混淆"],"content":"一、字符串加密的实现逻辑 1.1 字符串收集 // llvm/lib/Transforms/Obfuscation/StringEncryption.cpp std::set\u003cGlobalVariable *\u003e ConstantStringUsers; // collect all c strings LLVMContext \u0026Ctx = M.getContext(); ConstantInt *Zero = ConstantInt::get(Type::getInt32Ty(Ctx), 0); for (GlobalVariable \u0026GV : M.globals()) { if (!GV.isConstant() || !GV.hasInitializer()) { continue; } // 获取module下面的全局变量 Constant *Init = GV.getInitializer(); if (Init == nullptr) continue; if (ConstantDataSequential *CDS = dyn_cast\u003cConstantDataSequential\u003e(Init)) { if (CDS-\u003eisCString()) { CSPEntry *Entry = new CSPEntry(); StringRef Data = CDS-\u003egetRawDataValues(); Entry-\u003eData.reserve(Data.size()); // 保存字符数据到Data字段 for (unsigned i = 0; i \u003c Data.size(); ++i) { Entry-\u003eData.push_back(static_cast\u003cuint8_t\u003e(Data[i])); } Entry-\u003eID = static_cast\u003cunsigned\u003e(ConstantStringPool.size()); ConstantAggregateZero *ZeroInit = ConstantAggregateZero::get(CDS-\u003egetType()); GlobalVariable *DecGV = new GlobalVariable(M, CDS-\u003egetType(), false, GlobalValue::PrivateLinkage, ZeroInit, \"dec\" + Twine::utohexstr(Entry-\u003eID) + GV.getName()); GlobalVariable *DecStatus = new GlobalVariable(M, Type::getInt32Ty(Ctx), false, GlobalValue::PrivateLinkage, Zero, \"dec_status_\" + Twine::utohexstr(Entry-\u003eID) + GV.getName()); DecGV-\u003esetAlignment(GV.getAlignment()); Entry-\u003eDecGV = DecGV; Entry-\u003eDecStatus = DecStatus; ConstantStringPool.push_back(Entry); CSPEntryMap[\u0026GV] = Entry; collectConstantStringUser(\u0026GV, ConstantStringUsers); } } } ConstantStringPool收集CSPEntry实例，包含字符串 CSPEntryMap包含对应的GV 1.2 字符加密并构建解密函数 // llvm/lib/Transforms/Obfuscation/StringEncryption.cpp for (CSPEntry *Entry: ConstantStringPool) { // 生成enckey，针对每个module不同 getRandomBytes(Entry-\u003eEncKey, 16, 32); // 每个字符串进行加密 for (unsigned i = 0; i \u003c Entry-\u003eData.size(); ++i) { Entry-\u003eData[i] ^= Entry-\u003eEncKey[i % Entry-\u003eEncKey.size()]; } // 为每个module的解密函数生成 Entry-\u003eDecFunc = buildDecryptFunction(\u0026M, Entry); } void StringEncryption::getRandomBytes(std::vector\u003cuint8_t\u003e \u0026Bytes, uint32_t MinSize, uint32_t MaxSize) { uint32_t N = RandomEngine.get_uint32_t(); uint32_t Len; assert(MaxSize \u003e= MinSize); if (MinSize == MaxSize) { Len = MinSize; } else { Len = MinSize + (N % (MaxSize - MinSize)); } char *Buffer = new char[Len]; RandomEngine.get_bytes(Buffer, Len); for (uint32_t i = 0; i \u003c Len; ++i) { Bytes.push_back(static_cast\u003cuint8_t\u003e(Buffer[i])); } delete[] Buffer; } Function *StringEncryption::buildDecryptFunction(Module *M, const StringEncryption::CSPEntry *Entry) { LLVMContext \u0026Ctx = M-\u003egetContext(); IRBuilder\u003c\u003e IRB(Ctx); // 根据开头所说，module包含func、func包含块，因此创建逻辑也根据此 FunctionType *FuncTy = FunctionType::get(Type::getVoidTy(Ctx), {IRB.getInt8PtrTy(), IRB.getInt8PtrTy()}, false); // 函数创建 Function *DecFunc = Function::Create(FuncTy, GlobalValue::PrivateLinkage, \"goron_decrypt_string_\" + Twine::utohexstr(Entry-\u003eID), M); // 参数 auto ArgIt = DecFunc-\u003earg_begin(); Argument *PlainString = ArgIt; // output ++ArgIt; Argument *Data = ArgIt; // input PlainString-\u003esetName(\"plain_string\"); PlainString-\u003eaddAttr(Attribute::NoCapture); Data-\u003esetName(\"data\"); Data-\u003eaddAttr(Attribute::NoCapture); Data-\u003eaddAttr(Attribute::ReadOnly); // 创建块 BasicBlock *Enter = BasicBlock::Create(Ctx, \"Enter\", DecFunc); BasicBlock *LoopBody = BasicBlock::Create(Ctx, \"LoopBody\", DecFunc); BasicBlock *UpdateDecStatus = BasicBlock::Create(Ctx, \"UpdateDecStatus\", DecFunc); BasicBlock *Exit = BasicBlock::Create(Ctx, \"Exit\", DecFunc); IRB.SetInsertPoint(Enter); ConstantInt *KeySize = ConstantInt::get(Type::getInt32Ty(Ctx), Entry-\u003eEncKey.size()); Value *EncPtr = IRB.CreateInBoundsGEP(Data, KeySize); Value *DecStatus = IRB.CreateLoad(Entry-\u003eDecStatus); Value *IsDecrypted = IRB.CreateICmpEQ(DecStatus, IRB.getInt32(1)); IRB.CreateCondBr(IsDecrypted, Exit, LoopBody); IRB.SetInsertPoint(LoopBody); PHINode *LoopCounter = IRB.CreatePHI(IRB.getInt32Ty(), 2); LoopCounter-\u003eaddIncoming(IRB.getInt32(0), Enter); Value *EncCharPtr = IRB.CreateInBoundsGEP(EncPtr, LoopCounter); Value *EncChar = IRB.CreateLoad(EncCharPtr); Value *KeyIdx = IRB.Crea","date":"2023-03-30","objectID":"/posts/ollvm%E6%B7%B7%E6%B7%86%E4%B8%8E%E5%8F%8D%E6%B7%B7%E6%B7%86-goron%E6%A1%86%E6%9E%B6%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8A%A0%E5%AF%86%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/:0:1","tags":["goron框架"],"title":"Ollvm混淆与反混淆: goron框架字符串加密的实现原理","uri":"/posts/ollvm%E6%B7%B7%E6%B7%86%E4%B8%8E%E5%8F%8D%E6%B7%B7%E6%B7%86-goron%E6%A1%86%E6%9E%B6%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8A%A0%E5%AF%86%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/"},{"categories":["ollvm混淆与反混淆"],"content":"与间接函数调用同理，可参考 // llvm/lib/Transforms/Obfuscation/IndirectGlobalVariable.cpp bool runOnFunction(Function \u0026Fn) override { if (!toObfuscate(flag, \u0026Fn, \"indgv\")) { return false; } if (Options \u0026\u0026 Options-\u003eskipFunction(Fn.getName())) { return false; } LLVMContext \u0026Ctx = Fn.getContext(); GVNumbering.clear(); GlobalVariables.clear(); LowerConstantExpr(Fn); NumberGlobalVariable(Fn); if (GlobalVariables.empty()) { return false; } uint32_t V = RandomEngine.get_uint32_t() \u0026 ~3; ConstantInt *EncKey = ConstantInt::get(Type::getInt32Ty(Ctx), V, false); const IPObfuscationContext::IPOInfo *SecretInfo = nullptr; if (IPO) { SecretInfo = IPO-\u003egetIPOInfo(\u0026Fn); } Value *MySecret; if (SecretInfo) { MySecret = SecretInfo-\u003eSecretLI; } else { MySecret = ConstantInt::get(Type::getInt32Ty(Ctx), 0, true); } ConstantInt *Zero = ConstantInt::get(Type::getInt32Ty(Ctx), 0); GlobalVariable *GVars = getIndirectGlobalVariables(Fn, EncKey); for (inst_iterator I = inst_begin(Fn), E = inst_end(Fn); I != E; ++I) { Instruction *Inst = \u0026*I; if (PHINode *PHI = dyn_cast\u003cPHINode\u003e(Inst)) { for (unsigned int i = 0; i \u003c PHI-\u003egetNumIncomingValues(); ++i) { Value *val = PHI-\u003egetIncomingValue(i); if (GlobalVariable *GV = dyn_cast\u003cGlobalVariable\u003e(val)) { if (GVNumbering.count(GV) == 0) { continue; } Instruction *IP = PHI-\u003egetIncomingBlock(i)-\u003egetTerminator(); IRBuilder\u003c\u003e IRB(IP); Value *Idx = ConstantInt::get(Type::getInt32Ty(Ctx), GVNumbering[GV]); Value *GEP = IRB.CreateGEP(GVars, {Zero, Idx}); LoadInst *EncGVAddr = IRB.CreateLoad(GEP, GV-\u003egetName()); Constant *X; if (SecretInfo) { X = ConstantExpr::getSub(SecretInfo-\u003eSecretCI, EncKey); } else { X = ConstantExpr::getSub(Zero, EncKey); } Value *Secret = IRB.CreateSub(X, MySecret); Value *GVAddr = IRB.CreateGEP(EncGVAddr, Secret); GVAddr = IRB.CreateBitCast(GVAddr, GV-\u003egetType()); GVAddr-\u003esetName(\"IndGV\"); Inst-\u003ereplaceUsesOfWith(GV, GVAddr); } } } else { for (User::op_iterator op = Inst-\u003eop_begin(); op != Inst-\u003eop_end(); ++op) { if (GlobalVariable *GV = dyn_cast\u003cGlobalVariable\u003e(*op)) { if (GVNumbering.count(GV) == 0) { continue; } IRBuilder\u003c\u003e IRB(Inst); Value *Idx = ConstantInt::get(Type::getInt32Ty(Ctx), GVNumbering[GV]); Value *GEP = IRB.CreateGEP(GVars, {Zero, Idx}); LoadInst *EncGVAddr = IRB.CreateLoad(GEP, GV-\u003egetName()); Constant *X; if (SecretInfo) { X = ConstantExpr::getSub(SecretInfo-\u003eSecretCI, EncKey); } else { X = ConstantExpr::getSub(Zero, EncKey); } Value *Secret = IRB.CreateSub(X, MySecret); Value *GVAddr = IRB.CreateGEP(EncGVAddr, Secret); GVAddr = IRB.CreateBitCast(GVAddr, GV-\u003egetType()); GVAddr-\u003esetName(\"IndGV\"); Inst-\u003ereplaceUsesOfWith(GV, GVAddr); } } } } return true; } }; ","date":"2023-03-30","objectID":"/posts/ollvm%E6%B7%B7%E6%B7%86%E4%B8%8E%E5%8F%8D%E6%B7%B7%E6%B7%86-goron%E6%A1%86%E6%9E%B6%E9%97%B4%E6%8E%A5%E5%85%A8%E5%B1%80%E5%8F%98%E9%87%8F%E5%BC%95%E7%94%A8%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/:0:0","tags":["goron框架"],"title":"Ollvm混淆与反混淆: goron框架间接全局变量引用的实现原理","uri":"/posts/ollvm%E6%B7%B7%E6%B7%86%E4%B8%8E%E5%8F%8D%E6%B7%B7%E6%B7%86-goron%E6%A1%86%E6%9E%B6%E9%97%B4%E6%8E%A5%E5%85%A8%E5%B1%80%E5%8F%98%E9%87%8F%E5%BC%95%E7%94%A8%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/"},{"categories":["ollvm混淆与反混淆"],"content":"函数实现逻辑在llvm/lib/Transforms/Obfuscation/IndirectCall.cpp文件中，IndirectBranch，集成自类FunctionPass ","date":"2023-03-30","objectID":"/posts/ollvm%E6%B7%B7%E6%B7%86%E4%B8%8E%E5%8F%8D%E6%B7%B7%E6%B7%86-goron%E6%A1%86%E6%9E%B6%E9%97%B4%E6%8E%A5%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/:0:0","tags":["goron框架"],"title":"Ollvm混淆与反混淆: goron框架间接函数调用的实现原理","uri":"/posts/ollvm%E6%B7%B7%E6%B7%86%E4%B8%8E%E5%8F%8D%E6%B7%B7%E6%B7%86-goron%E6%A1%86%E6%9E%B6%E9%97%B4%E6%8E%A5%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/"},{"categories":["ollvm混淆与反混淆"],"content":"一、间接函数调用实现逻辑 1.1 变量初始化 std::map\u003cFunction *, unsigned\u003e CalleeNumbering; std::vector\u003cCallInst *\u003e CallSites; std::vector\u003cFunction *\u003e Callees; CalleeNumbering.clear(); Callees.clear(); CallSites.clear(); 1.2 CallSites、CalleeNumbering、Callees信息收集 void NumberCallees(Function \u0026F) { for (auto \u0026BB:F) { for (auto \u0026I:BB) { // 如果指令是调用指令 if (dyn_cast\u003cCallInst\u003e(\u0026I)) { CallSite CS(\u0026I); // 获取被调用的函数 Function *Callee = CS.getCalledFunction(); if (Callee == nullptr) { continue; } if (Callee-\u003eisIntrinsic()) { continue; } // CallSites添加这条指令 CallSites.push_back((CallInst *) \u0026I); if (CalleeNumbering.count(Callee) == 0) { CalleeNumbering[Callee] = Callees.size(); // Callees添加被调用的函数 Callees.push_back(Callee); } } } } } 1.3 重构Callees块的全局跳转变量 // 生成enckey uint32_t V = RandomEngine.get_uint32_t() \u0026 ~3; ConstantInt *EncKey = ConstantInt::get(Type::getInt32Ty(Ctx), V, false); GlobalVariable *Targets = getIndirectCallees(Fn, EncKey); GlobalVariable *getIndirectCallees(Function \u0026F, ConstantInt *EncKey) { std::string GVName(F.getName().str() + \"_IndirectCallees\"); GlobalVariable *GV = F.getParent()-\u003egetNamedGlobal(GVName); if (GV) return GV; // callee's address std::vector\u003cConstant *\u003e Elements; for (auto Callee:Callees) { Constant *CE = ConstantExpr::getBitCast(Callee, Type::getInt8PtrTy(F.getContext())); CE = ConstantExpr::getGetElementPtr(Type::getInt8Ty(F.getContext()), CE, EncKey); Elements.push_back(CE); } ArrayType *ATy = ArrayType::get(Type::getInt8PtrTy(F.getContext()), Elements.size()); Constant *CA = ConstantArray::get(ATy, ArrayRef\u003cConstant *\u003e(Elements)); GV = new GlobalVariable(*F.getParent(), ATy, false, GlobalValue::LinkageTypes::PrivateLinkage, CA, GVName); appendToCompilerUsed(*F.getParent(), {GV}); return GV; } 和间接跳转同理，间接模式都需要使用到全局变量+enckey，这里将所有的Callees函数都+enckey保存在全局变量中 1.4 指令替换 for (auto CI : CallSites) { // 获取idx Value *Idx = ConstantInt::get(Type::getInt32Ty(Ctx), CalleeNumbering[CS.getCalledFunction()]); Value *GEP = IRB.CreateGEP(Targets, {Zero, Idx}); LoadInst *EncDestAddr = IRB.CreateLoad(GEP, CI-\u003egetName()); Constant *X; if (SecretInfo) { X = ConstantExpr::getSub(SecretInfo-\u003eSecretCI, EncKey); } else { X = ConstantExpr::getSub(Zero, EncKey); } // 获取原始的地址 const AttributeList \u0026CallPAL = CS.getAttributes(); CallSite::arg_iterator I = CS.arg_begin(); unsigned i = 0; for (unsigned e = FTy-\u003egetNumParams(); i != e; ++I, ++i) { Args.push_back(*I); AttributeSet Attrs = CallPAL.getParamAttributes(i); ArgAttrVec.push_back(Attrs); } for (CallSite::arg_iterator E = CS.arg_end(); I != E; ++I, ++i) { Args.push_back(*I); ArgAttrVec.push_back(CallPAL.getParamAttributes(i)); } AttributeList NewCallPAL = AttributeList::get( IRB.getContext(), CallPAL.getFnAttributes(), CallPAL.getRetAttributes(), ArgAttrVec); Value *Secret = IRB.CreateSub(X, MySecret); Value *DestAddr = IRB.CreateGEP(EncDestAddr, Secret); Value *FnPtr = IRB.CreateBitCast(DestAddr, FTy-\u003egetPointerTo()); FnPtr-\u003esetName(\"Call_\" + Callee-\u003egetName()); // 新建调用替换原始调用 CallInst *NewCall = IRB.CreateCall(FTy, FnPtr, Args, Call-\u003egetName()); NewCall-\u003esetAttributes(NewCallPAL); Call-\u003ereplaceAllUsesWith(NewCall); Call-\u003eeraseFromParent(); } 1.5 效果分析 w8赋值 x10为全局变量+index+enckey后的地址 blr x10 ","date":"2023-03-30","objectID":"/posts/ollvm%E6%B7%B7%E6%B7%86%E4%B8%8E%E5%8F%8D%E6%B7%B7%E6%B7%86-goron%E6%A1%86%E6%9E%B6%E9%97%B4%E6%8E%A5%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/:0:1","tags":["goron框架"],"title":"Ollvm混淆与反混淆: goron框架间接函数调用的实现原理","uri":"/posts/ollvm%E6%B7%B7%E6%B7%86%E4%B8%8E%E5%8F%8D%E6%B7%B7%E6%B7%86-goron%E6%A1%86%E6%9E%B6%E9%97%B4%E6%8E%A5%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/"},{"categories":["ollvm混淆与反混淆"],"content":"二、总结 收集调用块中的被调用函数，形成map，map包含被调用函数和对应的index 生成enckey，遍历被调用函数，对其地址进行二次加密，整理到全局变量中 遍历调用块，对调用方式进行重构 根据map获取index，在全局变量中获取被调用函数的加密地址 解析得到原始地址 指令替换 ","date":"2023-03-30","objectID":"/posts/ollvm%E6%B7%B7%E6%B7%86%E4%B8%8E%E5%8F%8D%E6%B7%B7%E6%B7%86-goron%E6%A1%86%E6%9E%B6%E9%97%B4%E6%8E%A5%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/:0:2","tags":["goron框架"],"title":"Ollvm混淆与反混淆: goron框架间接函数调用的实现原理","uri":"/posts/ollvm%E6%B7%B7%E6%B7%86%E4%B8%8E%E5%8F%8D%E6%B7%B7%E6%B7%86-goron%E6%A1%86%E6%9E%B6%E9%97%B4%E6%8E%A5%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/"},{"categories":["ollvm混淆与反混淆"],"content":"Obfusaction Pass的管理统一在类ObfuscationPassManager中 static cl::opt\u003cbool\u003e EnableIndirectBr(\"irobf-indbr\", cl::init(false), cl::NotHidden, cl::desc(\"Enable IR Indirect Branch Obfuscation.\")); 根据clang的flag来判断是否开启某类混淆，以间接跳转为例 add(llvm::createIndirectBranchPass(EnableIndirectBr || Options-\u003eEnableIndirectBr, IPO, Options.get())); 对应的实现类是IndirectBranch，集成自类FunctionPass，重写函数getPassName、runOnFunction，具体实现是在runOnFunction函数中 ","date":"2023-03-30","objectID":"/posts/ollvm%E6%B7%B7%E6%B7%86%E4%B8%8E%E5%8F%8D%E6%B7%B7%E6%B7%86-goron%E6%A1%86%E6%9E%B6%E9%97%B4%E6%8E%A5%E8%B7%B3%E8%BD%AC%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/:0:0","tags":["goron框架"],"title":"Ollvm混淆与反混淆: goron框架间接跳转的实现原理","uri":"/posts/ollvm%E6%B7%B7%E6%B7%86%E4%B8%8E%E5%8F%8D%E6%B7%B7%E6%B7%86-goron%E6%A1%86%E6%9E%B6%E9%97%B4%E6%8E%A5%E8%B7%B3%E8%BD%AC%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/"},{"categories":["ollvm混淆与反混淆"],"content":"一、间接跳转实现逻辑 1.1 初始化BBNumbering、BBTargets集合 // llvm/lib/Transforms/Obfuscation/IndirectBranch.cpp std::map\u003cBasicBlock *, unsigned\u003e BBNumbering; std::vector\u003cBasicBlock *\u003e BBTargets; //all conditional branch targets // Init member fields BBNumbering.clear(); BBTargets.clear(); 1.2 BBNumbering、BBTargets块信息收集 SplitAllCriticalEdges(Fn, CriticalEdgeSplittingOptions(nullptr, nullptr)); // llvm/lib/Transforms/Utils/BasicBlockUtils.cpp unsigned llvm::SplitAllCriticalEdges(Function \u0026F, const CriticalEdgeSplittingOptions \u0026Options) { unsigned NumBroken = 0; // 遍历所有基础块 for (BasicBlock \u0026BB : F) { // 获取块的终止指令 Instruction *TI = BB.getTerminator(); // 如果指令有后继指令 if (TI-\u003egetNumSuccessors() \u003e 1 \u0026\u0026 !isa\u003cIndirectBrInst\u003e(TI)) for (unsigned i = 0, e = TI-\u003egetNumSuccessors(); i != e; ++i) // 分割块和后继块之间的连接 if (SplitCriticalEdge(TI, i, Options)) ++NumBroken; } return NumBroken; } // llvm/lib/Transforms/Obfuscation/IndirectBranch.cpp void NumberBasicBlock(Function \u0026F) { // 块遍历 for (auto \u0026BB : F) { if (auto *BI = dyn_cast\u003cBranchInst\u003e(BB.getTerminator())) { // 如果末尾指令是条件指令，则在BBTargets、BBNumbering中初始化对应块数量 if (BI-\u003eisConditional()) { unsigned N = BI-\u003egetNumSuccessors(); for (unsigned I = 0; I \u003c N; I++) { BasicBlock *Succ = BI-\u003egetSuccessor(I); if (BBNumbering.count(Succ) == 0) { BBTargets.push_back(Succ); BBNumbering[Succ] = 0; } } } } } // 打乱BBTargets顺序 long seed = RandomEngine.get_uint32_t(); std::default_random_engine e(seed); std::shuffle(BBTargets.begin(), BBTargets.end(), e); // 遍历BBTargets，填充BBNumbering，值为BBTargets的序号 unsigned N = 0; for (auto BB:BBTargets) { BBNumbering[BB] = N++; } } 1.3 重构BBTargets块的全局跳转变量 // llvm/lib/Transforms/Obfuscation/IndirectBranch.cpp // enckey创建 uint32_t V = RandomEngine.get_uint32_t() \u0026 ~3; ConstantInt *EncKey = ConstantInt::get(Type::getInt32Ty(Ctx), V, false); GlobalVariable *DestBBs = getIndirectTargets(Fn, EncKey); GlobalVariable *getIndirectTargets(Function \u0026F, ConstantInt *EncKey) { std::string GVName(F.getName().str() + \"_IndirectBrTargets\"); GlobalVariable *GV = F.getParent()-\u003egetNamedGlobal(GVName); if (GV) return GV; // encrypt branch targets std::vector\u003cConstant *\u003e Elements; // 遍历BBTargets块 for (const auto BB:BBTargets) { // 获取块地址 Constant *CE = ConstantExpr::getBitCast(BlockAddress::get(BB), Type::getInt8PtrTy(F.getContext())); // 地址+=enckey CE = ConstantExpr::getGetElementPtr(Type::getInt8Ty(F.getContext()), CE, EncKey); // 加入到Elements Elements.push_back(CE); } // 加入到全局变量中 ArrayType *ATy = ArrayType::get(Type::getInt8PtrTy(F.getContext()), Elements.size()); Constant *CA = ConstantArray::get(ATy, ArrayRef\u003cConstant *\u003e(Elements)); GV = new GlobalVariable(*F.getParent(), ATy, false, GlobalValue::LinkageTypes::PrivateLinkage, CA, GVName); // 添加到section llvm.metadata中 appendToCompilerUsed(*F.getParent(), {GV}); return GV; } 目的是收集BBTargets块的地址+enckey加入到全局变量中，这里全局变量已经得到 1.4 指令替换 for (auto \u0026BB : Fn) { auto *BI = dyn_cast\u003cBranchInst\u003e(BB.getTerminator()); if (BI \u0026\u0026 BI-\u003eisConditional()) { IRBuilder\u003c\u003e IRB(BI); // 获取块末尾指令 Value *Cond = BI-\u003egetCondition(); Value *Idx; Value *TIdx, *FIdx; // 获取 TIdx = ConstantInt::get(Type::getInt32Ty(Ctx), BBNumbering[BI-\u003egetSuccessor(0)]); FIdx = ConstantInt::get(Type::getInt32Ty(Ctx), BBNumbering[BI-\u003egetSuccessor(1)]); Idx = IRB.CreateSelect(Cond, TIdx, FIdx); // 加载全局变量+idx地址的值 Value *GEP = IRB.CreateGEP(DestBBs, {Zero, Idx}); LoadInst *EncDestAddr = IRB.CreateLoad(GEP, \"EncDestAddr\"); // Use IPO context to compute the encryption key // X = FuncSecret - EncKey // 全局变量-enckey等于块地址 Constant *X; if (SecretInfo) { X = ConstantExpr::getSub(SecretInfo-\u003eSecretCI, EncKey); } else { X = ConstantExpr::getSub(Zero, EncKey); } // -EncKey = X - FuncSecret Value *DecKey = IRB.CreateSub(X, MySecret); Value *DestAddr = IRB.CreateGEP(EncDestAddr, DecKey); // 跳转目标地址 IndirectBrInst *IBI = IndirectBrInst::Create(DestAddr, 2); IBI-\u003eaddDestination(BI-\u003egetSuccessor(0)); IBI-\u003eaddDestination(BI-\u003egetSuccessor(1)); // 指令替换 ReplaceInstWithInst(BI, IBI); } } 1.5 效果分析 w12为后继块的index x8为全局变量+index-enckey后的地址 br x8完成对后继块的跳转 ","date":"2023-03-30","objectID":"/posts/ollvm%E6%B7%B7%E6%B7%86%E4%B8%8E%E5%8F%8D%E6%B7%B7%E6%B7%86-goron%E6%A1%86%E6%9E%B6%E9%97%B4%E6%8E%A5%E8%B7%B3%E8%BD%AC%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/:0:1","tags":["goron框架"],"title":"Ollvm混淆与反混淆: goron框架间接跳转的实现原理","uri":"/posts/ollvm%E6%B7%B7%E6%B7%86%E4%B8%8E%E5%8F%8D%E6%B7%B7%E6%B7%86-goron%E6%A1%86%E6%9E%B6%E9%97%B4%E6%8E%A5%E8%B7%B3%E8%BD%AC%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/"},{"categories":["ollvm混淆与反混淆"],"content":"二、总结 根据对代码的分析，可以简述间接跳转的原理 收集末尾块的指令对应的后继块，形成map，map包含块以及对应的index 生成enckey，遍历后继块，对后继块的地址进行二次加密，整理到全局变量中 遍历末尾块的指令，对跳转后继块的指令进行重构 根据map获取index，在全局变量中获取后继块的加密地址 解析得到原始地址 指令替换 ","date":"2023-03-30","objectID":"/posts/ollvm%E6%B7%B7%E6%B7%86%E4%B8%8E%E5%8F%8D%E6%B7%B7%E6%B7%86-goron%E6%A1%86%E6%9E%B6%E9%97%B4%E6%8E%A5%E8%B7%B3%E8%BD%AC%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/:0:2","tags":["goron框架"],"title":"Ollvm混淆与反混淆: goron框架间接跳转的实现原理","uri":"/posts/ollvm%E6%B7%B7%E6%B7%86%E4%B8%8E%E5%8F%8D%E6%B7%B7%E6%B7%86-goron%E6%A1%86%E6%9E%B6%E9%97%B4%E6%8E%A5%E8%B7%B3%E8%BD%AC%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/"},{"categories":["ollvm混淆与反混淆"],"content":"很多App实现的定制ollvm框架中都有goron框架的影子，或多或少的借鉴了它的功能，包括 间接跳转,并加密跳转目标(-mllvm -irobf-indbr) 间接函数调用,并加密目标函数地址(-mllvm -irobf-icall) 间接全局变量引用,并加密变量地址(-mllvm -irobf-indgv) 字符串(c string)加密功能(-mllvm -irobf-cse) 过程相关控制流平坦混淆(-mllvm -irobf-cff) 想要了解怎么针对这些混淆功能完成去混淆，势必要先对其混淆过程有所了解，那么第一步就是对goron框架的编译使用 ","date":"2023-03-29","objectID":"/posts/ollvm%E6%B7%B7%E6%B7%86%E4%B8%8E%E5%8F%8D%E6%B7%B7%E6%B7%86-goron%E7%BC%96%E8%AF%91%E4%BD%BF%E7%94%A8/:0:0","tags":["goron框架"],"title":"Ollvm混淆与反混淆: Goron编译使用","uri":"/posts/ollvm%E6%B7%B7%E6%B7%86%E4%B8%8E%E5%8F%8D%E6%B7%B7%E6%B7%86-goron%E7%BC%96%E8%AF%91%E4%BD%BF%E7%94%A8/"},{"categories":["ollvm混淆与反混淆"],"content":"一、环境配置 环境：MacBook Pro 16G cmake：cmake version 3.26.3 Android Studio NDK：21.1.6352462 ","date":"2023-03-29","objectID":"/posts/ollvm%E6%B7%B7%E6%B7%86%E4%B8%8E%E5%8F%8D%E6%B7%B7%E6%B7%86-goron%E7%BC%96%E8%AF%91%E4%BD%BF%E7%94%A8/:0:1","tags":["goron框架"],"title":"Ollvm混淆与反混淆: Goron编译使用","uri":"/posts/ollvm%E6%B7%B7%E6%B7%86%E4%B8%8E%E5%8F%8D%E6%B7%B7%E6%B7%86-goron%E7%BC%96%E8%AF%91%E4%BD%BF%E7%94%A8/"},{"categories":["ollvm混淆与反混淆"],"content":"二、编译过程 2.1 工程选定 git clone https://github.com/amimo/goron.git cd goron git checkout llvm-9.0.0 2.2 编译 mkdir build \u0026\u0026 cd build 建好产出目录 cmake -DCMAKE_BUILD_TYPE=Release -DLLVM_ENABLE_ASSERTIONS=ON -DLLVM_ENABLE_PROJECTS=clang -G \"Unix Makefiles\" -DCMAKE_INSTALL_PREFIX=/Path/You/Install/Dir/llvm-project-install ../llvm make -j12 install LLVM_ENABLE_PROJECTS：参数只需开启clang编译器一个工程即可 CMAKE_INSTALL_PREFIX：（可选参数）设置编译后可执行文件、动态库、静态库、头文件等等统一的放置路径 编译完成之后就可以在bin目录下看到这些可执行文件了 FileCheck llvm-cat llvm-opt-fuzzer arcmt-test llvm-cfi-verify llvm-opt-report bugpoint llvm-config llvm-pdbutil c-arcmt-test llvm-cov llvm-profdata c-index-test llvm-cvtres llvm-ranlib clang llvm-cxxdump llvm-rc clang++ llvm-cxxfilt llvm-readelf clang-9 llvm-cxxmap llvm-readobj clang-check llvm-diff llvm-rtdyld clang-cl llvm-dis llvm-size ","date":"2023-03-29","objectID":"/posts/ollvm%E6%B7%B7%E6%B7%86%E4%B8%8E%E5%8F%8D%E6%B7%B7%E6%B7%86-goron%E7%BC%96%E8%AF%91%E4%BD%BF%E7%94%A8/:0:2","tags":["goron框架"],"title":"Ollvm混淆与反混淆: Goron编译使用","uri":"/posts/ollvm%E6%B7%B7%E6%B7%86%E4%B8%8E%E5%8F%8D%E6%B7%B7%E6%B7%86-goron%E7%BC%96%E8%AF%91%E4%BD%BF%E7%94%A8/"},{"categories":["ollvm混淆与反混淆"],"content":"三、集成到NDK 替换原有的NDK目录下的clang文件即可，首先在local.properties中配置好ndk.dir，接着替换clang、clang++文件即可 cp /Path/You/Install/Dir/llvm-project-install/bin/clang-9 /You/NDK/Path/Android/sdk/ndk/21.1.6352462/toolchains/llvm/prebuilt/darwin-x86_64/bin/clang cp /Path/You/Install/Dir/llvm-project-install/bin/clang-9 /You/NDK/Path/Android/sdk/ndk/21.1.6352462/toolchains/llvm/prebuilt/darwin-x86_64/bin/clang++ 配置完clang之后还需要在build.gradle中配置需要混淆组件，如下 defaultConfig { applicationId \"com.example.myapplication\" minSdk 24 targetSdk 33 versionCode 1 versionName \"1.0\" testInstrumentationRunner \"androidx.test.runner.AndroidJUnitRunner\" externalNativeBuild { cmake { cppFlags \"-mllvm -irobf-cff\" } } } 配合so函数如下 #include \u003cjni.h\u003e #include \u003cstring\u003e char text[256] = {0}; extern \"C\" JNIEXPORT jstring JNICALL Java_com_example_myapplication_MainActivity_stringFromJNI( JNIEnv* env, jobject /* this */, jint val) { if (val == 0) { strcpy(text, \"Hello from C++\"); } else if (val == 1) { strcpy(text, \"value is 1\"); } else if (val == 2) { strcpy(text, \"value is 2\"); } else if (val == 4) { strcpy(text, \"value is 4\"); } else if (val == 8) { strcpy(text, \"value is 8\"); } else if (val == 16) { strcpy(text, \"value is 16\"); } else if (val == 32) { strcpy(text, \"value is 32\"); } else if (val == 64) { strcpy(text, \"value is 64\"); } else if (val == 3) { strcpy(text, \"value is 3\"); } else if (val == 65535) { strcpy(text, \"value is 65535\"); } else { strcpy(text, \"value is default\"); } return env-\u003eNewStringUTF(text); } 运行查看效果 ","date":"2023-03-29","objectID":"/posts/ollvm%E6%B7%B7%E6%B7%86%E4%B8%8E%E5%8F%8D%E6%B7%B7%E6%B7%86-goron%E7%BC%96%E8%AF%91%E4%BD%BF%E7%94%A8/:0:3","tags":["goron框架"],"title":"Ollvm混淆与反混淆: Goron编译使用","uri":"/posts/ollvm%E6%B7%B7%E6%B7%86%E4%B8%8E%E5%8F%8D%E6%B7%B7%E6%B7%86-goron%E7%BC%96%E8%AF%91%E4%BD%BF%E7%94%A8/"},{"categories":["ollvm混淆与反混淆"],"content":"四、混淆效果对比 fla混淆后的效果 cse混淆后的效果 每个字符都对应一个加密函数 indgv混淆后的效果 字符串都通过全局变量来获取 icall混淆后的效果 indbr混淆后的效果 截断了函数流程 ","date":"2023-03-29","objectID":"/posts/ollvm%E6%B7%B7%E6%B7%86%E4%B8%8E%E5%8F%8D%E6%B7%B7%E6%B7%86-goron%E7%BC%96%E8%AF%91%E4%BD%BF%E7%94%A8/:0:4","tags":["goron框架"],"title":"Ollvm混淆与反混淆: Goron编译使用","uri":"/posts/ollvm%E6%B7%B7%E6%B7%86%E4%B8%8E%E5%8F%8D%E6%B7%B7%E6%B7%86-goron%E7%BC%96%E8%AF%91%E4%BD%BF%E7%94%A8/"},{"categories":["hook框架"],"content":"以14.2.18版本为例 ","date":"2023-03-12","objectID":"/posts/frida%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/:0:0","tags":["frida","源码分析"],"title":"Frida源码阅读","uri":"/posts/frida%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/"},{"categories":["hook框架"],"content":"一、frida-server做了什么 1.1 进程注入 // frida-core/src/linux/linux-host-session.vala protected override async Future\u003cIOStream\u003e perform_attach_to (uint pid, Cancellable? cancellable, out Object? transport) throws Error, IOError { PipeTransport.set_temp_directory (tempdir.path); var t = new PipeTransport (); var stream_request = Pipe.open (t.local_address, cancellable); uint id; string entrypoint = \"frida_agent_main\"; var linjector = injector as Linjector; #if HAVE_EMBEDDED_ASSETS id = yield linjector.inject_library_resource (pid, agent, entrypoint, t.remote_address, cancellable); #else id = yield linjector.inject_library_file (pid, Config.FRIDA_AGENT_PATH, entrypoint, t.remote_address, cancellable); #endif injectee_by_pid[pid] = id; transport = t; return stream_request; } perform_attach_to这里引入linjector来处理注入，注意这里的entrypoint // frida-core/src/linux/linjector.vala public async uint inject_library_resource (uint pid, AgentDescriptor agent, string entrypoint, string data, Cancellable? cancellable) throws Error, IOError { ensure_tempdir_prepared (); return yield inject_library_file_with_template (pid, agent.get_path_template (), entrypoint, data, cancellable); } public async uint inject_library_file (uint pid, string path, string entrypoint, string data, Cancellable? cancellable) throws Error, IOError { return yield inject_library_file_with_template (pid, PathTemplate (path), entrypoint, data, cancellable); } private async uint inject_library_file_with_template (uint pid, PathTemplate path_template, string entrypoint, string data, Cancellable? cancellable) throws Error, IOError { ensure_tempdir_prepared (); uint id = next_injectee_id++; yield helper.inject_library_file (pid, path_template, entrypoint, data, tempdir.path, id, cancellable); pid_by_id[id] = pid; return id; } public async void inject_library_file (uint pid, PathTemplate path_template, string entrypoint, string data, string temp_path, uint id, Cancellable? cancellable) throws Error, IOError { string path = path_template.expand (arch_name_from_pid (pid)); _do_inject (pid, path, entrypoint, data, temp_path, id); yield establish_session (id, pid); } 最终调用了_do_inject // frida-core/src/linux/frida-helper-backend-glue.c _frida_linux_helper_backend_do_inject (FridaLinuxHelperBackend * self, guint pid, const gchar * path, const gchar * entrypoint, const gchar * data, const gchar * temp_path, guint id, GError ** error) { FridaInjectInstance * instance; FridaInjectParams params; guint offset, page_size; FridaRegs saved_regs; gboolean exited; params.pid = pid; params.so_path = path; params.entrypoint_name = entrypoint; params.entrypoint_data = data; params.fifo_path = NULL; offset = 0; page_size = gum_query_page_size (); params.code.offset = offset; params.code.size = page_size; offset += params.code.size; params.data.offset = offset; params.data.size = page_size; offset += params.data.size; params.guard.offset = offset; params.guard.size = page_size; offset += params.guard.size; params.stack.offset = offset; params.stack.size = page_size * 2; offset += params.stack.size; params.remote_address = 0; params.remote_size = offset; params.open_impl = frida_resolve_libc_function (pid, \"open\"); params.close_impl = frida_resolve_libc_function (pid, \"close\"); params.write_impl = frida_resolve_libc_function (pid, \"write\"); params.syscall_impl = frida_resolve_libc_function (pid, \"syscall\"); if (params.open_impl == 0 || params.close_impl == 0 || params.write_impl == 0 || params.syscall_impl == 0) goto no_libc; #if defined (HAVE_GLIBC) params.dlopen_impl = frida_resolve_libc_function (pid, \"__libc_dlopen_mode\"); params.dlclose_impl = frida_resolve_libc_function (pid, \"__libc_dlclose\"); params.dlsym_impl = frida_resolve_libc_function (pid, \"__libc_dlsym\"); #elif defined (HAVE_UCLIBC) params.dlopen_impl = frida_resolve_linker_address (params.pid, dlopen); params.dlclose_impl = frida_resolve_linker_address (params.pid, dlclose); params.dlsym_impl = frida_resolve_linker_address (params.pid, dlsym); #elif defi","date":"2023-03-12","objectID":"/posts/frida%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/:0:1","tags":["frida","源码分析"],"title":"Frida源码阅读","uri":"/posts/frida%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/"},{"categories":["hook框架"],"content":"二、frida-gadget做了什么 gadget本身是一个动态库，在加载到目标进程中后会马上触发ctor执行指定代码，默认情况下是挂起当前进程并监听在27042端口等待Host的连接并恢复运行。其文件路径为lib/gadget/gadget.vala，启动入口为 // frida-core/lib/gadget/gadget.vala public void load (Gum.MemoryRange? mapped_range, string? config_data, int * result) { if (loaded) return; loaded = true; Environment.init (); Gee.Promise\u003cint\u003e? request = null; if (result != null) request = new Gee.Promise\u003cint\u003e (); location = detect_location (mapped_range); try { config = (config_data != null) ? parse_config (config_data) : load_config (location); } catch (Error e) { log_warning (e.message); return; } Gum.Process.set_code_signing_policy (config.code_signing); Gum.Cloak.add_range (location.range); exceptor = Gum.Exceptor.obtain (); wait_for_resume_needed = true; var listen_interaction = config.interaction as ListenInteraction; if (listen_interaction != null \u0026\u0026 listen_interaction.on_load == ListenInteraction.LoadBehavior.RESUME) { wait_for_resume_needed = false; } if (!wait_for_resume_needed) resume (); if (wait_for_resume_needed \u0026\u0026 Environment.can_block_at_load_time ()) { var scheduler = Gum.ScriptBackend.get_scheduler (); scheduler.disable_background_thread (); wait_for_resume_context = scheduler.get_js_context (); var ignore_scope = new ThreadIgnoreScope (); start (request); var loop = new MainLoop (wait_for_resume_context, true); wait_for_resume_loop = loop; wait_for_resume_context.push_thread_default (); loop.run (); wait_for_resume_context.pop_thread_default (); scheduler.enable_background_thread (); ignore_scope = null; } else { start (request); } if (result != null) { try { *result = request.future.wait (); } catch (Gee.FutureError e) { *result = -1; } } } Gadget启动时会根据指定路径去搜索配置文件，默认配置文件如下 { \"interaction\": { \"type\": \"listen\", \"address\": \"127.0.0.1\", \"port\": 27042, \"on_port_conflict\": \"fail\", \"on_load\": \"wait\" } } 即使用listen模式，监听在27042端口并等待连接。除了listen以外，还支持以下几种模式: connect: Gadget启动后主动连接到指定地址 script: 启动后直接加载指定的JavaScript文件 script-directory: 启动后加载指定目录下的所有JavaScript文件 ","date":"2023-03-12","objectID":"/posts/frida%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/:0:2","tags":["frida","源码分析"],"title":"Frida源码阅读","uri":"/posts/frida%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/"},{"categories":["hook框架"],"content":"三、ART Hook frida对于ART Hook的实现在项目frida-java-bridge中，在ART虚拟机中，对于方法的调用，大部分会调用到ArtMethod::Invoke void ArtMethod::Invoke(Thread* self, uint32_t* args, uint32_t args_size, JValue* result, const char* shorty) { if (UNLIKELY(!runtime-\u003eIsStarted() || (self-\u003eIsForceInterpreter() \u0026\u0026 !IsNative() \u0026\u0026 !IsProxyMethod() \u0026\u0026 IsInvokable()))) { if (IsStatic()) { art::interpreter::EnterInterpreterFromInvoke( self, this, nullptr, args, result, /*stay_in_interpreter=*/ true); } else { mirror::Object* receiver = reinterpret_cast\u003cStackReference\u003cmirror::Object\u003e*\u003e(\u0026args[0])-\u003eAsMirrorPtr(); art::interpreter::EnterInterpreterFromInvoke(self, this, receiver, args + 1, result, /*stay_in_interpreter=*/ true); } } else { if (!IsStatic()) { (*art_quick_invoke_stub)(this, args, args_size, self, result, shorty); } else { (*art_quick_invoke_static_stub)(this, args, args_size, self, result, shorty); } } } 主要分为两种情况 一种是ART未初始化完成或者系统配置强制以解释模式运行，此时则进入解释器 另一种情况是有native代码时，比如JNI代码、OAT提前编译过的代码或者JIT运行时编译过的代码以及代理方法等，此时则直接跳转到invoke_stub去执行 对于解释执行的情况，也细分为两种情况，一种是真正的解释执行，不断循环解析CodeItem中的每条指令并进行解析；另外一种是在当前解释执行遇到native方法时，这种情况一般是遇到了JNI函数，这时则通过method-\u003eGetEntryPointFromJni()获取对应地址进行跳转 class ArtMethod final { // ... struct PtrSizedFields { // Depending on the method type, the data is // - native method: pointer to the JNI function registered to this method // or a function to resolve the JNI function, // - resolution method: pointer to a function to resolve the method and // the JNI function for @CriticalNative. // - conflict method: ImtConflictTable, // - abstract/interface method: the single-implementation if any, // - proxy method: the original interface method or constructor, // - other methods: during AOT the code item offset, at runtime a pointer // to the code item. void* data_; // Method dispatch from quick compiled code invokes this pointer which may cause bridging into // the interpreter. void* entry_point_from_quick_compiled_code_; } ptr_sized_fields_; // ... }; 对于快速执行的模式是跳转到stub代码，以非静态方法为例，该stub定义在art/runtime/arch/arm64/quick_entrypoints_arm64.S文件中，大致作用是将参数保存在对应寄存器中，然后跳转到实际的地址执行 .macro INVOKE_STUB_CALL_AND_RETURN REFRESH_MARKING_REGISTER REFRESH_SUSPEND_CHECK_REGISTER // load method-\u003e METHOD_QUICK_CODE_OFFSET ldr x9, [x0, #ART_METHOD_QUICK_CODE_OFFSET_64] // Branch to method. blr x9 // Pop the ArtMethod* (null), arguments and alignment padding from the stack. mov sp, xFP // ... .endm 而ART_METHOD_QUICK_CODE_OFFSET_64对应的就是entry_point_from_quick_compiled_code_ 因此，不管是解释模式还是其他模式，只要目标方法有native代码，那么该方法的代码地址都是会保存在entry_point_from_quick_compiled_code_字段，只不过这个字段的含义在不同的场景中略有不同 所以我们若想要实现ARTHook，理论上只要找到对应方法在内存中的ArtMethod地址，然后替换其entrypoint的值即可。但是前面说过，并不是所有方法都会走到ArtMethod::Invoke。比如对于系统函数的调用，OAT优化时会直接将对应系统函数方法的调用替换为汇编跳转，跳转的目的就是就是对应方法的entrypoint，因为boot.oat由zygote加载，对于所有应用而言内存地址都是固定的，因此ART可以在优化过程中省略方法的查找过程从而直接跳转 再回到frida，对于ART Hook的实现在ArtMethodMangler当中 // lib/android.js patchArtMethod(replacementMethodId, { jniCode: impl, accessFlags: ((originalFlags \u0026 ~(kAccCriticalNative | kAccFastNative | kAccNterpEntryPointFastPathFlag)) | kAccNative | kAccCompileDontBother) \u003e\u003e\u003e 0, quickCode: api.artClassLinker.quickGenericJniTrampoline, interpreterCode: api.artInterpreterToCompiledCodeBridge }, vm); jniCode替换为用户封装而成的NativeFunction，并将accessFlags设置成kAccNative，即这是一个JNI方法。quickCode和interpreterCode分别是Quick模式和解释器模式的入口，替换为了上文中查找保存的trampoline，令Quick模式跳转到JNI入口，解释器模式跳转到Quick代码，这样就实现了该方法的拦截，每次执行都会当做JNI函数执行到jniCode即我们替换的代码中 虽然此时我们已经将目标ArtMethod改成了Native方法，且JNI的入口指向我们的hook函数，但如果该方法已经被OAT或者JIT优化成了二进制代码，此时在字节码层调用invoke-xxx时会通过方法的entry_point_from_quick_compiled_code_直接跳转到native代码执行，而不是quick_xxx_trampoline。 因此对于这种情况，我们可以将entrypoint的地址重新指向trampoline，但如前文所说，对于系统函数而言，其地址已知，因此调用方被优化后很可能直接就调转到了对应的native地址，而不会通过entrypoint去查找。因此frida采用的方法是直接修改目标方法的quickCode内容，将其替换为一段跳板代码，然后再间接跳转到我们的劫持实现中 Memory.patchCode(trampoline, 256, code =\u003e { const writer = new Arm64Writer(code, { pc: trampoline }); const relocator = new Arm64Relocator(address, writer); for (let i = 0; i !== 2; i++) { relocator.readOne(); } relocator.writeAll(); re","date":"2023-03-12","objectID":"/posts/frida%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/:0:3","tags":["frida","源码分析"],"title":"Frida源码阅读","uri":"/posts/frida%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/"},{"categories":["hook框架"],"content":"一、背景 从上手难度上来说frida可以说是开箱即用，几乎没有学习成本，对于大多数使用者来说，任何一个App都可以直接使用一个js脚本搞定。但是当面对繁多的App，如何将这种分析工具进行模块化拆分是需要好好思考思考的，直接使用js来做不太现实，而解决方案是ts+npm，优势在于 静态类型系统：提供静态类型检查，编译时即可发现类型错误，提升代码健壮性和可维护性 模块化管理：通过类型系统实现模块间的契约式开发，适用于大型项目管理 ","date":"2023-02-21","objectID":"/posts/frida%E8%B0%83%E8%AF%95%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:1:0","tags":["frida","源码编译"],"title":"Frida调试环境搭建","uri":"/posts/frida%E8%B0%83%E8%AF%95%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["hook框架"],"content":"二、frida ts项目配置 frida接入ts开发可以参考frida-agent-example，使用方式也很简单，参考 $ git clone git://github.com/oleavr/frida-agent-example.git $ cd frida-agent-example/ $ npm install $ frida -U -f com.example.android --no-pause -l _agent.js 实时编译可以直接调用npm run watch，如下 原理可以看package.json配置文件 { \"name\": \"frida-agent-example\", \"version\": \"1.0.0\", \"description\": \"Example Frida agent written in TypeScript\", \"private\": true, \"main\": \"agent/index.ts\", \"scripts\": { \"prepare\": \"npm run build\", \"build\": \"frida-compile agent/index.ts -o _agent.js -c\", \"watch\": \"frida-compile agent/index.ts -o _agent.js -w\" }, \"devDependencies\": { \"@types/frida-gum\": \"^18.5.1\", \"@types/node\": \"^18.19.3\", \"frida-compile\": \"^16.4.1\" } } 调用的是frida-compile agent/index.ts -o _agent.js -w来编译 修改index.ts代码可以动态编译 frida ts环境配置完成后需要主动暴露端口接入chrome调试，如下 frida -U -f com.tencent.wework -l _agent.js --debug --runtime=v8 默认端口为9229 ","date":"2023-02-21","objectID":"/posts/frida%E8%B0%83%E8%AF%95%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:2:0","tags":["frida","源码编译"],"title":"Frida调试环境搭建","uri":"/posts/frida%E8%B0%83%E8%AF%95%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["hook框架"],"content":"三、chrome调试环境配置 chrome打开标签chrome://inspect，点击Open dedicated DevTools for Node来新打开DevTools 进入DevTools后切换到Source可以看到该端口对应的文件 单步调试 ","date":"2023-02-21","objectID":"/posts/frida%E8%B0%83%E8%AF%95%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:3:0","tags":["frida","源码编译"],"title":"Frida调试环境搭建","uri":"/posts/frida%E8%B0%83%E8%AF%95%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":null,"content":"由于TLS 1.3是在TLS 1.2的基础上优化而来的，因此对于与上节实现相同的部分就不再详细介绍了，而只关注其中不同的部分。 总体来看，TLS 1.3与TLS 1.2相比，较大的差异有下面这些: 去除了一大堆过时的对称加密算法，只留下较为安全的AEAD(Authenticated Encryption with Associated Data)算法；加密套件(cipher suite)的概念被修改为单独的认证、秘钥交换算法以及秘钥拓展和MAC用到的哈希算法； 去除了静态RSA和秘钥交换算法套件，使目前所有基于公钥的交换算法都能保证前向安全； 引入了0-RTT(round-trip time) 的模式，减少握手的消息往返次数； ServerHello之后所有的握手消息都进行了加密； 修改了秘钥拓展算法，称为HKDF(HMAC-based Extract-and-Expand Key Derivation Function)； 废弃了TLS 1.2中的协议版本协商方法，改为使用Extension实现； TLS 1.2中的会话恢复功能现在采用了新的 PSK 交换实现； …… 下面将结合RFC文档、CS源码、Wireshark抓包这三个角度来讲解，资源来自于 The Illustrated TLS 1.3 Connection: Every byte explained The Illustrated TLS 1.3 Connection - Github 照惯例通过官方RFC文档初步认识下一个完整的握手流程 Client Server Key ^ ClientHello Exch | + key_share* | + signature_algorithms* | + psk_key_exchange_modes* v + pre_shared_key* --------\u003e ServerHello ^ Key + key_share* | Exch + pre_shared_key* v {EncryptedExtensions} ^ Server {CertificateRequest*} v Params {Certificate*} ^ {CertificateVerify*} | Auth {Finished} v \u003c-------- [Application Data*] ^ {Certificate*} Auth | {CertificateVerify*} v {Finished} --------\u003e [Application Data] \u003c-------\u003e [Application Data] + Indicates noteworthy extensions sent in the previously noted message. * Indicates optional or situation-dependent messages/extensions that are not always sent. {} Indicates messages protected using keys derived from a [sender]_handshake_traffic_secret. [] Indicates messages protected using keys derived from [sender]_application_traffic_secret_N. Figure 1: Message Flow for Full TLS Handshake 如果大家对于TLS1.2还有印象的话就会发现有几个变化 整个握手流程减少了一次服务端的回调 新增了key_share、pre_shared_key等等新的结构 整个流程目前只有1RTT，相比较之前的减少了一倍，在通信效率方面的提升巨大，而且还存在0RTT的模式，下面就通过具体的握手流程来分析下TLS1.3带来的变化 3.1.1 STEP 1 3.1.1.1 Client Hello 与TLS1.2一样，握手总是以Client发送Hello请求开始。但正如本节开头所说，TLS握手时的协议协商不再使用Handshake/Hello中的version字段，虽然是1.3版本，但请求中version还是指定1.2版本，这是因为有许多web中间件在设计时候会忽略不认识的TLS版本号，因此为了兼容性，版本号依旧保持不变。实际协商TLS版本是使用的是SupportedVersions拓展实现的。ClientHello的结构如下 struct { ProtocolVersion legacy_version = 0x0303; /* TLS v1.2 */ Random random; opaque legacy_session_id\u003c0..32\u003e; CipherSuite cipher_suites\u003c2..2^16-2\u003e; opaque legacy_compression_methods\u003c1..2^8-1\u003e; Extension extensions\u003c8..2^16-1\u003e; } ClientHello; session_id字段在此前的版本中该字段被用于恢复TLS会话，不过在TLS1.3中会话恢复使用了一种更为灵活的PSK秘钥交换方式，因此这个字段在TLS1.3中是没有实际作用的 在ClientHello消息中，有一个重要的拓展，即KeyShare，用于与服务器交换秘钥。前文说到在TLS1.3中，ServerHello之后的所有消息都是加密的，为了双方能够正确加解密数据，因此在ClientHello中通过该拓展告诉服务端自己的公钥以及秘钥交换算法 随后，该公钥就随着Client Hello发送给了服务端。 3.1.2 STEP 2 3.1.2.1 Server Hello 服务端根据客户端提供的选项，选择一个好自己支持的TLS版本以及加密套件，这里选的是TLS_AES_256_GCM_SHA384 由于涉及到了秘钥交换，服务端在收到请求后也需要先生成一对临时公私钥，Key Share Extension 中返回的即为上述公钥。 如果还记得上文的 ECDH 秘钥交换方法，这里就可以很容易计算出两端的共享秘钥。该秘钥用于生成后续握手包所需的秘钥，使用 HKDF 函数进行生成，如下所示 early_secret = HKDF-Extract(salt: 00, key: 00...) empty_hash = SHA384(\"\") derived_secret = HKDF-Expand-Label(key: early_secret, label: \"derived\", ctx: empty_hash, len: 48) handshake_secret = HKDF-Extract(salt: derived_secret, key: shared_secret) client_secret = HKDF-Expand-Label(key: handshake_secret, label: \"c hs traffic\", ctx: hello_hash, len: 48) server_secret = HKDF-Expand-Label(key: handshake_secret, label: \"s hs traffic\", ctx: hello_hash, len: 48) client_handshake_key = HKDF-Expand-Label(key: client_secret, label: \"key\", ctx: \"\", len: 32) server_handshake_key = HKDF-Expand-Label(key: server_secret, label: \"key\", ctx: \"\", len: 32) client_handshake_iv = HKDF-Expand-Label(key: client_secret, label: \"iv\", ctx: \"\", len: 12) server_handshake_iv = HKDF-Expand-Label(key: server_secret, label: \"iv\", ctx: \"\", len: 12) 3.1.2.2 Server Encrypted Extensions 在计算完共享秘钥后，后续的流量将使用上述秘钥进行加密，因此对于TLS 1.2的情况服务端会先返回一个 ChangeCipherSpec，在TLS 1.3中可不必多此一举，不过在兼容模式下为了防止某些中间件抽风还是会多这么一步。 我们这里直接看加密的数据，服务端一般会先返回一个Encrypted Extensions类型的Record消息，该消息加密后存放在Record(type=0x17)，即Application Data的Body部分，同时(加密后数据的)末尾还添加了16字节的 Auth Tag，这是AEAD算法用来校验加密消息完整性的数据。 根据之前服务端所选择的套件，这里数据使用 AES-256-GCM 进行加密和校验，这里解密后的拓展长度为空。一般与握手无关的额外拓展都会放在这里返回，这是为了能够尽可能地减少握手阶段的明文传输。 3.1.2.3 Server Certificate 使用server handshake key/iv进行加密。解密后的数据与TLS 1.2的证书响应相同。 3.1.2.4 Se","date":"0001-01-01","objectID":"/posts/untitled/:0:0","tags":null,"title":"","uri":"/posts/untitled/"}]